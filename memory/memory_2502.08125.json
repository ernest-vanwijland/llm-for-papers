{
  "nbtoprove": -1,
  "statements": [
    "If x is at level i, then for any vertex v, $d^x(v) \\le \\hat{d}^x(v) \\le d^x(v)(1 + \\epsilon / \\log m)^i$.",
    "The offline algorithm runs in time $O(m \\log(nW) (\\log^3 n) (\\log \\log n)/\\epsilon)$.",
    "For any sequence of edge inserts \\sigma', let \\tilde{d}^t(v) be the distance estimates that result from running the offline algorithm on \\sigma'. Then for any vertex v and time t \\ge 1, if v is dead at time t, then \\tilde{d}^t(v) = \\tilde{d}^{t-1}(v).",
    "For any time t and any vertex v, we have $d^t(v) \\le \\tilde{d}^t(v) \\le d^t(v)(1 + \\epsilon)$.",
    "After inserting edge $e_t$, we have $D[i] = \\tilde{d}^t(v_i)$ for $i = 1, \\dots, n$.",
    "For any integer $\\tau \\ge 0$ and position $i \\in \\{1, \\dots, m\\}$, there are at most $\\tau + 2|\\text{HIGH}(\\tau)|$ jumps over $i$.",
    "The online algorithm runs in time $\\tilde{O} (m \\cdot \\min_{\\tau} \\{\\tau + |HIGH(\\tau)|\\} \\cdot \\log W/\\epsilon)$.",
    "There is a learned online all-pairs shortest path algorithm with $\\tilde{O}(nm \\log W/\\epsilon)$ preprocessing time, $O(\\log n)$ worst-case update time, and $O(n^2 \\log \\log_{1+\\epsilon}(nW))$ worst-case query time."
  ],
  "proofs": [
    "Proof. We show the lemma by induction on i. For i = 0, i.e., x = 0 or x = m, we obtain the exact distance for every vertex.\n\nFirst, we show that $d^x(v) \\le \\hat{d}^x(v)$. If v is dead in subproblem x, then $\\hat{d}^x(v) = \\hat{d}^l(v)$, where l is the start of the interval of node x in the recursion tree. So, the level of l is smaller than i. By induction, $\\hat{d}^l(v) \\le d^l(v)$. Also, since $l < x$, we have $d^x(v) \\le d^l(v)$. Therefore, $\\hat{d}^x(v) \\le d^l(v) \\le d^x(v) = d^x(v)$. So, we can assume v is alive. Let $p = s, v_1, v_2, \\dots, v_k$ be the shortest path from s to $v = v_k$ in $G_x$, so $\\hat{d}^x(v)$ is the length of p rounded up to the nearest integer power of $1 + \\epsilon / \\log m$. Note that the path $v_1, v_2, \\dots, v_k$ exists in $G'_x$ as well, since all the edges that only appear in $G'_x$ start at s. If the edge $(s, v_1)$ is present in $G'_x$, then $\\hat{d}^x(v) \\le d^x(v)$, as p is a path from s to v in $G'_x$, which means that $d'_{G'_x}(v)$, the length of the shortest path in $G'_x$ from s to v, is at most the length of p. Otherwise, there exists an edge $(u, v_1)$ in $G_x$, such that u is dead at time x, and the edge $(s, v_1)$ has weight $\\hat{d}^l(u) + w(u, v_1)$. As shown above, since u is dead at time x, we have $\\hat{d}^l(u) \\ge d^l(u)$. Therefore,\n$$\n\\hat{d}^x(v) \\ge \\hat{d}^l(u) + w(u, v_1) + d_{G_x}(v_1, v) \\ge d^l(u) + w(u, v_1) + d_{G_x}(v_1, v) \\ge d^x(v).\n$$\nNext, we show that $\\hat{d}^x(v) \\le d^x(v)(1 + \\epsilon / \\log m)^i$. Let q be the shortest path from s to v in $G_x$. If q is also present in $G'_x$, it follows that $\\hat{d}^x(v) \\le d^x(v)(1 + \\epsilon / \\log m)$. Otherwise, let $(a, b)$ be the last edge in q that does not exist in $G'_x$. Thus, either a or b is not alive in $G_x$.\n\nFirst, let’s assume b is not alive in $G_x$. Thus b must be the last vertex in q—if there were an edge $(b, c)$ in q, this edge would exist in $G'_x$, so b would be alive in $G_x$ (note that $b \\ne s$). Since b is the last vertex in q, and $v = b$ is dead in $G_x$, it follows that\n$$\n\\hat{d}^x(v) = \\hat{d}^r(v) \\le d^r(v)(1 + \\epsilon / \\log m)^{i-1} < d^x(v)(1 + \\epsilon / \\log m)^{i-1},\n$$\nwhere r is the end of the interval of node x in the recursion tree. The first inequality follows from the induction hypothesis and the fact that the level of r is strictly less than i, and the second inequality is because $x \\le r$ and adding more edges can only decrease the distance of each node from s.\n\nOtherwise, assume b is alive in $G_x$, which means that a is dead in $G_x$. Thus, there is an edge $(s, b)$ in $G'_x$ with weight $\\hat{d}^r(a) + w(a, b) = d^r(a) + w(a, b)$. Prepending this edge to the suffix of q beginning at b results in a path in $G'_x$ from s to v of length $d^r(a) + w(a, b) + d_{G_x}(b, v)$. Since the level of r is less than x, by the induction hypothesis we have $d^r(a) \\le d^r(a)(1 + \\epsilon / \\log m)^{i-1}$. Hence,\n\\begin{align*}\n\\hat{d}^x(v) &\\le (d^r(a) + w(a, b) + d_{G_x}(b, v))(1 + \\epsilon / \\log m) \\\\\n&\\le (d^r(a)(1 + \\epsilon / \\log m)^{i-1} + w(a, b) + d_{G_x}(b, v))(1 + \\epsilon / \\log m) \\\\\n&\\le (d^x(a) + w(a, b) + d_{G_x}(b, v))(1 + \\epsilon / \\log m)^i \\\\\n&= d^x(v)(1 + \\epsilon / \\log m)^i.\n\\end{align*}",
    "Let $m_y$ be the number of alive edges in a subproblem $y$. For a subproblem $[l, r]$, the time to find the alive edges and nodes in $G_x$ is $O(m_r)$, where $x$ is the midpoint of $[l, r]$. For an alive edge $e = (u, v)$ in $G_x$, if $u$ is alive in $G_x$, then inserting $e$ in $G'_x$ takes $O(1)$ time. Otherwise, the algorithm needs to recover $\\tilde{d}^r(u)$ from the lowest ancestor of $x$ in the recursion tree in which $u$ is alive in order to calculate the weight of the edge $(s, v)$ in $G'_x$. Each node $y$ in the recursion tree maintains $\\tilde{d}^y(w)$ for all alive vertices $w$ in $G_y$ in a balanced binary search tree. Therefore, the algorithm can check whether a vertex is alive in a subproblem in time $O(\\log n)$. Also, if $w$ is alive in $G_y$, it takes $O(\\log n)$ time to find $\\tilde{d}^y(w)$. Since node $x$ has at most $\\log m$ ancestors, recovering $\\tilde{d}^r(u)$ can be done in $O(\\log n \\log \\log m)$ time by doing a binary search on the ancestors. Hence, building $G'_x$ takes $O(m_x \\log n \\log \\log m)$ time. The time to run Dijkstra’s on $G'_x$ is $O(m_x \\log n)$. Also, the time to build the balanced binary search tree corresponding to subproblem $x$ is $O(m_x \\log n)$, as the number of alive nodes in $G_x$ is bounded by the number of alive edges in $G_x$. Thus, the runtime of the algorithm is bounded by $O(\\log n \\log \\log m)$ times the total number of alive edges in all the subproblems.\n\nFor a given $i$ and $v$, let $x$ be the time when $d(v)$ decreases from $(1 + \\epsilon / \\log m)^{i+1}$ to $(1 + \\epsilon / \\log m)^i$. Then $v$ is alive in any subproblem that contains $x$; there is at most 1 such subproblem in each level of the recursion tree. For each vertex $v$, summing over all $\\log_{1+\\epsilon/\\log m}(nW) = O(\\log(nW) \\log m/\\epsilon)$ values of $i$ and the $\\log m$ levels of the recursion tree, we have that there are in total $O(\\log(nW) \\log^2 m/\\epsilon)$ subproblems in which $v$ is alive. Since an edge is only alive if its head is alive, there are only a total of $m \\log(nW) \\log^2 m/\\epsilon$ alive edges over all subproblems. Substituting $\\log m = O(\\log n)$, we obtain an aggregate running time $O(m \\log(nW) (\\log^3 n) (\\log \\log n)/\\epsilon)$.",
    "Proof. If $t = m$, then $v$ cannot be dead at time $t$. Otherwise, since $1 \\le t \\le m-1$, $t$ is the midpoint of some subproblem $[l, r]$ with $r-l \\ge 2$, which means $l < t$. If $v$ is dead at time $t$, then $\\tilde{d}^l(v) = \\tilde{d}^t(v)$. If $l = t-1$, the claim is proven. Otherwise, we must have $t-1 \\in (l, t)$. Therefore, $t-1$ is the midpoint of some descendant of $[l, t]$ in the recursion tree. Since $v$ is dead during all such recursive calls, $\\tilde{d}^{t-1}(v) = \\tilde{d}^l(v) = \\tilde{d}^t(v)$.",
    "Proof. For each time $t = 0, \\dots, m$, let $\\mathcal{T}_t$ be the recursion tree of all subproblems when the offline algorithm is run on $\\hat{\\sigma}_t$, and let $\\hat{\\mathcal{T}}_t$ be the recursion tree of the online algorithm after t edge insertions. In each of these trees, for each tree node x, the additional information of $\\hat{d}^x(v)$ for all alive vertices $v$ in $G_x$ is stored in a balanced binary search tree.\n\nWe show $\\hat{\\mathcal{T}}_t = \\mathcal{T}_t$ for all $t = 0, \\dots, m$, which proves that the distance estimates for all the nodes are similar in $\\mathcal{T}_t$ and $\\hat{\\mathcal{T}}_t$. The result then follows from Lemma 1 and the fact that $\\hat{\\sigma}_t(i) = \\sigma(i)$ for $i = 1, \\dots, t$.\n\nWe prove this by induction on $t$. For $t = 0$, since the algorithm starts by running the offline algorithm on $\\hat{\\sigma}_0$, it follows that $\\hat{\\mathcal{T}}_0 = \\mathcal{T}_0$. Let $t \\ge 1$ and assume $\\hat{\\mathcal{T}}_{t-1} = \\mathcal{T}_{t-1}$. We want to show $\\hat{\\mathcal{T}}_t = \\mathcal{T}_t$.\n\nAt time $t$, if the newly arrived edge $e_t$ was correctly predicted, we have $\\hat{\\sigma}_t = \\hat{\\sigma}_{t-1}$ and the online algorithm does not change the recursion tree, meaning that $\\hat{\\mathcal{T}}_t = \\hat{\\mathcal{T}}_{t-1}$. Also, since $\\hat{\\sigma}_t = \\hat{\\sigma}_{t-1}$, we have $\\mathcal{T}_t = \\mathcal{T}_{t-1}$, and by the induction hypothesis, we conclude that $\\hat{\\mathcal{T}}_t = \\mathcal{T}_t$. So, assume that $t' = \\text{index}_{t-1}(e_t) > t$. So $e_t$ jumps from $t'$ to $t$, and the online algorithm rebuilds all the subproblems $[l, r]$ where $e_t$ jumps over their midpoint $x = (l + r)/2$ and all their descendants.\n\nWe show that the algorithm rebuilds all the necessary subproblems. In other words, we show each subproblem $x$ that is not rebuilt, i.e., is the same in $\\hat{\\mathcal{T}}_t$ and $\\hat{\\mathcal{T}}_{t-1}$, is also the same in $\\mathcal{T}_t$ and $\\mathcal{T}_{t-1}$. Since, by the induction hypothesis, $x$ is the same in trees $\\hat{\\mathcal{T}}_{t-1}$ and $\\mathcal{T}_{t-1}$, this proves that $x$ is the same in $\\hat{\\mathcal{T}}_t$ and $\\mathcal{T}_t$, as desired.\n\nAssume for sake of contradiction that there is an interval $[l, r]$ with midpoint $x$ such that $e_t$ does not jumps over the midpoint of $[l, r]$ or the midpoint of any of the ancestors of $[l, r]$, but $x$ is different in $\\mathcal{T}_{t-1}$ and $\\mathcal{T}_t$, meaning that the binary search trees that store $\\hat{d}^x(v)$ for alive vertices $v$ in $G_x$ are different in $\\mathcal{T}_{t-1}$ and $\\mathcal{T}_t$. Without loss of generality, assume no ancestor of $x$ has these properties.\n\nSince $x$ is not rebuilt, none of its ancestors is rebuilt either. By the choice of $x$, this means that all the ancestors of $x$ are the same in $\\mathcal{T}_{t-1}$ and $\\mathcal{T}_t$. The binary search tree stored at $x$ depends on the auxiliary graph $G'_x$, which in turn only depends on the alive nodes and edges in $G_x$, and the distance estimates $\\hat{d}^y(u)$ for each dead vertex $u$ that is the tail of an alive edge. For any vertex $u$ that is dead in $G_x$, $\\hat{d}^x(u)$ is stored in the binary search tree of some ancestor $y$ of $x$, where $u$ is alive in $G_y$. Since $y$ is the same in $\\mathcal{T}_{t-1}$ and $\\mathcal{T}_t$, these distance estimates are the same in $\\mathcal{T}_{t-1}$ and $\\mathcal{T}_t$. A node is alive in $G_x$ if and only if it is alive in $G_l$ and $G_r$, and its distance estimates differ at $l$ and $r$. An edge is alive in $G_x$ in $\\mathcal{T}_t$ (respectively, $\\mathcal{T}_{t-1}$) if it is among the first $x$ edges in $\\hat{\\sigma}_t$ (respectively, $\\hat{\\sigma}_{t-1}$), and its head is alive. Since the edge $e_t$ has not jumped over $x$, we conclude that the set of the first $x$ edges in $\\hat{\\sigma}_t$ is similar to that of $\\hat{\\sigma}_{t-1}$. The set of alive vertices in $G_x$ only depends on the alive vertices in $G_l$ and $G_r$. Since $l$ and $r$ are ancestors of $x$, the binary search trees that store distance estimates to alive vertices in $G_l$ and $G_r$ are exactly the same in $\\mathcal{T}_{t-1}$ and $\\mathcal{T}_t$. Therefore, the set of alive vertices and edges in $G_x$ are the same in $\\mathcal{T}_{t-1}$ and $\\mathcal{T}_t$. Putting everything together, we conclude that node $x$ is similar in $\\mathcal{T}_{t-1}$ and $\\mathcal{T}_t$, which contradicts the choice of $x$.",
    "Proof. We show the lemma by induction on $t$. The case $t = 0$ is trivial.\nIf $v_i$ is dead in $G_{t'}$ for every $t' \\in \\text{rebuild}(t)$, where $t' \\le t$, then $v_i$ is dead at time $t$ (note that by definition we always have $t \\in \\text{rebuild}(t)$). Also, in this case, $D[i]$ is not overwritten at time $t$. By Lemma 3 and the induction hypothesis, $D[i] = \\tilde{d}^{t-1}(v_i) = \\tilde{d}^t(v_i)$.\nOtherwise, let $t'$ be the largest time less than or equal to $t$ in $\\text{rebuild}(t)$ at which $v_i$ is alive. By definition of the algorithm, $D[i] = \\tilde{d}^{t'}(v_i)$. If $t' = t$, then $D[i] = \\tilde{d}^t(v_i)$, and if $t' < t$, then by repeatedly applying Lemma 3, $\\tilde{d}^t(v_i) = \\tilde{d}^{t'}(v_i)$.",
    "Proof. Fix $\\tau$. Let $h_t$ be the number of edges in $\\text{HIGH}(\\tau)$ that have arrived by time $t$. To begin, we claim that at any time $t$, each edge $e \\in \\text{LOW}(\\tau)$ is at most $\\tau + h_t$ slots ahead of its true position, i.e., $\\text{index}_t(e) - \\text{index}(e) \\le \\tau + h_t$. This is true at $t = 0$ by definition. For sake of contradiction, consider the first time $t$ at which this condition does not hold for some edge $e$, i.e., $\\text{index}_{t-1}(e) - \\text{index}(e) \\le \\tau + h_{t-1}$, but $\\text{index}_t(e) - \\text{index}(e) > \\tau + h_t$. Notice that at each time the position of an edge can increase by at most 1, so the above can only happen if $\\text{index}_t(e) = \\text{index}_{t-1}(e) + 1$ and $h_t = h_{t-1}$, meaning the edge $e'$ inserted at time $t$ is in $\\text{LOW}(\\tau)$. Since insertion of $e'$ changes the position of $e$, $e'$ must have jumped from a position greater than $\\text{index}_{t-1}(e)$ to position $t$. Thus $\\text{index}_{t-1}(e') > \\text{index}_{t-1}(e)$. Also note that since $e'$ has jumped over $e$ in the updated predictions, it means that $e$ has not arrived yet, i.e., $\\text{index}(e) > t = \\text{index}(e')$. Therefore,\n$$ \\text{index}_{t-1}(e') - \\text{index}(e') > \\text{index}_{t-1}(e) - \\text{index}(e)+2 = \\text{index}_t(e) - \\text{index}(e)+1 > \\tau + h_t = \\tau + h_{t-1}, $$\nwhich contradicts the choice of $t$.\n\nNow, fix a position $i \\in \\{1, \\dots, m\\}$. At each time $t$, either no jump happens, or some edge jumps from position $t' > t$ to position $t$. Consider the first time $t^*$ an edge $e \\in \\text{LOW}(\\tau)$ jumps over $i$. We want to show that $t^*$ cannot be “much smaller” than $i$. Assume this jump is from position $t' > i$ to position $t^* < i$. So, the position of $e$ at time $t^* - 1$ in the updated prediction is $t'$, i.e., $\\text{index}_{t^*-1}(e) = t'$. Also, the actual position of $e$ is $t^*$, i.e., $\\text{index}(e) = t^*$. We know that\n$$ t' - t^* = \\text{index}_{t^*-1}(e) - \\text{index}(e) \\le \\tau + h_{t^*-1} \\le \\tau + |\\text{HIGH}(\\tau)|, $$\nwhich means that $i - t^* < t' - t^* \\le \\tau + |\\text{HIGH}(\\tau)|$.\n\nBefore time $t^*$, all the edges that might have jumped over $i$ are in $\\text{HIGH}(\\tau)$. So there are at most $|\\text{HIGH}(\\tau)|$ jumps over $i$ before time $t^*$. Also, after time $i$, no edge can jump over $i$. Therefore, the total number of jumps over $i$ is at most $|\\text{HIGH}(\\tau)| + (i - t^* + 1) \\le \\tau + 2|\\text{HIGH}(\\tau)|$.",
    "Each subproblem $[l, r]$ is rebuilt only if an edge jumps over its midpoint or the midpoint of one of its ancestors. Each subproblem has at most $\\log m$ ancestors. For each $\\tau$, it follows from Lemma 6 that the subproblem $[l, r]$ is rebuilt at most $(\\log m)(\\tau + 2|HIGH(\\tau)|)$ times. From Lemma 2, we know it takes $\\tilde{O}(m \\log W/\\epsilon)$ time to rebuild all the subproblems once. Thus, the time it takes to do all the rebuilds in the online algorithm is $\\tilde{O} (m \\cdot \\min_{\\tau} \\{\\tau + |HIGH(\\tau)|\\} \\cdot \\log W/\\epsilon)$.\n\nWe must also account for the time required to maintain the distance array $D$. Consider the updates on $D$ at time $t$. If no subproblem gets rebuilt at time $t$, we only iterate through the alive vertices in $G_t$ when updating $D$. We can charge this cost to the cost of the last rebuild of subproblem $t$, as the last time subproblem $t$ was rebuilt, it had the same set of alive vertices as it has at time $t$. Otherwise, in order to update $D$, we only iterate once through the alive vertices of a subset of the subproblems that get rebuilt at time $t$, and we can charge this cost to the cost of rebuild of these subproblems at time $t$. Note that this way, each subproblem that gets rebuilt throughout all the edge insertions gets charged at most once, which means that maintaining the distance array $D$ does not have any asymptotic overhead.\n\nFinally, we need to add the time needed to update the predicted sequence $\\hat{\\sigma}$. The total number of slots an edge $e \\in \\{e_1, ..., e_m\\}$ is shifted by over all edges equals the total number of times a position $i \\in \\{1, ..., m\\}$ is jumped over for all positions. By Lemma 6, each position gets jumped over at most $\\tau+2|HIGH(\\tau)|$ times for any $\\tau$. Therefore, updating the predicted sequence takes $O(m \\cdot (\\tau+|HIGH(\\tau)|))$ time for any $\\tau$.\n\nThus, the total runtime of the algorithm is $\\tilde{O} (m \\cdot \\min_{\\tau} \\{\\tau + |HIGH(\\tau)|\\} \\cdot \\log W/\\epsilon)$.",
    "Proof of Theorem 3. We briefly summarize the algorithm of van den Brand et al.; see the proof of Theorem 3.1 in [45] for the full details. To begin, we run the algorithm from Corollary 2 on $\\hat{\\sigma}$ in $\\tilde{O}(nm \\log W/\\epsilon)$ time, so that for all $t, i, j$ we can find $\\hat{d}^t(i, j)$ in $O(\\log \\log_{1+\\epsilon}(nW))$ time.\n\nOn a query at time $t$ for vertices $i$ and $j$, we do the following. Let $t'$ be the latest time such that all edges that were predicted to appear by time $t'$ in $\\hat{\\sigma}$ have actually appeared (in $\\sigma$) by time $t$. Notice that if $\\hat{\\sigma}$ is a permutation of $\\sigma$, then $t - t' \\le \\eta$ (see the discussion immediately after Theorem 3.1 in [45] for a formal proof). Let $E'$ be the set of all edges that have arrived by time $t$ minus the edges that were predicted to arrive by time $t'$. Then, $|E'| = t - t' \\le \\eta$. We construct $G'$ with a set of vertices equal to all vertices in any edge in $E'$, plus $i$ and $j$. The graph $G'$ is complete. For each edge $e = (u, v)$ in $G'$, the weight of the edge is the minimum of: (1) the weight of any edge from $u$ to $v$ in $E'$, and (2) $\\hat{d}^{t'}(u, v)$. We run Dijkstra's algorithm to obtain the distance from $i$ to $j$ in $G'$; this answers the query. Constructing $G'$ and running Dijkstra's algorithm can be done in time $O(\\eta^2 \\log \\log_{1+\\epsilon}(nW))$.\n\nLet us briefly explain why this works. First, let's show that the answer is at least $d^t(i, j)$. Consider the shortest path $P$ from $i$ to $j$ in $G'$. Each edge $e = (u, v)$ in $P$ is one of two types: either an edge in $E'$, or an edge with weight $\\hat{d}^{t'}(u, v)$. The edge with weight $\\hat{d}^{t'}(u, v)$ upper bounds the length of the shortest path between $u$ and $v$ over edges that were predicted to arrive by $t'$. All such edges are in $G_t$ by definition of $t'$. Thus, by concatenating the edges from $P$ in $E'$ and the subpaths corresponding to the edges in $P$ not in $E'$, we obtain a path $P'$ in $G_t$ with weight at most that of $P$. Now, we show the answer is at most $(1+\\epsilon)d^t(i, j)$. Consider the shortest path $Q$ from $i$ to $j$ in $G_t$. We can decompose $Q$ into a sequence of subpaths, each of which is either an edge in $E'$, or consists of a sequence of edges not in $E'$. For each edge and subpath, there is an edge in $G'$ with weight at most $(1 + \\epsilon)$ larger by definition; concatenating these edges we obtain a path $Q'$ in $G'$ of weight at most $(1 + \\epsilon)$ larger.\n\nWith queries in mind, there are two goals for updates: we must be able to construct $E'$ efficiently, and we must maintain $t'$. We can store the inserted edges in a balanced binary-search tree, which takes $O(\\log n)$ time per insert to maintain. At each time $t$, the BST contains index$(e)$ for all edges $e$ that have arrived by time $t$. This allows us to find $t'$ and construct $|E'|$ in $O(\\log n)$ and $O(|E'|\\log n) = O(\\eta \\log n)$ time, respectively (see the discussion in [45, Theorem 3.1])."
  ],
  "solutions": [],
  "verifs": [],
  "grades": [],
  "proof_type": [],
  "timestamp": "2025-09-15T12:31:02.522960"
}
