\section{Near-Optimal LDDs in Near-Linear Time} \label{sec:ldd-fast}
In this section we show that near-optimal LDDs can even be computed in near-linear (i.e., near-optimal) running time. Formally, the goal of this section is to prove the last of our main theorems:

\thmMainFast*

We structure this section as follows: In \cref{sec:ldd-fast:sec:cutting} we first prove an important cutting lemma (\cref{lem:cut-light}), which we then apply in \cref{sec:ldd-fast:sec:algo} to prove \cref{thm:main-fast}.

\subsection{Cutting Lemma} \label{sec:ldd-fast:sec:cutting}
We rely on the following result due to Cohen that we can approximate efficiently the sizes of out-balls $\Bout(v, r)$ simultaneously for all nodes $v$. Note that we can equally approximate the size of the in-balls $\Bin(v, r)$ by applying \cref{lem:cohen} on the reverse graph.

\begin{lemma}[Cohen's Algorithm~{{\cite[Theorem~5.1]{Cohen97}}}] \label{lem:cohen}
Let $G$ be a directed weighted graph, let $r \geq 0$ and~\makebox{$\epsilon > 0$}. There is an algorithm that runs in time $\Order(m \epsilon^{-2} \log^3 n)$ and computes approximations~$b(v)$ satisfying with high probability that
\begin{equation*}
    (1 - \epsilon) |\Bout(v, r)| \leq b(v) \leq (1 + \epsilon) |\Bout(v, r)|.
\end{equation*}
\end{lemma}

The goal of this subsection is to establish the following lemma:

\begin{lemma}[Cutting Light Nodes] \label{lem:cut-light}
Let $G = (V, E)$ be a directed weighted graph, and consider the parameters $\delta > 0$, $0 \leq r_0 < r_1$, $1 \leq s_1 < s_0 \leq m$. There is an algorithm that computes a set of cut edges $S \subseteq E$ and sets of remaining vertices $R \subseteq V$ such that:
\begin{enumerate}[label=(\roman*)]
    \item Each strongly connected component in $G \setminus S$ either only contains nodes from $R$ or only nodes from $V \setminus R$. In the latter case it contains at most $\frac32 \cdot \frac{m}{s_1}$ edges.
    \item For every node $v \in R$ with $|\Bout_G(v, r_1)| \leq \frac{m}{s_1}$, it holds that $|\Bout_{G[R]}(v, r_0)| \leq \frac{m}{s_0}$.
    \item None of the edges in $S$ has its source in $R$ (i.e., $S \subseteq (V \setminus R) \times V$). Moreover, for each edge $e = (x, y) \in E$ it holds that:
    \begin{equation*}
        \Pr(e \in S \mid x \not\in R) \leq \frac{w_e \ln(2s_0 / \delta)}{r_1 - r_0}.
    \end{equation*}
\end{enumerate}
With probability at most $\delta$ the algorithm instead returns ``fail'', and with probability at most~$\frac{1}{\poly(n)}$ the algorithm returns an arbitrary answer. The running time is~\smash{$\Order(m \log^4 n)$}.
\end{lemma}

\begin{proof}\textcolor{red}{TOPROVE 0}\end{proof}

\subsection{Near-Linear-Time LDD} \label{sec:ldd-fast:sec:algo}
We are ready to state the LDD algorithm. Throughout this section, we fix the following parameters:
\begin{itemize}
    \item $L = \ceil{\log\log m} + 1$,
    \item \smash{$\delta = \frac{1}{\log^{10} m}$},
    \item $r_0 := 0$ and \smash{$r_\ell := r_{\ell-1} + \frac{D}{2^{L-\ell+3}} + \frac{D}{4 L}$} (for $1 \leq \ell \leq L$),
    \item \smash{$s_\ell := \min(2^{2^{L-\ell}}, m+1)$} (for $0 \leq \ell \leq L$).
\end{itemize}
With these parameters in mind, consider \cref{alg:ldd-fast}. The algorithm first deletes all edges with sufficiently large weight. Then it proceeds in $L$ iterations where in each iteration we apply \cref{lem:cut-light} to cut some edges in the graph (or reverse graph). If any of these calls returns ``fail'', then the entire algorithm restarts. In the following \cref{lem:ldd-fast-correctness,lem:ldd-fast-prob,lem:ldd-fast-time} we will show that this procedure correctly implements the algorithm claimed in \cref{thm:main-fast}.

\begin{algorithm}[t]
\caption{The near-linear-time near-optimal LDD, see \cref{thm:main-fast}.} \label{alg:ldd-fast}
\begin{enumerate}
    \item Initially let $S \subseteq E$ be the set of edges of weight at least $\frac{D}{4L}$, and remove these edges from $G$
    \item For $\ell \gets L, \dots, 1$:
    \begin{enumerate}
        \item[2.1.] Run \cref{lem:cut-light} on $G$ with parameters $\delta, r_{\ell-1}, r_\ell, s_{\ell-1}, s_{\ell}$, and let $S^+_\ell, R^+_\ell$ denote the resulting sets.
        \item[2.2.] Compute the strongly connected components in $(G \setminus S^+_\ell)[V \setminus R^+_\ell]$. Recur on each such component and add the recursively computed cut edges to $S$.
        \item[2.3.] Update $G \gets G[R^+_\ell]$ and $S \gets S \cup S^+_\ell$.
        \item[2.4.] Run \cref{lem:cut-light} on $\rev(G)$ with parameters $\delta, r_{\ell-1}, r_\ell, s_{\ell-1}, s_{\ell}$, and let $S^-_\ell, R^-_\ell$ denote the resulting sets.
        \item[2.5.] Compute the strongly connected components in $(G \setminus S^-_\ell)[V \setminus R^-_\ell]$. Recur on each such component and add the recursively computed cut edges to $S$.
        \item[2.6.] Update $G \gets G[R^-_\ell]$ and $S \gets S \cup S^-_\ell$.
    \end{enumerate}
    \item If any of the $2L$ previous calls to \cref{lem:cut-light} returns ``fail'', then we restart the entire algorithm (i.e., we reset $G$ to be the given graph, we reset $S \gets \emptyset$, and we start the execution from step~1).
\end{enumerate}
\end{algorithm}

\begin{lemma}[Correctness of \cref{alg:ldd-fast}] \label{lem:ldd-fast-correctness}
Let $u, v$ be two nodes lying in the same strongly connected component in $G \setminus S$. Then $d_G(u, v) \leq D$.
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 1}\end{proof}

\begin{lemma}[Edge Cutting Probability of \cref{alg:ldd-fast}] \label{lem:ldd-fast-prob}
For any edge $e \in E$, we have
\begin{equation*}
    \Pr(e \in S) \leq \Order\parens*{\frac{w_e}{D} \cdot \log n \log\log n + \frac{1}{\poly(n)}}.
\end{equation*}
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 2}\end{proof}

\begin{lemma}[Running Time of \cref{alg:ldd-fast}] \label{lem:ldd-fast-time}
The expected running time is $\Order(m \log^5 n \log\log n)$.
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 3}\end{proof}

We remark that we have not attempted to optimize the log-factors in the running time here and it is likely that the overhead can be reduced. An obvious improvement to shave one log-factor from the running time is to employ a faster priority queue in Dijkstra's algorithm, e.g.\ as developed by Thorup~\cite{Thorup03}.