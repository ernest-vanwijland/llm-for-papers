\documentclass[11pt,letterpaper,pdftex]{article}



\newif\ifsubmission
\submissionfalse


\usepackage{fullpage}





\usepackage[font=small,labelfont=bf]{caption}


\usepackage[dvips]{color}
\usepackage{xcolor}
\definecolor{DarkRed}{RGB}{150,0,0}
\definecolor{DarkGreen}{RGB}{0,150,0}
\definecolor{DarkBlue}{RGB}{0,0,150}
\definecolor{purple}{RGB}{200,0,200}
\usepackage[colorlinks=true,linkcolor=DarkRed,citecolor=DarkBlue,urlcolor=DarkGreen]{hyperref}
\usepackage[hyperpageref]{backref}


\usepackage{tikz}
\usetikzlibrary{shapes,positioning, arrows.meta}

\usepackage{beton}
\usepackage[T1]{fontenc}


\usepackage{mathptmx}
\usepackage{subfig}

\usepackage{bm}





\usepackage{paralist,tabularx}
\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage{latexsym}
\usepackage{enumerate}
\usepackage{mathtools}
\usepackage{wrapfig}


\usepackage{algorithm, algorithmicx, algpseudocode} 
\usepackage{algorithmicx}

\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage[algo2e]{algorithm2e}

\newtheorem{hypothesis}{Hypothesis}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}




	
\newcounter{definition}
\newenvironment{definition}[1][]{\refstepcounter{definition}\par\medskip
   \noindent \textbf{Definition~\thedefinition. #1} \rmfamily}{\medskip}	
\newenvironment{reminder}[1]{\smallskip
	\noindent {\scshape \textbf{Reminder of #1 }}\em}{
}

{\makeatletter
 \gdef\xxxmark{\expandafter\ifx\csname @mpargs\endcsname\relax \expandafter\ifx\csname @captype\endcsname\relax \marginpar{\textcolor{red}{\textbf{xxx}}}\else
       \textbf{\textcolor{red}{xxx}} \fi
   \else
     \textbf{\textcolor{red}{xxx}} \fi}
 \gdef\xxx{\@ifnextchar[\xxx@lab\xxx@nolab}
 \long\gdef\xxx@lab[#1]#2{\textbf{[\xxxmark \textcolor{{blue}#2} ---{\sc {\color{blue}#1}}]}}
 \long\gdef\xxx@nolab#1{\textbf{[\xxxmark \textcolor{blue}{#1}]}}
}


\newcommand{\rene}[1]{$\ll$\textsf{\color{cyan} Rene: { #1}}$\gg$}

\newcommand{\harry}[1]{$\ll$\textsf{\color{violet} Harry: { #1}}$\gg$}

\newcommand{\ailnote}[1]{$\ll$\textsf{\color{blue} Andrea: { #1}}$\gg$}
\newcommand{\andrea}{\ailnote}




\newcommand{\dOVm}{$\#$OV$^{\mu,d}$}

\newcommand{\kstr}{k^\star}
\newcommand{\Pclass}{\textit{P}}
\newcommand{\PSPACE}{\textit{PSPACE}}
\newcommand{\RandomSat}{\textsc{$k$-RandomSat }}
\newcommand{\HammDist}{\textsc{$\alpha$-LocalSearch}}
\newcommand{\Satis}{\textrm{Satisfaction}}
\newcommand{\ncs}{\textsc{NumClausesSAT}}
\newcommand{\ncus}{\textsc{NumClausesUnSAT}}
\newcommand{\nls}{\textsc{NumLiteralsSAT}}
\newcommand{\smlHDAlg}{\textsc{SAT-from-$\alpha$-Small-HD}}
\newcommand{\pprom}{p_{\textrm{promising}}}
\newcommand{\pbad}{p_{\textrm{bad}}}
\newcommand{\Sbad}{S_{\textrm{bad}}}
\newcommand{\DPa}{D_{pa}}
\newcommand{\DPc}{D_{pc}}

\newcommand{\ttildeo}{\tilde{o}}
\newcommand{\tO}{\tilde{O}}
\newcommand{\tTheta}{\tilde{\Theta}}
\newcommand{\tOmg}{\tilde{\Omega}}
\newcommand{\pgb}{P_{>\beta}}

\newcommand{\poly}{\text{poly}}
\newcommand{\polylog}{\text{polylog}}

\newcommand{\eps}{\epsilon}

\newtheorem{assumption}{Assumption}




\def \Z {\mathbb Z}
\def \R {\mathbb R}


\newcommand{\kOV}{$k$\mbox{-}OV}
\newcommand{\aczkc}{ACZ$k$C}
\newcommand{\zkc}{Z$k$C}
\newcommand{\ZKC}{\zkc}
\newcommand{\SOVH}{SOVH}
\newcommand{\kov}{\kOV}

\newcommand{\klcs}[1][]{\ifthenelse{\equal{#1}{}}{$k$-LCS}{${#1}$-LCS}}

\newcommand{\kwlcs}[1][]{\ifthenelse{\equal{#1}{}}{$k$-WLCS}{${#1}$-WLCS}}

\newcommand{\kNLstC}[1][]{\ifthenelse{\equal{#1}{}}{$k$-NLstC}{${#1}$-NLstC}}

\newcommand{\kELstC}[1][]{\ifthenelse{\equal{#1}{}}{$k$-ELstC}{${#1}$-ELstC}}


\newcommand{\czkc}[1][]{\ifthenelse{\equal{#1}{}}{FZ$k$C}{FZ${#1}$C}}


\newcommand{\czkch}[1][]{\ifthenelse{\equal{#1}{}}{FZ$k$CH}{FZ${#1}$CH}}

\newcommand{\cfkc}[1][]{\ifthenelse{\equal{#1}{}}{F$\mathfrak{f}k$C}{F$\mathfrak{f}{#1}$C}}

\newcommand{\cfkch}[1][]{\ifthenelse{\equal{#1}{}}{F$\mathfrak{f}k$CH}{F$\mathfrak{f}{#1}$CH}}

\newcommand{\fkkc}[1]{\ckkc[{#1}]}

\newcommand{\ckov}[1][]{\ifthenelse{\equal{#1}{}}{F$k$-OV}{F${#1}$-OV}}

\newcommand{\ckovh}[1][]{\ifthenelse{\equal{#1}{}}{F$k$-OVH}{F${#1}$-OVH}}



\newcommand{\cksum}[1][]{\ifthenelse{\equal{#1}{}}{F$k$-SUM}{F${#1}$-SUM}}

\newcommand{\cksumh}[1][]{\ifthenelse{\equal{#1}{}}{F$k$-SUMH}{F${#1}$-SUMH}}

\newcommand{\fksum}[1]{\cksum[{#1}]}

\newcommand{\fzkc}[1][]{\ifthenelse{\equal{#1}{}}{FZ$k$C}{FZ${#1}$C}}

\newcommand{\ckxor}[1][]{\ifthenelse{\equal{#1}{}}{F$k$-XOR}{F${#1}$-XOR}}

\newcommand{\ckxorh}[1][]{\ifthenelse{\equal{#1}{}}{F$k$-XORH}{F${#1}$-XORH}}

\newcommand{\fkxor}[1]{\ckxor[{#1}]}

\newcommand{\ckfunc}[1][]{\ifthenelse{\equal{#1}{}}{F$k$-$\mathfrak{f}$}{F${#1}$-$\mathfrak{f}$}}

\newcommand{\ckfunch}[1][]{\ifthenelse{\equal{#1}{}}{F$k$-$\mathfrak{f}$H}{F${#1}$-$\mathfrak{f}$H}}







\newcommand{\chpgh}{CHGHP}


\newcommand{\ckfunct}{\textrm{F}k\textrm{-}f}

\newcommand{\czt}{FZT}
\newcommand{\fzt}{FZT}
\newcommand{\NDMT}{PMT}
\newcommand{\pmt}{PMT}
\newcommand{\Unif}{\textsc{Unif}}


\newcommand{\erdosRen}{Erd{\H{o}}s-R{\'{e}}nyi }



\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}

\newcommand{\GoodPolys}{Good Low-Degree Polynomials}
\newcommand{\goodPoly}{good low-degree polynomial}
\newcommand{\gPol}[1]{GLDP(#1)}


\newcommand{\WGoodPolys}{Weak Good Low-Degree Polynomials}
\newcommand{\WgoodPoly}{weak good low-degree polynomial}
\newcommand{\WgPol}[1]{WGLDP(#1)}

\newenvironment{proofof}[1]{{\bf Proof of #1.  }}{\hfill$\Box$}



\newcommand{\txor}{$3$-XOR}
\newcommand{\kxor}[1][]{\ifthenelse{\equal{#1}{}}{$k$-XOR}{${#1}$-XOR}}

\newcommand{\tsum}{$3$-SUM}
\newcommand{\ksum}[1][]{\ifthenelse{\equal{#1}{}}{$k$-SUM}{${#1}$-SUM}}

\newcommand{\vtsum}{V$3$-SUM}
\newcommand{\vksum}[1][]{\ifthenelse{\equal{#1}{}}{V$k$-SUM}{V${#1}$-SUM}}

\newcommand{\subsampXOR}[2]{\Lambda^{XOR}_{{#1}\rightarrow{#2}}}
\newcommand{\subsampq}[2]{\Lambda^{\mathbb{F}_q}_{{#1}\rightarrow{#2}}}

\newcommand{\selfReduc}{\mathcal{A}}

\newcommand{\errAlg}[1]{\mathcal{E}_{{#1}}}
\newcommand{\LkJ}{LkJ}
\newcommand{\LKJ}{\LkJ}
\newcommand{\lkj}{\LkJ}

\newcommand{\ukov}[1][]{\ifthenelse{\equal{#1}{}}{U$k$-OV}{U${#1}$-OV}}
\newcommand{\nukov}[1][]{\ifthenelse{\equal{#1}{}}{NU$k$-OV}{NU${#1}$-OV}}
\newcommand{\ukxor}[1][]{\ifthenelse{\equal{#1}{}}{U$k$-XOR}{U${#1}$-XOR}}

\newcommand{\alg}{\mathcal{A}}

\newcommand{\GoodDPolys}[1][]{\ifthenelse{\equal{#1}{}}{Good $d$-Degree Polynomials}{Good ${#1}$-Degree Polynomials}}
\newcommand{\goodDPoly}[1][]{\ifthenelse{\equal{#1}{}}{good $d$-degree polynomial}{good ${#1}$-degree polynomial}}
\newcommand{\gDPol}[2]{G-${#1}$-DP(${#2}$)}

\newcommand{\OKPolys}[1][]{\ifthenelse{\equal{#1}{}}{Fine $d$-Degree Polynomials}{Fine ${#1}$-Degree Polynomials}}
\newcommand{\okPoly}[1][]{\ifthenelse{\equal{#1}{}}{fine $d$-degree polynomial}{fine ${#1}$-degree polynomial}}
\newcommand{\okPol}[2]{Fine-${#1}$-DP(${#2}$)}





\newcommand{\authnote}[3]{\textcolor{#3}{[{\footnotesize {\bf #1:} { {#2}}}]}}

\newcommand{\anote}[1]{\authnote{Andrea}{#1}{red}}

\def\edgepartitionc{E_{a_1,...,a_c}}
\def\gchosenlabels{G^{\ell_1,...\ell_{\binom{k}{c}}}}
\def\Otil{\tilde{O}}
\usepackage{thm-restate} \def\paritySAT{\mathsf{paritySAT}}
\def\paritykOV{\mathsf{parity}\text{-}k\text{-}OV}
\def\paritykSUM{\mathsf{parity}\text{-}k\text{-}SUM}
\def\paritykXOR{\mathsf{parity}\text{-}k\text{-}XOR}
\setcounter{page}{0}

\title{Worst-Case and Average-Case Hardness of\\
Hypercycle and Database Problems}

\author{
    Cheng-Hao Fu \thanks{Boston University, \texttt{chenghao@bu.edu}.}
    \and 
    Andrea Lincoln \thanks{Boston University, \texttt{andrea2@bu.edu}.}
    \and 
    Rene Reyes \thanks{Boston University, \texttt{rdreyes@bu.edu}. Supported by NSF Grant No. 2209194.}
}
\date{April 25, 2025}
\begin{document}

\maketitle
\thispagestyle{empty}
\begin{abstract}
In this paper we present tight lower-bounds and new upper-bounds for hypergraph and database problems. 
We give tight lower-bounds for finding minimum hypercycles. 
We give tight lower-bounds for a substantial regime of unweighted hypercycle. We also give a new faster algorithm for longer unweighted hypercycles. 
We give a worst-case to average-case reduction from detecting a subgraph of a hypergraph in the worst-case to counting subgraphs of hypergraphs in the average-case. 
We demonstrate two applications of this worst-case to average-case reduction, which result in average-case lower bounds for counting hypercycles in random hypergraphs and queries in average-case databases. Our tight upper and lower bounds for hypercycle detection in the worst-case have immediate implications for the average-case via our worst-case to average-case reductions.

 \end{abstract}

\thispagestyle{empty}
\newpage

\ifsubmission
\else
\pagenumbering{roman}
\tableofcontents
\newpage
\pagenumbering{arabic}
\fi 

\section{Introduction}
\label{sec:intro}
The fine-grained hardness of hypergraph problems is known to have interesting connections to both theoretical and practical problems in computer science. For example, hypergraph problems have deep connections to solving constraint satisfaction problems: algorithms for hypercycle problems in hypergraphs can be used to solve various Constraint Satisfaction Problems (CSPs), including Max-$k$-SAT \cite{LVW18}.
On the practical side, a recent line of work in database theory (initiated by Carmeli and Kr\"oll \cite{kroll2021}) has shown that certain queries of interest can be interpreted as problems about detecting, listing and counting small structures in hypergraphs.
Nevertheless, the fine-grained study of hypergraph problems remains largely under-explored, especially when compared to the volume of work on fine-grained hardness of graph problems.
In this paper, we aim to extend the understanding of hypergraphs in the average-case setting.
We focus on two main directions: the worst-case hardness of hypercycle problems and the average-case hardness of counting small subhypergraphs.

To our knowledge, this work is the first to show that the conditional hardness of hypercycle detection is dependent on both the length of the hypercycle and the size of the hyperedges.
This is somewhat surprising, given that for other problems, such as hyperclique detection, hardness is conjectured to depend only on the size of the hyperclique.
In the weighted case we get tight lower bounds for all hypercycle lengths.
In the unweighted case, we show that brute-force is necessary for  short hypercycles, resulting in tight upper and lower bounds. 
For the parameter regime where we can't show the brute force lower bound, we give a new faster algorithm for longer unweighted hypercycles using matrix multiplication. 
This shows the brute-force lower bound is actually false past the point where our reduction stops working.

For our average-case results, we build on a line of work that has used the error-correcting properties of polynomials to show average-case fine-grained hardness.
This technique, introduced by Ball et al. \cite{BallWorstToAvg} has already been applied to hypergraph problems by Boix-Adser\`a et al. \cite{UniformCliqueABB}, who show that counting small hypercliques in random hypergraphs where all hyperedges have the same size is as hard as in the worst-case.
In the graph setting, their approach was generalized by Dalirroyfard et al.\cite{factoredProblems} who showed similar worst-case-to-average-case reductions for counting any small subgraph.
We further generalize their result to show that this is true for counting small subhypergraphs in random hypergraphs, including ones where the hyperedges have different sizes.
The worst-case to average-case reduction also allows us to prove that counting queries on random databases are hard on average.

These two results are highly complementary.
Applying our worst-case-to-average-case reduction to our hypercycle hardness results immediately gives us average-case hardness of hypercycle problems.
Furthermore, understanding the worst-case hardness of other hypergraph substructures would shed light on what types of counting queries are hard on average.
Finally, in the process of exploring these areas, we have found many new avenues to explore, which range from understanding the parameter regimes where we do not get tight upper and lower bounds to improving some generic techniques from traditional worst-case reductions.

\subsection{Hypercycle Algorithms and Lower Bounds}

A $k$-hypercycle in a $u$-uniform hypergraph is a list of $k$ distinct nodes $v_1, \ldots, v_k$ such that every hyperedge of $u$ adjacent nodes exists in the hypergraph. 
That is, a $k$-hypercycle consists of the edges $(v_i, \ldots, v_{i+u-1 \mod k})$ for all $i \in [k]$.
In the literature, this is often called a tight hypercycle, but we will omit the `tight' and call these hypercycles throughout this paper (following the norm of \cite{LVW18}). 

We demonstrate new algorithms and conditional lower bounds for the minimum hypercycle and unweighted hypercycle problems.
Our upper and lower bounds for minimum hypercycle are tight, as shown in Figure \ref{fig:weightedHypercycleBounds}.
In the unweighted case, we show that the hardness of hypercycle detection depends on the relationship between the hyperedge size and hypercycle length, as shown in Figure \ref{fig:unweightedHypercycleBounds}.
The conditional lower bounds are derived from the minimum $k$-clique hypothesis and the $(k, u)$-hyperclique hypothesis:


\begin{definition}[MIN WEIGHT k-CLIQUE HYPOTHESIS (e.g. \cite{AbboudWW14,BackursT17})] 
\label{def:minClique}There is a constant $c > 1$ such that, on a Word-RAM with $O(\log(n))$-bit words, finding a $k$-Clique of minimum total edge weight in an $n$-node graph with non-negative integer edge weights in
$[1,n^{ck}]$ requires $n^{k-o(1)}$ time.
\end{definition}

\begin{definition}[$(k, u)$-HYPERCLIQUE HYPOTHESIS \cite{LVW18}]
\label{def:hypercliqueHypothesis}
Let $k > u > 2$ be integers. On a Word-RAM with $O(\log(n))$ bit
words, finding a $k$-hyperclique in a 
$u$-uniform hypergraph on $n$ 
nodes requires $n^{k-o(1)}$ time.
\end{definition}

As evidence for this hypothesis, \cite{LVW18} give a reduction from the maximum degree-$u$-CSP problem to the $(k,u)$-hyperclique problem. 
They also give a reduction from hyperclique detection to hypercycle detection.
The hard instances output by this reduction only cover a specific hypercycle length $k$ for each uniformity $u$ and this seems inherent to the technique.
A natural question to ask is whether the hardness of finding $k$-hypercycles in $u$-uniform hypergraphs depends on the relationship between $u$ and $k$.
We answer this question in the affirmative for both weighted and unweighted hypercycle problems.
This is surprising since the hardness of other hypergraph problems such as $(k,u)$-hyperclique is conjectured to be independent of this relationship.

For min-weight $k$-hypercycle, we show that brute-force is required when $k$ is less than $2u-1$.
When $k \geq 2u-1$, we give an algorithm with runtime independent of $k$.
For unweighted hypercycle, we show that brute force is needed for all $k$ up to the length of the instances output by the \cite{LVW18} reduction.
For longer hypercycles, we show this is not the case by giving novel algorithms which use matrix multiplication to get a speedup.

We now provide a more detailed overview of our techniques along with formal theorem statements for our upper and lower bounds.






\subsubsection{Weighted Hypercycle}
In Section \ref{sec:tight_weighted} we give the results for weighted hypercycle, depicted in Figure \ref{fig:weightedHypercycleBounds}. 
The matching lower bounds come from a reduction between cliques in graphs (2-uniform hypergraphs) and hypercycles. Informally the minimum $k$-clique hypothesis states that finding a minimum $k$-clique in a graph can't be done faster than the naive algorithm which takes $n^{k-o(1)}$ time (see definition \ref{def:minClique}). We prove the following. 
\begin{restatable}{theorem}{weightedCycleLB}
    If the minimum $k$-clique hypothesis holds then the minimum $k$-hypercycle problem in a $u$-uniform hypergraph requires $n^{k-o(1)}$ time for $k \in [u+1 , 2u-1]$. 
\end{restatable}

\begin{figure} [ht]
    \centering
    \begin{tikzpicture}
\definecolor{shadecolor}{rgb}{1,0.5,0.5}

\draw[->] (0,0) -- (8,0) node[anchor=north] {Hyper-Cycle length};
    \draw[->] (0,0) -- (0,5) node[anchor=east] {Running time $\log_n$};

\fill[shadecolor] (0,0) -- (4,4) -- (4,0) -- cycle;

\draw[thick] (0,0) -- (4,4) -- (7,4);

\draw[red, thin] (1,0) -- (1,1);
    \draw[red, thin] (2,0) -- (2,2);
    \draw[red, thin] (3,0) -- (3,3);
    \draw[red, thin] (4,0) -- (4,4);
    \draw[red, thin] (1,1) -- (4,1);
    \draw[red, thin] (2,2) -- (4,2);
    \draw[red, thin] (3,3) -- (4,3);

\node[anchor=north] at (0,-0.2) {$u$};
    \node[anchor=north] at (4,-0.2) {$2u-1$};
    \node[anchor=east] at (-0.2,4) {$2u-1$};

\end{tikzpicture}
    \caption{The running time of minimum weight hyper-cycle in a weighted $u$-uniform hyper-graph. The exponent of the running time is indicated by the black line and the lower bound is matching, as indicated by the hatched red area. Note the running time is $O(n^u)$ for a $u$ length hyper-cycle and $O(n^{2u-1})$ for a $2u-1$ length hyper-cycle. Then for all hyper-cycles of length $k>2u-1$ the running time continues to be $O(n^{2u-1})$.}
    \label{fig:weightedHypercycleBounds}
\end{figure}

\subsubsection{Unweighted Hypercycle} 

For the unweighted version of the problem we get tight upper and lower bounds in a $u$-uniform graph for all $k \leq \gamma_3^{-1}(u)$, where we define $ \gamma_3(k) = k-\lceil k/3 \rceil +1$ as is done in \cite{LVW18} and $k = \gamma_3^{-1}(u)$ is the \emph{largest} $k$ such that $\gamma_3(k)=u$.
Intuitively, this is the largest $k$ such that any three nodes in the hypercycle are covered by at least one hyperedge of size $u$, which happens when $k \approx 3u/2$. 
For larger hypercycles where $k \geq \gamma_3^{-1}(u)+1$, we can pick three partitions such that no hyperedge covers all three. 
This property allows us to reduce the problem to triangle-counting and then use matrix multiplication to obtain an algorithmic speedup.
This algorithm, given in Section \ref{sec:ub_unweighted}, runs in time $n^{k-3+\omega}$ where $\omega$ is the matrix multiplication constant. 
We depict the upper and lower bounds for unweighted hypergraphs in Figure \ref{fig:unweightedHypercycleBounds}.


We get tight lower bounds for hypercycle up to the ``phase transition'' point at $ \gamma_3(k)$. These lower bounds come from the $(u,k)$-hyperclique hypothesis. Informally, this says detecting a $k$-hyperclique in a $u$-uniform hypergraph if $k > u > 2$ requires $n^{k-o(1)}$ (see Definition \ref{def:hypercliqueHypothesis}).  We prove the following theorem in section \ref{subsec:tighthardnessshorthypercycles}.

\begin{restatable}{theorem}{tightShortHypercycle}\label{thm:tight short hypercycle}
    Under the $(3,k)$-hyperclique hypothesis, an algorithm for finding (counting)  $(u,k)$-hypercycle for $k \in [u,\gamma_3^{-1}(u)]$ requires $O(n^{k-o(1)})$ time.
\end{restatable}

When $k > \gamma_3(k)$ we show an algorithm which is better than brute force by a factor dependent on $\omega$ (where $\omega$ is the matrix multiplication constant). 
\begin{restatable}{theorem}{fastCycleDetect} \label{thm:fastCycledetect}
    There exists a time-$\tilde{O}(k^k(n+m+n^{2u-1-(3-\omega)}))$ algorithm for finding $k$-hypercycles in any $n$-node hypergraph $G$ when $k \geq 2u-1$. 
\end{restatable}

Proving conditional lower bounds in this regime might unexpectedly imply conditional lower bounds on $\omega$.
In short, we get tight lower bounds for all values of $k$ where lower bounds wouldn't have implications for matrix multiplication's running time, $\omega$.

\begin{figure} [ht]
    \centering
        \begin{tikzpicture}
\definecolor{shadecolor}{rgb}{1,0.5,0.5}
    \definecolor{linecolor}{rgb}{1,0,1}

\draw[->] (0,0) -- (10,0) node[anchor=north] {Hyper-Cycle length};
    \draw[->] (0,0) -- (0,8) node[anchor=east] {Running time $\log_n$};

\fill[shadecolor] (0,0) -- (3,3) -- (3,0) -- cycle;

\draw[thick] (0,0) -- (3,3);
    \draw[thick] (3,3) -- (4,3.4);
    \draw[thick] (4,3.4) -- (7,6.4);
\draw[thick] (7,6.4) -- (9.5, 6.4);

\draw[dotted, thick] (3,3) -- (4,3) -- (7,6) -- (9.5,6);

\draw[red, thin] (1,0) -- (1,1);
    \draw[red, thin] (2,0) -- (2,2);
    \draw[red, thin] (3,0) -- (3,3);
    \draw[red, thin] (1,1) -- (3,1);
    \draw[red, thin] (2,2) -- (3,2);

\node[anchor=north] at (0,-0.2) {$u$};
    \node[anchor=north] at (3,-0.2) {$\gamma_3^{-1}(u)$};
    \node[anchor=north] at (7,-0.2) {$2u-1$};

    \node[anchor=east] at (-0.2, 3) {$\gamma_3^{-1}(u)$};
    \node[anchor=east] at (-0.2,6.4) {$2u-1+(3-\omega)$};

    \end{tikzpicture}
    \caption{The running time of \textit{unweighted} hyper-cycle in a $u$-uniform hyper-graph. The exponent of the running time is indicated by the black line. The lower bound is matching for the hatched red area from cycles of length $u$ to $\gamma_3^{-1}(u)$ and the running time is $O(n^k)$ for a $k$-hypercycle. Then from $\gamma_3^{-1}(u)$ to $2u-1$ the running time is $\tilde{O}(n^{k-3+\omega})$ for $k$-hypercycle where $\omega$ is the matrix multiplication constant ($\omega < 2.3716$ \cite{mmConstantOmega}). The dotted line represents the running time the algorithm would achieve if $\omega=2$. There is an algorithm running in $\tilde{O}(n^{2u-1-(3-\omega)})$ time for all $k \geq 2u-1$. The shading stops after $\gamma_3^{-1}(u)$ because we don't know of any tight lower bounds past this point. }
    \label{fig:unweightedHypercycleBounds}
\end{figure}


\subsubsection{Average-Case Implications}
We can apply our worst-case to average-case reduction techniques to get lower bounds for random hypergraphs. 
Notably, for constant-length unweighted-hypercycle, the hardness of counting in the worst-case is equivalent to the hardness in the average-case up to polylog factors. 
This gives tight upper and lower bounds for the average-case hardness of counting $k$-hypercycles in the same regime of cycle length for a given uniformity when $k \leq \gamma_3^{-1}(u)$. Informally, if the $(3,k)$-hyperclique hypothesis holds then counting $k$-hypercycles in $u$-uniform Erd{\H{o}}s-R{\'{e}}nyi hypergraphs when $k \in [u, \gamma_3^{-1}(u)]$ requires $\tilde{O}(n^{k-o(1)})$ time. We prove this in Section \ref{sec:lb_unweighted}.


\subsection{Counting Subhypergraphs on Average is as Hard as Detecting them in the Worst Case }
To enable our average-case results for databases and for counting hypercycles we provide a new reduction. 
Our reduction can handle non-uniform hypergraphs, meaning hypergraphs with edges of \emph{different} sizes (see Figure \ref{fig:exampleOfSmallGraph}).
This is necessary for the results to apply to the databases setting.
We transform the problem into a low degree polynomial and use a known framework to show average-case hardness. 

However, to get back to average-case graphs that aren't color-coded we use a new form of inclusion exclusion. 
Prior work introduced inclusion-edgesculsion \cite{LVW18}. 
We present a simultaneously generalized and simplified proof which allows us to show hardness for counting these subhypergraphs in uniformly randomly sampled hypergraphs (even those where there are mixed hyperedge sizes). 

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}

\node[draw, circle] (A) at (0,0) {A};
\node[draw, circle] (B) at (2,0) {B};
\node[draw, circle] (C) at (1,2) {C};
\node[draw, circle] (D) at (3,2) {D};
\node[draw, circle] (E) at (4,0) {E};

\draw (A) -- (B);
\draw (B) -- (C);
\draw (C) -- (D);
\draw (B) -- (D);


\draw[red, thick] (1,0.7) circle [radius=1.7];

\draw[blue, thick] (2.5, 1) circle [radius=2.2];



\end{tikzpicture}
    \caption{An example of a small subgraph with hyperedges of multiple different sizes. This graph contains hyperedges $\{A,B\}, \{B,C\}, \{B, D\}, \{C, D\}, \{A,B,C\},$ and $\{B,C,D,E\}$. We depict the $3$-width edge as a red circle, the $4$-width edge as a blue circle, and the $2$-width edges as black lines.}
    \label{fig:exampleOfSmallGraph} 
\end{figure}

\begin{theorem} [Informal]\label{thm: informal wc to ac}
Let $k$ be a constant. 
Counting the number of $k$-node hypergraphs $H$ made up of nodes $v_1,\ldots, v_k$ in $k$-partite hypergraphs $G$ with partitions $V_1, \ldots, V_k$ in the worst case where we only count copies of $H$ where $v_i \in V_i$ can be solved with polylog calls to a counter for hypergraphs $H$ in uniformly random hypergraphs.
\end{theorem}

Via color-coding this means that if detecting a hypergraph $H$ in the worst case is $T(n)$ hard then counting that hypergraph in the uniform average-case is hard. So, starting from the hardness of either detection or the counting problem in a $k$-partite graph implies the hardness of the counting problem in the uniform average-case. 

These approaches allow us to show hardness for database problems and the problem of counting subhypergraphs. We demonstrate the usefulness of the improved approach by showing its applications to these two problem areas.

\subsection{Database Results}
We now provide a high-level introduction to the databases setting we are interested in. For full definitions of these problems, see Section \ref{sec:database}. 
A table in a database is called a relation. 
A relation, $R_i$, is a set of tuples. 
For example, a relation on $(user\_id, user\_name)$ would be a set of tuples grouping user ids and user names. 
A database may have many relations, and the relations may have tuples of different sizes (e.g. the example database could also include a table of $(user\_id, purchase\_id, purchase\_date)$). 

Queries over a database can take many forms, but a classic form is a join query. 
To be concrete, if we have a table with two relations $R_1(a,b)$ and $R_2(a,c,d)$ then we can have a query $Q_1(a,b,c,d) \leftarrow R_1(a,b), R_2(a,c,d)$. 
If we ask to enumerate all answers to $Q_1$ then we want all tuples $(a',b',c',d')$ such that $(a',b') \in R_1$ and $(a',c',d')\in R_2$. 
Some query types (e.g. `FIRST' in SQL) ask to give a single answer. 
In this paper we will focus on queries that ask to count the number of matching outputs in the query (e.g. `COUNT' in SQL). 
In database theory, enumeration queries are the most studied.
While these queries are often trivial in the average-case, non-enumerating query types are still often hard-on-average.
See Appendix \ref{subsec:whyEnumIsEasy} for more discussion of enumeration and counting on average. 

You might notice that relations look like lists of hyperedges and queries look like requests to enumerate, detect, or count subhypergraphs of the implied hypergraph. 
However, these database ``hyperedges'' are directed. 
The tuple $('Jane', 'Doe')$ and $('Doe', 'Jane')$ have different meanings, whereas in an undirected hypergraph the edges are simply sets. 
However, these problems are similar enough that we can apply analogous worst-case to average-case reduction techniques to show hardness on average for these database problems. 

We now work through an example to help solidify the similarity between databases and hypergraphs.
The hypergraph from Figure \ref{fig:exampleOfSmallGraph} could be represented as a database by the following list of relations: 
$$R_1(A,B), R_2(B,C), R_3(B, D), R_4(C, D), R_5(A,B,C), R_6(B,C,D,E).$$
Then, to count the number of appearances of the hypergraph from Figure \ref{fig:exampleOfSmallGraph} within the hypergraph representing the entire database, we could make the following query:
$$Q_1(A,B,C,D,E) \leftarrow R_1(A,B), R_2(B,C), R_3(B, D), R_4(C, D), R_5(A,B,C), R_6(B,C,D,E).$$ 

A natural question for databases is this: how hard are queries on uniformly random databases? 
If our real world case involves uniformly distributed data, when can we hope to find algorithmic improvements?
We answer this question by giving lower bounds for counting queries in Section \ref{sec:database} and explaining why \emph{small} enumeration queries will be easy in Appendix \ref{sec:appendix_discussion}. 

\subsection{Context and Prior Works}

There has been a lot of work on average-case fine-grained complexity. Ball et al. 
\cite{BallWorstToAvg} showed that starting from popular fine-grained hypotheses, evaluating certain functions could be shown to be hard on average. Later Ball et al. \cite{BallRSV18} showed that you can build a fine-grained proof of work using these functions. 
\cite{UniformCliqueABB} showed that there is an equivalence, up to polylog factors, between counting constant sized hypercliques in the worst-case and in the average-case of  Erd{\H{o}}s-R{\'{e}}nyi Hypergraphs. 
Goldreich presented an alternative method to count cliques mod 2 \cite{Goldreich20}. 
Dalirrooyfard et al. \cite{factoredProblems} generalized these ideas and presented a method to produce a worst-case to average-case reduction for any problem which can be represented by a `good' low degree polynomial.
Additionally they showed that counting small subgraphs (not just cliques) is equivalently hard in the worst-case and in Erd{\H{o}}s-R{\'{e}}nyi graphs. 
In this paper we further generalize this result to the hypergraph setting.
Specifically, we show that counting small sub\textbf{hyper}graphs is equivalently hard in the worst-case and average-case. 
We also give worst-case to average-case hardness for many classes of \textbf{counting database queries}. 
Our contributions include expanding the previous results and connecting fine-grained average-case complexity to database theory. 


Recently, the database theory community has had increased interest in the fine-grained hardness of various database queries. 
This is highlighted by many recent papers in the area. 
Carmeli and KrÃ¶ll \cite{kroll2021} use fine-grained hypotheses to show that answering unions of conjunctive queries are hard.
Carmeli and Segoufin \cite{selfJoinsHard2023} explore the fine-grained complexity of enumeration queries with self joins. 
Bringman et. al. \cite{tightFineGrainedCarmeli} characterize the amount of preprocessing time needed to get polylogarithmic access time. 
We will show that for counting queries over a constant number of relations that don't involve self-joins, the worst-case and average-case hardness are equivalent up to polylogarithmic factors.

Carmeli et al \cite{CarmeliTGKR23} eschew enumeration to explore  logarithmic time access to the $k^{th}$ answer to a conjunctive query after a quasi-linear database preprocessing. 
They provide fast algorithms for these problems.
Recent work from Wang, Willsey, and Suciu \cite{WangWS23} proposed a \emph{free join} which achieves worst-case optimality. 
These are algorithms where the runtime matches the worst-case output size. 
As we explore counting queries where the output size is a single word, $O(\lg(n))$ bits, worst-case optimality is impossible as long as the full input must be read to answer the query. 
We thus focus on efficiency more generally. 
A 2023 Simons program on Logic and Algorithms in Database Theory and AI ran a workshop on Fine-Grained Complexity, Logic, and Query Evaluation\cite{simons_fine_grained_complexity_2023}. 
In this workshop, the open problem of the average-case hardness of database queries was brought up in the open problem session on September 27th. 
In this paper we have explored and proved this average-case hardness for many kinds of counting queries in databases. 
In this paper we seek to give a new definition of an average-case for database theory and provide a worst-case to average-case reduction using fine-grained complexity techniques. 

Hypercycles (``tight hypercycles'' in much of the literature) have been well-studied in both math and computer science. 
Allen et. al. \cite{allen2015tight} showed that for $k$-hypercycles in a $u$-uniform graph where $k \equiv 0 \mod u$ must exist if there are at least $(k/n + \delta)\binom{n}{u}$ hyperedges for some constant $\delta>0$ . 
It is unclear if when $\delta = \Theta(1/n)$ you can still guarantee a hypercycle exists. In this paper we show hardness for $k < 2u$, where these results do not apply. 
Huang and Ma \cite{tightCyclesHypergraphsExistance} continued the exploration of this existential hypercycle question, showing that, in some sense, the previous result is tight up to constants. 
Later, Allen et al. \cite{AllenKPP18} gave a faster algorithm for tight Hamiltonian hypercycles in random graphs, that is in average-case graphs. 
The results in our paper rely on $k$ being small, for larger $k$ the worst-case to average-case reduction becomes increasingly expensive. 
So their work and ours shows an interesting dynamic where short cycles have more similar hardness in the worst-case and average-case and there is a divergence as the cycle length grows.
Lincoln, Vassilevska and Williams \cite{LVW18} give a reduction from max-$k$-SAT to hypercycle and then to cycle. 
However, their results for cycle are not tight. 
They give a bound of $m^{3/2-o(1)}$ for $k$-cycle. They give a tighter bound for $7$-cycle of $m^{7/5-o(1)}$ in graphs with $m = n^{5/4}$. 
In theorem C.1 they show a lower bound for hypercycle. 
However, this is \textit{dense} hypercycle. 
In our paper we present\textit{ tight} bounds for sparse hypercycle. 
We also present a new faster algorithm for unweighted hypercycle. 
Our weighted lower bounds are tight. 
Our unweighted lower bounds are tight until the regime where matrix multiplication is used in the fastest algorithm. 

\subsection{Paper Structure}

We present the basic background and definitions in Section \ref{sec:prelims}. 
We show tight lower bounds for hypercycles in Section \ref{sec:lb_unweighted}. 
We give fast algorithms for hypercycles in Section \ref{sec:ub_unweighted}. 
We give the tight upper and lower bounds for minimum hypercycle in Section \ref{sec:tight_weighted}. 
We give the worst-case to average-case reduction for counting subhypergraphs in Section \ref{sec:wc_to_ac}. 
We show the average-case hardness for (self-join-free) counting queries in Section \ref{sec:database}. 
We present open problems in Section \ref{sec:conc_and_open_prob}. 
Finally, we include extra discussion in Appendix \ref{sec:appendix_discussion}. 
\section{Preliminaries}
\label{sec:prelims}
In this paper we combine ideas and techniques from average-case fine-grained complexity, databases, and worst-case fine-grained complexity and algorithms. As a result we will mostly define the needed terms in the corresponding sections. Our preliminaries are short and focus on hypergraphs as these appear in most sections.

\begin{definition}
    A $u$-uniform hypergraph $G$ has a vertex set $V$ and a set of hyperedges $E$ where each hyperedge is a set of $u$ vertices from $V$. 

    A hypergraph of mixed sizes with hyperedge set sizes of $u_1, \ldots, u_k$ has a vertex set $V$ and a set of hyper edges $E$ where each hyperedge is a set of vertices from $V$ and the size of that set must be $u_1, \ldots,$ or $ u_k$.
\end{definition}

\begin{definition}
    A tight $k$-hypercycle in a $u$-uniform hypergraph $G$ is a list of $k$ nodes $v_1, \ldots, v_k \in V$ where every hyperedge
    $$(v_i, v_{i+1 \mod k}\ldots, v_{i+u-1 \mod k})$$
    exists in $E$. That is, every hyperedge of $u$ adjacent vertices on the cycle exists.
\end{definition}





\begin{definition}
    A $k$-hypercycle in a $u$-uniform hypergraph $G$ is a list of $k$ nodes $v_1, \ldots, v_k \in V$ where every hyperedge $(v_{i_1},\ldots, v_{i_u})$ where $i_j \in [1,k]$ exists $E$. That is, every possible hyperedge between the $k$ nodes exists in the graph. 
\end{definition}


\begin{figure}[ht]
\centering
\begin{tikzpicture}[scale=1.0, every node/.style={circle,draw,inner sep=1pt}]

\node[draw=none] at (0.5,3.7) {\Large $H$};

\node (t1) at (0,2) {};
\node (t2) at (1,2) {};
\node (t3) at (0,1) {};
\draw (t1)--(t2)--(t3)--cycle;

\node (b1) at (0,0) {};
\node (b2) at (1,0) {};
\node (b3) at (1,-1) {};
\node (b4) at (0,-1) {};
\draw (b1)--(b2)--(b3)--(b4)--cycle;

\node[draw=none] at (5,3.7) {\Large Example of an $H$-partite Graph};

\begin{scope}[xshift=4.5cm, yshift=1.3cm]
\foreach \i in {1,...,4} {
    \node (A\i) at (-1,1.6-0.5*\i) {};
  }
  \foreach \i in {1,...,4} {
    \node (B\i) at (0,1.6-0.5*\i) {};
  }
  \foreach \i in {1,...,4} {
    \node (C\i) at (1,1.6-0.5*\i) {};
  }

\foreach \i in {1,...,4} {
    \foreach \j in {1,...,4} {
      \draw (A\i)--(B\j);
      \draw (B\i)--(C\j);
      \draw (A\i)--(C\j);
    }
  }

\draw[dotted] (-1,0.8) ellipse (0.4cm and 1.2cm);
  \draw[dotted] ( 0,0.8) ellipse (0.4cm and 1.2cm);
  \draw[dotted] ( 1,0.8) ellipse (0.4cm and 1.2cm);
\end{scope}

\begin{scope}[xshift=4.5cm, yshift=-1.8cm]
\foreach \i in {1,...,4} {
    \node (P\i) at (-1.5,1.6-0.5*\i) {};
  }
  \foreach \i in {1,...,4} {
    \node (Q\i) at (-0.5,1.6-0.5*\i) {};
  }
  \foreach \i in {1,...,4} {
    \node (R\i) at (0.5,1.6-0.5*\i) {};
  }
  \foreach \i in {1,...,4} {
    \node (S\i) at (1.5,1.6-0.5*\i) {};
  }

\foreach \i in {1,...,4} {
    \foreach \j in {1,...,4} {
      \draw (P\i)--(Q\j);
      \draw (P\i)--(R\j);
      \draw (P\i)--(S\j);
      \draw (Q\i)--(R\j);
      \draw (Q\i)--(S\j);
      \draw (R\i)--(S\j);
    }
  }

\draw[dotted] (-1.5,0.8) ellipse (0.4cm and 1.2cm);
  \draw[dotted] (-0.5,0.8) ellipse (0.4cm and 1.2cm);
  \draw[dotted] ( 0.5,0.8) ellipse (0.4cm and 1.2cm);
  \draw[dotted] ( 1.5,0.8) ellipse (0.4cm and 1.2cm);
\end{scope}

\end{tikzpicture}

\caption{An example of two small graphs and corresponding $H$-partite graphs. }
\label{fig:Hpartite}
\end{figure}

In this paper we use the term $k$-hypercycle to refer to a tight $k$-hypercycle. We use these concepts throughout the paper. We also use a more general notion of a subgraph of a hypergraph. 

\begin{definition}
    A subhypergraph or subgraph of a hypergraph $G$ (the hypergraph could have mixed uniformity or not) is a graph $H$ whose vertex set and edge set is a subset of $G$'s vertex and edge set. That is, if $H$ has a vertex set $V_H$ and edge set $E_H$ then $H$ is a subgraph of $G$ if $V_H \subset V$ and $E_H \subset E$.
\end{definition}



\begin{theorem}[Theorem 3.1 from \cite{LVW18}] \label{thm:hclique_to_hcycle}


    Let $G$ be a $u$-uniform hypergraph on $n$ vertices $V$, partitioned into $k$ parts $V_1,\ldots,V_k$. 
    
    Let $\gamma_u(k)=k-\lceil k/u\rceil +1$.
    
    In $O(n^{\gamma_u(k)})$ time we can create a $\gamma_u(k)$-uniform hypergraph $G'$ on the same node set $V$ as $G$, so that $G'$ contains an $k$-hypercycle if and only if $G$ contains an $k$-hyperclique with one node from each $V_i$.
    
    If $G$ has weights on its hyperedges in the range $[-W,W]$, then one can also assign weights to the hyperedges of $G'$ so that a minimum weight $k$-hypercycle in $G'$ corresponds to a minimum weight $k$-hyperclique in $G$ and every edge in the hyperclique has weight between $[-\binom{\gamma_u(k)}{u}W,\binom{\gamma_u(k)}{u}W]$. Notably, $\binom{\gamma_u(k)}{u}\leq O(k^u)$.
\end{theorem}

For intuition on this theorem see Appendix \ref{subsec:prevCliquetoCycle}.

\begin{definition}[From  \cite{factoredProblems}]
Let $H=(V_H,E_H)$ be a $k$-node graph with $V_H=\{x_1,\ldots,x_k\}$. 

An $H$-partite graph is a graph with $k$ partitions $V_1,\ldots,V_k$. This graph must only have edges between nodes $v_i \in V_i$ and $v_j \in V_j$ if e $(x_i,x_j)\in E_H$. (See Figure \ref{fig:Hpartite} in the appendix.)
\end{definition}















%
 
\section{Short Unweighted Hypercycles Require Brute-Force}
\label{sec:lb_unweighted}


We will begin by showing that short hypercycles are tightly hard. We will do so for hypercycles of lengths at most $\gamma_3^{-1}(u)$. Recall that $\gamma_3(k) = k - \lceil k/3 \rceil +1$, so $\gamma_3^{-1}(u) \approx 3u/2$.  On an intuitive level $\gamma_3^{-1}(u)$ corresponds to the largest length of cycle such that all sets of three nodes are included in at least one hyperedge. In this section we will show that given this constraint, the best algorithm for $k$-hypercycle is the naive brute force $n^k$ algorithm. In the next section we will show that if the cycle length is even one larger than $\gamma_3^{-1}(u)$, then we can beat brute force using fast matrix multiplication. In this sense our brute force lower-bound is tight, we couldn't extend the brute force lower bound to cycles of any longer length. 


Our lower bounds are based on the min-weight $k$-clique and $(u,k)$-hyperclique hypotheses, which states that these problems require $O(n^{k-o(1))})$ time (see Definition \ref{def:hypercliqueHypothesis}). 
We use a reduction from \cite{LVW18} to show hardness for our hypercycle problems; to make this work self-contained, we now give the necessary intuition.

\subsection{Reduction from k-clique}
\label{subsec:prevCliquetoCycle}

Our lower bounds are based on the min-weight $k$-clique and $(u,k)$-hyperclique hypotheses, which states that these problems require $O(n^{k-o(1))}$ time (see Definition \ref{def:hypercliqueHypothesis}).
We will use a reduction from \cite{LVW18} to show hardness for our hypercycle problems.

\begin{theorem}[Theorem 3.1 from \cite{LVW18}] 


    Let $G$ be a $u$-uniform hypergraph on $n$ vertices $V$, partitioned into $k$ parts $V_1,\ldots,V_k$. 
    
    Let $\gamma_u(k)=k-\lceil k/u\rceil +1$.
    
    In $O(n^{\gamma_u(k)})$ time we can create a $\gamma_u(k)$-uniform hypergraph $G'$ on the same node set $V$ as $G$, so that $G'$ contains an $k$-hypercycle if and only if $G$ contains an $k$-hyperclique with one node from each $V_i$.
    
    If $G$ has weights on its hyperedges in the range $[-W,W]$, then one can also assign weights to the hyperedges of $G'$ so that a minimum weight $k$-hypercycle in $G'$ corresponds to a minimum weight $k$-hyperclique in $G$ and every edge in the hyperclique has weight between $[-\binom{\gamma_u(k)}{u}W,\binom{\gamma_u(k)}{u}W]$. Notably, $\binom{\gamma_u(k)}{u}\leq O(k^u)$.
\end{theorem}

\begin{figure}[ht]
    \centering

\begin{tikzpicture}[scale=1]

\node[circle, draw, thick] (n1) at (90:2) {};
\node[circle, draw, thick] (n2) at (45:2) {};
\node[circle, draw, thick] (n3) at (0:2) {};
\node[circle, draw, thick] (n4) at (315:2) {};
\node[circle, draw, thick] (n5) at (270:2) {};
\node[circle, draw, thick] (n6) at (225:2) {};
\node[circle, draw, thick] (n7) at (180:2) {};

\draw[thick] (n1) circle (0.3);
\draw[thick] (n3) circle (0.3);
\draw[thick] (n5) circle (0.3);

\draw[dashed, thick, blue] (n1) ++(110:1) arc[start angle=100, end angle=-50, radius=2.6];

\draw[dashed, thick, violet] (n1) ++(90:1) arc[start angle=90, end angle=270, radius=2.8];


\draw[dashed, thick, red] (90:2.2) ++(105:1) arc[start angle=95, end angle=-100, radius=3];


\end{tikzpicture}
    \caption{The case of $k=7$ where we start with a $3$-uniform graph. The double circles indicate the `farthest apart' three nodes can be. Note the purple and blue arcs indicate the furthest a uniformity $4$ hyperedge can go while including the top node, and that neither hyperedge includes all three double circled nodes. Further note that the red edge, which is a hyperedge of uniformity $5$, covers all three double circled nodes. This is what $\gamma(\cdot)$ is capturing. }
    \label{fig:smallExampleGamma}
\end{figure}

To give the reader context and intuition we will explain the core ideas of this previous work. The main idea behind this reduction is to output $k$-partite hypergraphs such that the vertex partitions can be arranged in a circle and hyperedges only exist between adjacent partitions.
Then, the value $\gamma_u(k)$ corresponds to the smallest edge uniformity such that this type of edge will cover any possible subset of $u$ vertex partitions.
This allows this more restricted type of hyperedge to capture information about any possible hyperedge in the original $u$-uniform hypergraph. See Figure \ref{fig:smallExampleGamma} for a small illustrative example. 


 
While this reduction shows a relationship between the hardness of hypercycle detection and hypercliques, it is important to observe that it requires a very specific uniformity $\gamma_u(k)$.
A natural question to ask is: what happens for other combinations of $u$ and $k$?



We show that the hardness varies based on the relationship between uniformity $u$ and cycle length $k$.
Note that for fixed $u$ and sufficiently large constant $k$, algorithms for finding or counting hypercycles yield runtimes independent of $k$.
This can be seen as a ``plateau'' in the hardness of hypercycle detection for any fixed $u$ seen in Figure \ref{fig:unweightedHypercycleBounds} and Section \ref{sec:ub_unweighted}.
For all $k$ where brute force is the best known algorithm, we give a matching lowerbound.



\subsection{Tight Hardness for Short Hypercycles}
\label{subsec:tighthardnessshorthypercycles}

We begin by showing that for finding relatively short hypercycles, brute-force algorithms are optimal unless the $(u,k)$-hyperclique hypothesis is false.
Note that the reduction from Theorem \ref{thm:hclique_to_hcycle} preserves the number of vertices in the graph $G$.
We use this second fact throughout the proof of our lower bound for this parameter regime.


Now, what exactly do we mean by ``short hypercycles''? 
To formally define the range in which we get tight results, we must introduce some notation, which allows us to reason about the uniformities we show hardness for.

\begin{definition}
    Recall the function $\gamma_u(k)=k-\lceil \frac{k}{u} \rceil+1$ from Theorem \ref{thm:hclique_to_hcycle}.
    Then, for constant $c$ define:
    
    \[\gamma_c^{-1}(u) = \max \{ k : \gamma_c(k) = u\}\]
\end{definition}
This function will make it easier to discuss the hypercycle lengths for which the hyperclique reduction yields hardness.
These correspond to the range $k \in [u, \gamma_3^{-1}(u)]$, which we will sometimes refer to as \textit{short hypercycles}.
In particular, we show that improving over brute-force search for short hypercycles would yield faster algorithms for finding hypercliques.
More formally we will prove that:


\tightShortHypercycle*

This conditional lower bound follows from the following ideas, which we prove as intermediate lemmas.
First, the function $\gamma_3$ is monotonically increasing, so applying the hyperclique reduction for $k\leq \gamma_3^{-1}(u)$ yields a uniformity $u' \leq u$.
Furthermore, we show a self-reducibility property of the hypercycle problem, which is that algorithms solving $k$-hypercycle on a given uniformity can be used to solve it on smaller uniformities.
Putting these ideas together, we are able to show that any hardness given by the hyperclique reduction on uniformities $u'<u$ can be extended to $u$.

\subsubsection{Understanding the Hyperclique to Hypercycle Reduction}

We begin by showing monotonicity of $\gamma$.

\begin{lemma} \label{lem:gamma monotone}
    For all $c\geq2$, the function $\gamma_c(k)$ is monotonically increasing.
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 0}\end{proof}

\begin{corollary}
For every $k$ such that $u\leq k<\gamma_3^{-1}(u):\gamma_3(k) \leq u$.
\end{corollary}

We next want to show that if finding hypercycles is hard on $u$-uniform graphs, it is also hard in graphs with uniformity $u'>u$. 
To do this, we will make use of $k$-circle-layered hypergraphs:

\begin{definition}[$k$-circle-layered hypergraphs]
    We say that a hypergraph $G$ is $k$-circle-layered if it is $k$-partite and its vertex partitions $V_1, \cdots, V_k$ can be arranged in a circle such that hyperedges only exist between adjacent vertex partitions. That is between $u$ partitions $V_i, V_{i+1 \mod k},...,V_{i+u-1 \mod k}$. 
\end{definition}

While this seems like a highly restrictive definition, \cite[Lemma~2.2]{LVW18} shows that a time-$O(T(n,m))$ algorithm for finding $k$-hypercycles in this type of hypergraph can be used to find $k$-hypercycles in arbitrary hypergraphs using time $\tilde{O}(k^k(n+m+T(n,m)))$.
Thus, for practical purposes we will treat the problems as equivalent.
Moreover, when indexing into a vertex $v_i$ in a $k$-hypercycle or a partition $V_i$ in a $k$-circle-layered graph, the index $i$ should be interpreted as shorthand for $(i \mod{k})$.



Now, we need one more property of $k$-circle-layered hypergraphs before we prove our self-reducibility result.
The structure of these graphs are useful for reasoning about hypercycles when we can ensure that any hypercycle in the graph uses exactly one vertex from each partition.
When this is true, we can think of the hypercycle as ``going around'' the circular structure of the hypergraph.
Nonetheless, there are some scenarios in which more than one vertex from some partition may appear in the hypercycle.
We can think of these as ``backward cycles'', since they must turn around at some point to re-visit the repeated partition.

We will now show that such hypercycles cannot exist when $k \not\equiv 0 \mod{u}$.

\begin{lemma}\label{lem:no_short_backward_cycles}
Suppose there exists a $k$-hypercycle $v_0,...,v_{k-1}$ in a $k$-circle layered hypergraph with uniformity $u$ that does not use exactly one node from each partition. Then, we have that $k\equiv 0 \mod{u}$.
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 1}\end{proof}

\subsubsection{Increasing Uniformity Preserves Hardness}

We can now show the following self-reducibility lemma about finding and counting $k$-hypercycles:

\begin{lemma} \label{lem:uniform self reduction}
    Let $k$ be a hypercycle length such that $k \not \equiv 0 \mod{u}$.
    Suppose there exists $\varepsilon>0$ such that there is an algorithm for finding (counting) $(u,k)$-hypercycles in $k$-circle-layered graphs that runs in time $O(n^{k-\varepsilon})$.
    Then, for any uniformity $u'<u$, there exists an algorithm for finding (counting) $(u',k)$-hypercycle in $k$-circle-layered graphs running in time $O(n^{k-\varepsilon}+n^u)$.
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 2}\end{proof}

\subsubsection{Getting the Tight Lower Bound}

We finally prove that short hypercycles require brute force:

\tightShortHypercycle*
\begin{proof}\textcolor{red}{TOPROVE 3}\end{proof}

From out worst-case to average-case reduction in Lemma \ref{lem:WCtoAC}, we can conclude that the average-case version of counting $(u,k)$-hypercycles also requires brute-force:

\begin{corollary}
    If the $(3,k)$-hyperclique hypothesis holds then counting $k$-hypercycles in $u$-uniform Erd{\H{o}}s-R{\'{e}}nyi hypergraphs when $k \in [u, \gamma_3^{-1}(u)]$ requires $\tilde{O}(n^{k-o(1)})$ time for constant $u$.
\end{corollary}
\begin{proof}\textcolor{red}{TOPROVE 4}\end{proof} 
\section{Beating Brute Force for Longer Hypercycles}
\label{sec:ub_unweighted}

In this section we give a new faster algorithm for hypercycle. 
While the range in which we get tightness in the previous section may have seemed arbitrary, the brute-force lower bound is actually \textit{false} for any longer hypercycle.
In particular, we show two different algorithms which leverage matrix multiplication to beat brute force when $k$ is sufficiently bigger than $u$.
One of these algorithms allows improvement over $n^{k-o(1)}$ starting at exactly $k \geq \gamma_3^{-1}(u)+1$, which is the point at which we can no longer prove tightness. 
The second algorithm exploits the sparsity of its input, and yields even better runtimes than the first when $k \geq 2u-1$.

These algorithms suggest the following relationship between hypercycle length and potential lower bounds.
When $k \in [\gamma_3^{-1}(u),2(u-1)]$, hardness is still dominated by the hypercycle length, but any reasonable lower bounds must account for fast matrix multiplication.
Then, when $k \in [2u-1, \infty]$, since the algorithm exploits sparsity and the total number of possible hyperedges is $O(n^u)$, hardness becomes independent of hypercycle length and is dominated by uniformity. 

\subsection{Faster Algorithm via Triangle-Detection} \label{subsec:triangle_detection}

We now show how matrix multiplication can be used to speed up hypercycle algorithms.
The main idea behind this algorithm is that when $k>\gamma_3^{-1}(u)$, it is possible to find three vertex partitions that are sufficiently ``spread out'' that no hyperedge covers all three partitions. This lets us treat the relationship between these three partitions as edges, not hyperedges. Specifically, we can represent the problem with many $3$-partite graphs which contain a triangle if and only if the original hypergraph contains a $k$-hypercycle. 
Then, since triangle-detection can be solved in $n^\omega$ time using matrix multiplication, we can get some savings.

To present our algorithm, we will need the following lemma.

\begin{lemma} \label{lem: triangle partitions}
    Let $\delta = \lceil k/3 \rceil$.

    Let $G$ be an $n$-vertex, $u$-uniform $k$-circle layered hypergraph with vertex partitions $V_1, \cdots, V_k$.
    Then, for all $k>\gamma_3^{-1}(u)$ and $i \in [1,k]$, every hyperedge covers at most two out of the three vertex sets $V_i,V_{i+\delta},V_{i+2\delta}$.
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 5}\end{proof}

Our algorithm uses this idea to combine brute-force search with known triangle-counting techniques, which yields a saving of $(3-\omega)$ in the exponent of the brute-force runtime.


\begin{restatable}{theorem}{matmultCycle} \label{thm: matmul_cycle}
    Let $G$ be an $n$-vertex $u$-uniform $k$-circle-layered hypergraph and $k > \gamma^{-1}_3(u)$.
    Then, there exists an $O(n^{k-3+\omega})$-time algorithm for finding (counting) $k$-hypercycles in $G$.
\end{restatable}


\begin{proof}\textcolor{red}{TOPROVE 6}\end{proof}
This algorithm shows that for hypercycles which are sufficiently longer than the hyperedge size, it is actually possible to beat brute force.
It is worth noting that the algorithm's complexity still increases with $k$.
This leaves open the possibility that we can find reasonably tight lower bounds dependent on $k$ for $k \geq \gamma^{-1}_3(u)$.

Nonetheless, we next show that such a lower bound is only possible for hypercycles up to length $2(u-1)$, since there is an algorithm which only depends on $u$ and is faster for $k \geq 2u-1$.

\subsection{A Faster Algorithm for Longer Hypercycles} \label{subsec:longer_hypercycles}

In this section, we explore a different approach to the hypercycle problem.
Once again, we exploit the structure of a $k$-circle-layered graph.
The main idea behind previous algorithms for e.g. weighted cycle is to start at some partition $V_1$, then for each vertex $v_1$ in $V_1$ iterate through $V_2,\cdots,V_k$ while keeping track of whether $v_1$ has a path to each of these \cite{LVW18}.
When going from $V_i$ to $V_{i+1}$, a node in $V_{i+1}$ will be reachable if it shares an edge with a node in $V_i$ that is reachable from $v$.
This reduces the cycle problem to this reachability subproblem between adjacent partitions.

\begin{figure}[ht]
    \centering
    
\begin{tikzpicture}[scale=1.5, every node/.style={circle, draw, minimum size=1cm, inner sep=0pt}]

\node (v3) at (0,0) {$v_3$};
\node (v2) at (1,0) {$v_2$};
\node (v1) at (2,0) {$v_1$};
\node (vk) at (3,0) {$v_k$};
\node (vk1) at (4,0) {$v_{k-1}$};
\node (vk2) at (5,0) {$v_{k-2}$};


\draw[thick, rounded corners] (0.6,0.5) rectangle (3 + 0.4,-0.5);
\draw[thick, rounded corners] (1.6,0.6) rectangle (4 + 0.4,-0.6);
\draw[thick, dashed, rounded corners] (2.6,0.4) rectangle (5 + 0.4,-0.4);
\draw[thick, dashed, rounded corners] (-0.4,0.4) rectangle (2 + 0.4,-0.4);



\draw[dotted, thick, bend left=80] (v3) to (vk2);

\end{tikzpicture}
    \caption{Example with uniformity $u=3$ to demonstrate why you need $u-1$ nodes. These are the four hyperedges which involve only the vertices $v_1,v_2, v_2, v_k, v_{k-1},$ and $v_{k-2}$. The two thick hyperedges include at least one vertex from $v_1, v_2, v_3$ and at least one vertex from $v_k,v_{k-1},v_{k-2}$, the dashed hyperedges include only vertices from one side. Note that only $v_2, v_1, v_k,$ and $v_{k-1}$ are involved in the crossover edges. Note that $2 = u-1$ in this context.}
    \label{fig:reachabilityHypercycle}
\end{figure}


We define a more general reachability subproblem, modified in ways that are necessary to use it for hypercycle detection. 
The key difference is that instead of considering all possible starting vertices for the hypercycle, we have to consider all possible sets of $u-1$ starting vertices.
This is due to the fact that at the end of the hypercycle, we will need the last $u-1$ edges to contain all of these vertices. See Figure \ref{fig:reachabilityHypercycle} for a visual representation of why $u-1$ partitions are needed to finish the cycle. 

We define a reachability problem in circle-layered graphs to capture this idea.

\subsubsection{Reachability Problems in Uniform Hypergraphs}

\newcommand{\uCLR}{$u$-CLR}

Intuitively the following problem asks for all hyperpaths that cross $2u-1$ partitions in a $(2u-1)$-circle-layered hypergraph. The output will answer for all tuples of nodes of the first $u-1$ nodes and last $u-1$ nodes if a path exists, or what the minimum weight path is. 

\begin{definition}[(Weighted) $u$-uniform circle-layered reachability problem ((Weighted) \uCLR)] \label{def: u-CLR}
Let $G=(V,E)$ be an $n$-vertex $u$-uniform $(2u-1)$-circle-layered (weighted) hypergraph with vertex partitions $V_1, \cdots, V_{2u-1}$. 
Let $L=V_1 \times \cdots \times V_{u-1}$ and $R=V_{u+1} \times \cdots \times V_{2u-1}$ be sets of vertex partitions.
Then, the $u$-uniform circle-layered reachability problem asks for an output of size $n^{2u-2}$. 
For all $2u-2$ tuples of nodes $(x_1, \cdots, x_{u-1}, y_1, \cdots, y_{u-1})$  where $(x_1, \cdots, x_{u-1}) \in L$ and  $(y_1, \cdots, y_{u-1}) \in R$ you must return the following:
\begin{itemize}
    \item If unweighted return if there exists a $v \in V_{u}$ 
such that edges $(x_1, \cdots \, x_{u-1},v)$, $(x_2, \cdots \, x_{u-1},v,y_1)$,  $\ldots$, $(x_{u-1},v, y_1, \cdots, y_{u-2})$, $(v, y_1, \cdots, y_{u-1})$ exist  in $E$. (That is if a hyperpath $x_1, \cdots, x_{u-1}, v, y_1, \cdots, y_{u-1}$ exists.)  
    \item If weighted let $w()$ be a function which returns the weight of a hyperedge. Then return 
    $$ min_{v\in V_{u}}  \left( w(x_1, \cdots \, x_{u-1},v)+ w(v, y_1, \cdots, y_{u-1}) + \sum_{i\in [2,u-2]} w(x_i,x_{i+1},\ldots,x_{u-1}, v, y_1, \ldots, y_{i-1}) \right) $$
\end{itemize}
  
The output of this problem is an $n^{u-1} \times n^{u-1}$ matrix, which we denote CLR($L,R$) (we will also call this output matrix CLR$_{2u-1}$($L,R$)). This matrix is binary if unweighted and is over field of the weights if weighted. 
\end{definition}

For convenience we will also define a second version of this which takes in a CLR$_{k-1}$($L,R$) matrix and outputs another reach-ability matrix, CLR$_{k}$($L,R$),  for a graph with one more circle layer. The key intuition for why we define the problem this way is that if you have reachability information from the first $u-1$ nodes to the last $u-1$ nodes you can extend this to another partition because no hyperedge in the path will need information from the `middle' nodes as the hyperedges are of uniformity $u$.
\newcommand{\uECLR}[2]{$(#1,#2)$-ECLR}

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}

\draw[thick, red] (-3.5,1.2) rectangle (-0.5,-0.2);
    \foreach \i/\label in {0/V_1, 1/V_2, 2/\cdots, 3/V_{u-1}} {
        \draw[thick] (-3+\i*0.7,0.5) ellipse (0.3 and 0.6);
        \node at (-3+\i*0.7, 0.5) {\scriptsize $\label$};
    }
    \node at (-2, 1.5) {$L$};

\node at (0, 0.5) {\huge $\cdots$};

\draw[thick, red] (2.15,1.2) rectangle (5,-0.2);
    \foreach \i/\label in {-1/V_{\text{\tiny{k-u+1}}}, 0/, 1/\cdots, 2/, 3/V_{k}} {
        \draw[thick] (2.5+\i*0.7,0.5) ellipse (0.3 and 0.6);
        \node at (2.5+\i*0.7, 0.5) {\scriptsize $\label$};
    }
    \node at (4.6, 1.5) {$R_k$};

\draw[thick, purple] (1.25,1.3) rectangle (4.25,-0.3);
    \node at (1.8, -0.6) {$R_{k-1}$};

    \end{tikzpicture}
    \caption{The \uECLR{u}{k} problem.}
    \label{fig:ECLR}
\end{figure}

\begin{definition}[(Weighted) $(k,u)$-extension uniform circle-layered reachability problem ((Weighted) \uECLR{u}{k})] \label{def: uk-ECLR}
Let $G=(V,E)$ be an $n$-vertex $u$-uniform $k$-circle-layered (weighted) hypergraph with vertex partitions $V_1, \cdots, V_{k}$. 
Let $L=V_1 \times \cdots \times V_{u-1}$ and $R_k=V_{k-(u-1)+1} \times \cdots \times V_{k}$ be sets of vertex partitions.
Additionally let CLR$_{k-1}(L, R_{k-1})$ be a reachability matrix which gives (minimum weight) hyperpath reachability from $L$ to $V_{k-(u-1)-1} \times \cdots \times V_{k-1}$.

Then, the \uECLR{u}{k} problem asks for an output of size $n^{2u-2}$. 
For all $2u-2$ tuples of nodes \\
$(x_1, \cdots, x_{u-1}, y_1, \cdots, y_{u-1})$  where $(x_1, \cdots, x_{u-1}) \in L$ and  $(y_1, \cdots, y_{u-1}) \in R$ you must return the following:
\begin{itemize}
    \item If unweighted return if there exists a hyperpath which starts at nodes $x_1, \cdots, x_{u-1}$ and ends at nodes $ y_1, \cdots, y_{u-1}$. 
    \item If weighted then return the minimum weight hyperpath which starts at $x_1, \cdots, x_{u-1}$ and ends at nodes $ y_1, \cdots, y_{u-1}$. 
\end{itemize}
  
The output of this problem is an $n^{u-1} \times n^{u-1}$ matrix, which we denote CLR$_k$($L,R$). This matrix is binary if unweighted and is over field of the weights if weighted. See Figure \ref{fig:ECLR} for a visual of this problem. 
\end{definition}

\subsubsection{Hypercycle Algorithm from Reachability Algorithm}

We now show that a pair of algorithms solving these problems can be used efficiently to solve hypercycle.

\begin{lemma} \label{lem: dp-like algorithm}
    
Suppose there exists a $T_1(n)$-time algorithm for \uCLR~and a $T_2(n)$-time algorithm for \uECLR{u}{k}. 
Then, there exists an $O(T_1(n)+T_2(n)+n^{2(u-1)}))$-time algorithm for finding (counting) $k$-hypercycles in $n$-vertex $u$-uniform $k$-circle-layered hypergraphs.
\end{lemma}

\begin{proof}\textcolor{red}{TOPROVE 7}\end{proof}

Note that if $T_1(n)$ and $T_2(n)$ have runtimes independent of $k$, then so will this algorithm.
Inutitively this should be true since one problem is completely characterized by $(2u-1)$-circle-layered graphs, and the other is simply asking about extending the reachability by one layer.
In the next subsection, we actually prove this by constructing algorithms for \uCLR~and \uECLR{u}{k}~ which will let us prove the following theorem:


\begin{restatable}{theorem}{matMulReach}\label{thm:matmul_reachability}
There exists a time-$O(n^{2u-1-(3-\omega)})$ algorithm for finding (counting) $k$-hypercycles in $n$-node $u$-uniform $k$-circle layered hypergraphs when $k \geq 2u-1$.
\end{restatable}

\subsubsection{Algorithms for Unweighted Reachability}

To achieve the desired runtime, we need algorithms for \uCLR~and \uECLR{u}{k} running in time $O(n^{2u-1- (3-\omega}))$. 
We will show that this can be achieved using matrix multiplication in a similar way as done in Theorem \ref{thm: matmul_cycle}.

We first show how to do this for $k=2u-1$.
\begin{lemma} \label{lem: uECLR algorithm}
    There exists a time-$O(n^{2u-1-(3-\omega)})$ algorithm for solving \uCLR~ in $n$-node $u$-uniform hypergraphs.
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 8}\end{proof}

We now show how to extend the technique to solve reachability when $k>2u-1$.

\begin{lemma} \label{lem: uCLR algorithm}
    There exists a time-$O(n^{2u-1-(3-\omega)})$ algorithm for solving \uECLR{u}{k} in $n$-node $u$-uniform hypergraphs.
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 9}\end{proof}

We can now prove that $k$-hypercycle can be solved in $O(n^{2u-1-(3-\omega)})$ for sufficiently large $k$.

\matMulReach*

\begin{proof}\textcolor{red}{TOPROVE 10}\end{proof}

We can now prove our desired theorem. 


\fastCycleDetect*

\begin{proof}\textcolor{red}{TOPROVE 11}\end{proof}


 
\section{Tight Results for Min-Weight Hypercycle}
\label{sec:tight_weighted}
In this section we present the tight matching upper and lower bounds for minimum hypercycle represented in Figure \ref{fig:weightedHypercycleBounds}. We start by providing the algorithm for min-weighted hypercycle and then prove the lower bounds.

Notably, we demonstrate that the best algorithm for weighted $k$-hypercycle for $k \in [u+1, 2u-1]$ is the naive algorithm. Our algorithm relies on tracking the first $u-1$ nodes of a hyperpath and the last $u-1$ nodes of a hyperpath.  This lower bound shows that doing so is, in some sense, required. The tight upper and lower bound gives credence to the intuition that when thinking about hypercycles you should think of sets of $(u-1)$ nodes as being analogous to single nodes in a normal graph with uniformity $2$. Furthermore, this suggests that, perhaps surprisingly, for $k\leq 2u-1$ the $k$-hypercycle problem requires the same running time as the  $k$-hyperclique problem in a $u$ uniform graph. 

\subsection{Algorithms for Minimum Hypercycle}
We will present two algorithms in this section. The first is the naive algorithm, presented for completeness. The second uses the definitions of 
\uCLR~and \uECLR{u}{k}~from the previous section (see Definitions \ref{def: u-CLR} and \ref{def: uk-ECLR}) and demonstrates fast algorithms for them. We can then use the \uECLR{u}{k}~algorithm to solve the $k$-hypercycle problem for $k\geq 2u-1$.

\subsubsection{Algorithm for k less than 2u-1}
This is the totally naive algorithm for the problem. We simply try all possible orders of nodes and check if they form a hypercycle.

\begin{lemma}
    The minimum $k$-hypercycle problem in a $u$-uniform hypergraph can be solved in time $O(k \cdot n^k)$, when $k$ is constant this is $O(n^k)$. 
    \label{lem:shortweightedkhypercyclealg}
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 12}\end{proof}

\subsubsection{Algorithm for k at least 2u-1}
We start with the base case, which can be solved with the naive algorithm. We present an algorithm which gives a speedup if the graph is sparse\footnote{We will note without proof that a $n^{u-1} |E|$ algorithm exists for finding the minimum hypercycle if instead of keeping a $n^{2u-2}$ sized output matrix you replace that matrix with a hashtable and ask only for the minimum between those sets of nodes in $L$ and $R$ which have a path.}. 

\begin{lemma}
    The weighted \uCLR~problem has a $O(u \cdot n^{u-1}|E| + n^{2u-2})$ algorithm, where $|E|$ is the number of hyperedges in the graph. Note this is also $O(n^{2u-1})$.
    \label{lem:weighteduCLRAlg}
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 13}\end{proof}


The key for this next lemma is that a minimum hyperpath of length $k$ can be computed quickly given minimum reachability information for hyperpaths of length $k-1$. Specifically, by tracking the $u-1$ nodes on the `end' of the $(k-1)$-hyperpath we can extend by one node as the only hyperedge the new node is involved in only concern the last $u-1$ nodes of the previous hyperpath. This lets us extend our path information. 
\begin{lemma}
    The weighted \uECLR{u}{k}~problem has a $O(n^{2u-2} + n^{u-1} \cdot |E|)$ algorithm. Note this running time is also $O(n^{2u-1})$.
    
    \label{lem:weightedukECLRAlg}
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 14}\end{proof}


Now we will use these split up problems solve the hypercycle problem. Note that the problems as they have been split are basically a dynamic programming setup.
\begin{lemma}
    The minimum $k$-hypercycle problem in a $u$-uniform graph has a  $O(k^k \cdot u \cdot k \cdot (n^{u-1}|E| + n^{2u-2}))$ algorithm $k \geq 2u-1$ which succeeds with probability at least $2/3$. Note that $|E| = O(n^u)$ and thus the run time is also $O(k^k \cdot u \cdot k \cdot n^{2u-1})$
    \label{lem:longweightedkhypercyclealg}
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 15}\end{proof}

\subsubsection{Putting Both Algorithms Together}
We can now do the very simple operation of using the faster algorithm in the appropriate situation. 

\begin{theorem}
    An algorithm for finding the minimum $k$-hypercycle in a $u$-uniform hypergraph with $n$ nodes with probability at least $2/3$ exists which runs in $O\left(\min(n^k, n^{2u-1})\right)$ time for constant $k$.
\end{theorem}
\begin{proof}\textcolor{red}{TOPROVE 16}\end{proof}

\subsection{Lower-Bounds for Minimum Hypercycle}

\begin{corollary}
    Let $G$ be a $2$-uniform hypergraph on $n$ vertices $V$, partitioned into $k$ parts $V_1,\ldots,V_k$. 
    
    Let $\gamma_2(k)=k-\lceil k/2\rceil +1$.
    
    In $O(n^{\gamma_2(k)})$ time we can create a $\gamma_2(k)$-uniform hypergraph $G'$ on the same node set $V$ as $G$, so that $G'$ contains an $k$-hypercycle if and only if $G$ contains an $k$-hyperclique with one node from each $V_i$.
    
    If $G$ has weights on its hyperedges in the range $[-W,W]$, then one can also assign weights to the hyperedges of $G'$ so that a minimum weight $k$-hypercycle in $G'$ corresponds to a minimum weight $k$-hyperclique in $G$ and every edge in the hyperclique has weight between $[-\binom{\gamma_2(k)}{2}W,\binom{\gamma_2(k)}{2}W]$. Notably, $\binom{\gamma_2(k)}{2}\leq O(k^2)$.
\end{corollary}
\begin{proof}\textcolor{red}{TOPROVE 17}\end{proof}

\subsubsection{Odd Cycle Lengths}
We can now consider what value of $k$ corresponds to a given value of $u$. That is, if $u = k- \lceil k/2 \rceil +1$ given $u$ what is the $k$ we should consider? Consider $k=2\ell +1$ then note that $u = 2\ell+1 - \ell -1+1 = \ell +1$. So, for a given $u$ we should consider $\ell = u-1$ which corresponds to $k = 2u-2+1 =  2u-1$.

\begin{corollary}
    Let $G$ be a $2$-uniform hypergraph on $n$ vertices $V$, partitioned into $k = 2u-1$ parts $V_1,\ldots,V_{2u-1}$. Note that $u=k-\lceil k/2\rceil +1$.
    
    In $O(n^{u})$ time we can create a $u$-uniform hypergraph $G'$ on the same node set $V$ as $G$, so that $G'$ contains an $(2u-1)$-hypercycle if and only if $G$ contains an $k$-hyperclique with one node from each $V_i$.
    
    If $G$ has weights on its hyperedges in the range $[-W,W]$, then one can also assign weights to the hyperedges of $G'$ so that a minimum weight $k$-hypercycle in $G'$ corresponds to a minimum weight $(2u-1)$-hyperclique in $G$ and every edge in the hyperclique has weight between $[-\binom{u}{2}W,\binom{u}{2}W]$. Notably, $\binom{u}{2}\leq O(u^2)$.
    \label{cor:reverseUandKMin}
\end{corollary}
\begin{proof}\textcolor{red}{TOPROVE 18}\end{proof}

This gives an immediate implication 

\begin{corollary}
The minimum $(2u-1,u)$-hypercycle problem requires $n^{2u-1-o(1)}$ time if the minimum $(2u-1)$-clique hypothesis holds. 
\label{cor:min2u-1ishard}
\end{corollary}
\begin{proof}\textcolor{red}{TOPROVE 19}\end{proof}

\subsubsection{Even Cycle Lengths}

\begin{corollary}
    \label{cor: reverseUandKMineven}
    Let $G$ be a $2$-uniform hypergraph on $n$ vertices $V$, partitioned into $k = 2u-2$ parts $V_1,\ldots,V_{2u-2}$. Note that $u=2(u-1)-\lceil 2(u-1)/2\rceil +1 = u-1+1$.
    
    In $O(n^{u})$ time we can create a $u$-uniform hypergraph $G'$ on the same node set $V$ as $G$, so that $G'$ contains an $(2u-2)$-hypercycle if and only if $G$ contains an $k$-hyperclique with one node from each $V_i$.
    
    If $G$ has weights on its hyperedges in the range $[-W,W]$, then one can also assign weights to the hyperedges of $G'$ so that a minimum weight $k$-hypercycle in $G'$ corresponds to a minimum weight $(2u-1)$-hyperclique in $G$ and every edge in the hyperclique has weight between $[-\binom{u}{2}W,\binom{u}{2}W]$. Notably, $\binom{u}{2}\leq O(u^2)$.
\end{corollary}
\begin{proof}\textcolor{red}{TOPROVE 20}\end{proof}

This gives an immediate implication 

\begin{corollary}
The minimum $(2u-2)$-hypercycle problem requires $n^{2u-2-o(1)}$ time if the minimum $(2u-2)$-clique hypothesis holds in a graph with uniformity $u$. 
\label{cor:min2u-1ishardEven}
\end{corollary}
\begin{proof}\textcolor{red}{TOPROVE 21}\end{proof}


\subsubsection{Combining to Produce Lower Bound}
To prove the same statement for shorter cycles we will use the following strategy. Consider, for example $k = 2u-3$. We can show hypercycles of this length are hard when the uniformity is $u-1$. We will show that if the problem is hard with smaller uniformity then it is hard for larger uniformity. Together this will let us show hardness for smaller $k$ for uniformity $u$.


The intuition for this next lemma is that a $u' > u$ hypercycle is more constraining than a $u$ hypercycle. Notably we have edges which are `longer'. So, we can simply include all possible extensions of edges to compute the original problem. We use color-coding to make our graph $k$-circle-layered to make the proof more straightforward. 

\begin{lemma}
Let $k^k = n^{o(1)}$.
If the $k$-hypercycle problem is $n^{k-o(1)}$ hard for some uniformity $u < k$ then the $k$-hypercycle problem is  $n^{k-o(1)}$ hard for all uniformities $u'$ where $2u' > k > u' \geq u$.
\label{lem:growUniformityFree}
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 22}\end{proof}

Now we can combine our hardness results for $2u-1$ and $2u-2$ hypercycle with the above lemma to show hardness for $k$-hypercycle when $k$ is small. 

\weightedCycleLB*
\begin{proof}\textcolor{red}{TOPROVE 23}\end{proof} 
\section{Worst-Case to Average-Case Reductions for Counting sub-Hypergraphs}
\label{sec:wc_to_ac}
\subsection{Overview of Approach}
In this section, we aim to give results on worst-case to average-case reductions for counting instances of a subhypergraph. We do this with an extension of the Inclusion-Edgesclusion technique (among others) introduced in \cite{factoredProblems}. In fact, we show here that the result in \cite{factoredProblems} can be extended to hypergraphs with some modifications to the approach. We begin with some definitions for the problems in question.

\begin{definition}\label{def: H}
The \textbf{counting }$\boldsymbol{H}$ \textbf{subgraphs in an }$\boldsymbol{H}$\textbf{-partite hypergraph (\#H)} problem takes as input a hypergraph $H$ and a $H$-partite $n$-node graph $G$ with the vertices partitioned into $k$ components, $V_1,...,V_k$, and asks for the count of the number of (non-induced) subgraphs of $G$ that have exactly one node from each of the $k$ partitions and contain the hypergraph $H$.
\end{definition}

\begin{definition}\label{def: UH}
The \textbf{uniform counting }$\boldsymbol{H}$ \textbf{subgraphs in an }$\boldsymbol{H}$\textbf{-partite hypergraph (U\#H)} problem takes as input a hypergraph $H$ and a $H$-partite $n$-node graph $G$ with the vertices partitioned into $k$ components, $V_1,...,V_k$, where every hyperedge between any partitions that have edges in $H$ is chosen to exist iid with probability $\mu$. The problem then asks for the count of the number of (non-induced) subgraphs of $G$ that have exactly one node from each of the $k$ partitions and contain the hypergraph $H$.
\end{definition}


Note that both problems only consider $G$ that are $H$-partite, and that U\#H is the uniform distribution over inputs to \#H.

\begin{definition}\label{def: HK}
The \textbf{counting }$\boldsymbol{H}$ \textbf{subgraphs in a }$k$\textbf{-partite hypergraph (\#HK)} problem takes as input a hypergraph $H$ and a $k$-partite $n$-node graph $G$ with the vertices partitioned into $k$ components, $V_1,...,V_k$, and asks for the count of the number of (non-induced) subgraphs of $G$ that have exactly $k$ nodes and contain hypergraph $H$, where each partition contains exactly one node.
\end{definition}



\begin{definition}\label{def: HER}
The \textbf{counting }$\boldsymbol{H}$ \textbf{subgraphs in a } \textbf\erdosRen \textbf{ hypergraph (\#HER)} problem takes as input a hypergraph $H$ and a \erdosRen hypergraph $G$ where every possible hyperedge exists with probability $\frac1b$, and asks for the count of the number of (non-induced) subgraphs of $G$ that have exactly $k$ nodes and contain hypergraph $H$.
\end{definition}




We now state the main result of Section \ref{sec:wc_to_ac}, the formalization of Theorem \ref{thm: informal wc to ac}.




\begin{restatable}{theorem}{WCtoACcounting}\label{thm: WCtoACcounting}
Let $H$ have $e$ edges and $k = O(1)$ edges, Let $A$ be an average-case algorithm for counting subgraphs $A$ in \erdosRen hypergraphs with edge probability $1/b$ which takes $T(n)$ time with probability at least $1-2^{-2^k} \cdot b^{-2^k} \cdot (\lg (e) \lg\lg(e))^{-\omega(1)}$.

Then there exists an algorithm $A'$ that runs in time $\Otil(T(n))$ that solves the \#HK problem with probability at least $1-\Otil(2^{\lg^2(n)})$.
\end{restatable}



Our goal is to do the following chain of reductions:
\[
\mathrlap{\underbrace{\phantom{\text{\#HK}\rightarrow\text{\#H}}}_\text{(1)}} \text{\#HK}\rightarrow\mathrlap{\overbrace{\phantom{\text{\#H}\rightarrow\text{U\#H}}}^\text{(2)}} \text{\#H}\rightarrow\underbrace{\text{U\#H} \rightarrow\text{\#HER}}_\text{(3)}
\]

Completing the $3$ reductions will show the desired result. We will do reduction $2$, then reduction $3$, then reduction $1$ in the following sections.

\subsection{Reducing \#H to U\#H}\label{sec: H to UH}

We begin by defining the notion of a \emph{good low-degree polynomial}, introduced by \cite{factoredProblems}.

\begin{definition}\cite{factoredProblems}\label{def: GLDP}
Let $n$ be the input size of a problem $P$, let $P$ return an integer in the range $[0,p-1]$ where $p$ is a prime and $p<n^c$ for some constant $c$. A good low-degree polynomial is a polynomial $f$ over a finite prime field $F_p$ where:

\begin{itemize}
    \item If $\Vec{I} = b_1,...,b_n$, then $f(b_1,...,b_n) = f(\Vec{I}) = P(\Vec{I})$, where $b_i$ is a zero or a one in the field.
    \item The function $f$ has degree $d = o(\lg(n)/\lg\lg(n))$.
    \item The function is strongly $d-$partite, meaning that the inputs can be partitioned into $d$ sets where no monomial contains more than one input that comes from the same set.
\end{itemize}
\end{definition}
\begin{definition}\label{def: GLDP H}
Let $H$ be a $k$-node graph with vertices $V_H$ and $G$ an $H$-partite $n$-node hypergraph with vertex set partition $V_1,...,V_k$. Let $E$ be the set of variables $\{e(v_{a_1},...,v_{a_c})|v_i\in V_i, a_x < a_y \iff x < y\}$ such that $e$ is 1 when the hyperedge between the vertices exists in $G$ and 0 when it does not. Let $h(v_{1},...,v_{k})$ be a function that multiplies all corresponding $e$ for hyperedges in $H$ for the selection of vertices in the input. Define $f$ as follows:
\[
f(E)=\sum_{v_1\in V_1,...v_k\in V_k} h(v_{1},...,v_{k})\mod{p}
\]

Where $p$ is some prime.
\end{definition}

\begin{lemma}\label{lem: f correct}
The function in the above definition returns the output of \#H, given that $p$ is a prime in $[2n^k, n^{2k}]$. 
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 24}\end{proof}

\begin{lemma}\label{lem: f GLDP}
$f$ is a good low-degree polynomial for \#H if the number of edges in $H$ is $o(\lg(n)/\lg\lg(n))$.
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 25}\end{proof}

We can now apply the following result, also from \cite{factoredProblems}.

\begin{theorem}\cite{factoredProblems}\label{thm: GLDP}
Let $\mu$ be a constant such that $\mu\in(0,1)$. Let $P$ be a problem such that a function $f$ exists that is a good low-degree polynomial for $P$, and let $d$ be the degree of $f$. Let $A$ be an algorithm that runs in time $T(n)$ such that when $\Vec{I}$ is formed by $n$ bits each chosen iid from $Ber[\mu]$:

\[
Pr[A(\Vec{I}) = P(\Vec{I})]\geq 1-1/\omega\left(\lg^d(n)\lg\lg^d(n)\right).
\]

Then there is a randomized algorithm $B$ that runs in time $\Otil(n+T(n))$ such that for any $\Vec I\in\{0,1\}^n$:

\[
\Pr[B(\Vec I) = P(\Vec I)]\geq 1 - O\left(2^{-\lg^2(n)}\right).
\]
\end{theorem}

This immediately gives the following corollaries that finish the reduction.

\begin{corollary}
Let $d=2^k$ and $k=o(\sqrt[c]{\lg(n)/\lg\lg(n) })$. If an algorithm exists to solve U\#H in time $T(n)$ with probability $1-1/\omega(\lg^d(n)\lg\lg^d(n) )$, then an algorithm exists to solve \#H in time $\Otil(T(n) + n^2)$ with probability at least $1-O \left(2^ {-\lg^2(n)}\right)$.
\end{corollary}

\begin{corollary}\label{H TO UH}
Let $ H $ be such that $|E_H|=o(\lg(n)/\lg\lg(n) )$ and define $d = |E_H|$. If an algorithm exists to solve U\#H in time $T(n)$ with probability $1-1/\omega(\lg^d(n)\lg\lg^d(n) )$, then an algorithm exists to solve \#H in time $\Otil(T(n) + n^2)$ with probability at least $1-O \left(2^ {-\lg^2(n)}\right)$.
\end{corollary}

\subsection{Reducing U\#H to Average-Case Erd{\H{o}}s-R{\'{e}}nyi}

We now desire to reduce U\#H to Average-Case Erd{\H{o}}s-R{\'{e}}nyi - meaning that, we want to show that counting $H$ in an Erd{\H{o}}s-R{\'{e}}nyi hypergraph can be used to solve U\#H. We make a note here that, with more precise counting, the below techniques work for $k = o(\lg\lg n)$, but for ease of discussion, we will proceed assuming that $k$ is constant. We also note that we do not put any restrictions on the size of the hyperedges. 

\begin{definition}
Let $G$ be a $k$-partite Erd{\H{o}}s-R{\'{e}}nyi hypergraph with every hyperedge included with probability $1/b$, where $b$ is an integer. Let the vertex partitions of $G$ be $V_1,...,V_k$, and the edge partitions be $\edgepartitionc$, where $a_i < a_j \iff i < j$.

Label all hyperedges in $\edgepartitionc$ with $\ell\in[1,b]$ as follows: Edges that exist in $G$ are given label 1. The rest of the edges are uniformly assigned labels from $[2,b]$. Let $\edgepartitionc^\ell$ be the set of all edges of label $\ell$ between these $c$ vertex sets.

Let $\gchosenlabels$ be the following graph: We select all edges with label $\ell_i$ from the $i^{th}$ edge partition by lexicographical ordering on the labels of the vertex sets associated with the edge partition. We note that there are then $b^{2^k}$ such hypergraphs, as we have $b$ choices for each distinct edge partition. Define this set of hypergraphs as $S_G$. We note that, due to symmetry, all hypergraphs in $S_G$ are drawn from the same distribution.
\end{definition}

Essentially, we are looking at $G$ through the lens of a complete $k$-partite hypergraph with labels on the edges, labeling all the edges in $G$ with $1$. We then focus on hypergraphs where we choose a label for every edge partition, and take edges from each partition with the corresponding label.

\begin{definition}\label{def: count labels}
Let $G$ be defined as above. We define a labeled subgraph $L$ of $H$ in $G$ to be a subgraph of $H$ where every vertex is assigned a unique label in $[1,k]$. Define the count of the number of $L$ in $G$ to be the number of not-necessarily induced subgraphs $L$ where every vertex with label $\ell$ in $L$ comes from $V_\ell$ in $G$.
\end{definition}

Again, we want to reduce U\#H to counting subgraphs in Erd{\H{o}}s-R{\'{e}}nyi hypergraphs. The main barrier that we must overcome comes from the fact that, in an Erd{\H{o}}s-R{\'{e}}nyi graph, there exist edges that don't exist in $H$-partite graphs. This leads to overcounting subgraphs. We solve this problem by creating correlated hypergraphs 
that individually look Erd{\H{o}}s-R{\'{e}}nyi, through which we can get the true count of $H$ in the $H$ partite graph.

\subsubsection{Counting Small Subgraphs}
Our argument will make use of recursion to count labeled $H$. We begin here by solving the base cases. We define counting labeled $H$ in the same way as outlined in 
Definition \ref{def: count labels}.

\begin{lemma}\label{lem: disconnected count}
Let $G$ be a hypergraph with $n$ nodes, $m$ edges, and $k$ labeled partitions of the vertices, $V_1,...,V_k$ ($G$ is not necessarily $k$-partite).

If we have the counts of all labeled subgraphs of $H$ in $G$ of size less than $s$ vertices, we can compute the number of labeled subgraphs in $G$ that are the union of two disconnected labeled subgraphs of $H$ of size $s$ or less in constant time.
\end{lemma}

\begin{proof}\textcolor{red}{TOPROVE 26}\end{proof}

\begin{lemma}\label{lem: tiny count}
Let $G$ be defined as above. We can compute the count of any subgraph $H$ in $G$ with 1 edge or fewer in $\Otil(m)$ time. This applies regardless of whether or not $H$ is labeled.
\end{lemma}

\begin{proof}\textcolor{red}{TOPROVE 27}\end{proof}

\subsubsection{Recursion}

This step forms the main technical difficulty of this counting process. We will use all counts of subgraphs with a smaller number of hyperedges to count those with more hyperedges.

\begin{restatable}{lemma}{lemmaInclusion}\label{lem: inclusion}
Let $G$ be a labeled $k$-partite hypergraph with $n$ nodes per partition.

Say we are given the counts of the number of subgraphs $H$ in all hypergraphs in $S_G$.

Additionally, say we are given the counts of all labeled subgraphs of $H$ with $x\in [0,v]$ vertices and $y\in [0,e]$ hyperedges.

Let $L$ be a labeled subgraph of $H$ with $v$ vertices and $e+1$ edges.

Using all of these counts, we can count the number of not-necessarily induced subgraphs $L$ in $G$ in time $O(k!\cdot 2^{2^k} + b^{2^k})$.
\end{restatable}



The techniques we use in this proof essentially comes from a careful extension of the technique used to prove Lemma 5.9 in \cite{factoredProblems}. Of course, with there being hyperedges instead of edges, there are key parameters that change (resulting in a slightly different Lemma statement), but the key ideas are the same. For this reason, we leave the proof for this Lemma to Section \ref{sec: appendixLemmaRecursion}.






\subsubsection{Reducing to Erd{\H{o}}s-R{\'{e}}nyi}
We reduce counting labeled copies of $H$ in a $k$-partite Erd{\H{o}}s-R{\'{e}}nyi hypergraph to counting $H$ in Erd{\H{o}}s-R{\'{e}}nyi hypergraphs. Note that picking a particular labeling solves the problem of U\#H, as we can treat labeled hypergraph partitions as being $H$-partite.

\begin{lemma}\label{lem: AC to HP count}
Let $H$ have $e$ edges and $k$ vertices. Let $A$ be an average-case algorithm for counting unlabeled subgraphs $H$ in $k$-partite Erd{\H{o}}s-R{\'{e}}nyi graphs with edge probability $1/b$ which takes $T(n)$ time with probability $1 - \varepsilon/b^{2^k }$.

The number of labeled copies of subgraph $H$ in $k$-partite Erd{\H{o}}s-R{\'{e}}nyi graphs with edge probability $1/b$ can be computed in time $\Otil \left(2^{2^k} \cdot \left(m + k!\cdot 2^{2^k } + b^{2^k }\right) + b^{2^k  } \cdot T(n) \right) $ with probability $1-\varepsilon$.
\end{lemma}

We note that the technique we use here is slightly simpler than the one used to achieve the analogous statment in \cite{factoredProblems}.


\begin{proof}\textcolor{red}{TOPROVE 28}\end{proof}

\begin{lemma} \label{lem:WCtoAC}
Let $H$ have $e$ edges and $k$ vertices, and let $A$ be an average-case algorithm for counting subgraphs $H$ in Erd{\H{o}}s-R{\'{e}}nyi graphs where each hyperedge exists with probability $1/b$ which takes $T(n)$ time with probability $1-2^{-2k}\cdot b^{2^k}\cdot\left(\log(e)\log\log(e))^{-\omega(1)}\right)$.

Then, there exists an algorithm to count subgraphs in uniform $H$-partite graphs in time $\Otil(T(n))$ (U\#H) with probability at least $1-O(2^{-\log^2{n} } )$.

\end{lemma}




\begin{proof}\textcolor{red}{TOPROVE 29}\end{proof}

\subsection{\#HK to \#H and the proof of Theorem \ref{thm: WCtoACcounting}}

\begin{lemma}\label{lem: HK to H}

Let $A$ be an algorithm that solves \#H on $H$-partite $G$ with $n$ vertices and $H$ with $v = k = O(1)$ and $e = O(1)$ edges in time $T(n)$ with probability of success at least $1-\varepsilon$.

Then there exists an algorithm that solves \#HK on $k$-partite $G'$ with $n$ vertices and the same $H$ that runs in $O(T(n))$ time with probability of success at least $1 - 2^{2^k}\varepsilon$.

\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 30}\end{proof}


We can now prove the main theorem in this section.

\WCtoACcounting*

\begin{proof}\textcolor{red}{TOPROVE 31}\end{proof}





 
\section{Applications to Database Problems}
\label{sec:database}
The aim of this section is to demonstrate the applicability of the above techniques to solve existing problems in the databases setting. We begin by defining the relevant terms.

A \emph{database} $D$ is a relational structure with a set of objects $V$, and relations $R_i(\Vec s)$, where $\Vec s\in V^r$. We refer to $r$ as the \emph{arity} of $R_i$. A relational term that exists in the database is referred to as a \emph{fact}. 



A \emph{conjunctive query} $Q(R_a(\Vec s_a),...)$ is defined as a conjunction of the relations $R_j$ in its input. The variables in $X_i$ are referred to as \emph{free variables}. The query evaluates to true if there is some assignment of variables in $V$ to the free variables in the sets $X_i$ such that every relation in $Q$ exists in the database. We note that some of the sets $X_i$ may be share free variables. Naturally, every single free variable with the same label must be the same. In this paper, this is the only type of query we consider, and so we will simply refer to them as \emph{queries}.

A \emph{count query} simply answers with the number of unique assignments of variables that are valid for $Q$. A query contains \emph{self-joins} if it contains more than one copy of the same relation. We say that a query is \emph{self-join-free} if it has no self-joins. For this paper, we assume that the size of the queries is constant.







\subsection{Worst case to Average Case reduction for self-join-free count queries}




\begin{definition}
The \textbf{self-join-free count query (SCQ)} problem takes as input a database $D$ and a query $Q$ and asks for the count of the number of unique assignments of elements in the domain of $D$ to free variables in $Q$ such that $Q$ is satisfied. Relations in $D$ can be limited to those that appear in $Q$.
\end{definition}

\begin{definition}
The \textbf{uniform self-join-free count query (USCQ)} problem is the same as the SCQ problem, only that the database is such that every fact within a relation exists with some probability $\mu_{R_{i}}$. This is the average-case version of the SCQ problem.
\end{definition}

Much like the reduction we did in Section \ref{sec: H to UH}, we start by constructing a good low-degree polynomial for SCQ.

\begin{definition}
Let $D$ be a database with domain $V$ and relations $R_i$. Let $Q$ be a count query as defined above, where the number of relations in $Q$ is $k$ and the number of free variables is $r$. Note that $r\leq k$. Let $\Vec E$ be a vector such that every entry corresponds to a potential fact in the database, where it is $1$ if the fact is in the database, and $0$ otherwise. Let $h(v_1,...,v_r)$ be a function that multiples all corresponding entries for facts in the query for the selection of domain elements $v_1$ through $v_r$. Note that this function returns $1$ if the selection of variables in the input form a valid response to the query and $0$ otherwise. Define $f$ as follows:

\[
f(\Vec E) = \sum_{v_1,...,v_r\in V} h(v_1,...,v_r)\mod{p}
\]

where $p$ is some prime.
\end{definition}



\begin{lemma}\label{lem: SCQ polynomial accuracy}
The above function returns the output of SCQ given that $p$ is a prime in $[2n^k, n^{2k}] $
\end{lemma}






\begin{proof}\textcolor{red}{TOPROVE 32}\end{proof}

\begin{lemma}
Let $ Q $ be such that $|Q|= O(1) $ and define $d = |Q|$.
$f$ is a good low-degree polynomial for SCQ of degree $d$ if the size of the query is bounded by a constant. \label{lem:scqGLDP}
\end{lemma}

\begin{proof}\textcolor{red}{TOPROVE 33}\end{proof}

We now apply Theorem \ref{thm: GLDP} to get the result desired.

\begin{corollary}\label{cor: SCQ to USCQ}
Let $ Q $ be such that $|Q|= O(1) $ and define $d = |Q|$. Let the size of the query be constant. If an algorithm exists to solve USCQ in time $T(n)$ with probability $1-1/\omega(\lg^d(n)\lg\lg^d(n) )$, then an algorithm exists to solve SCQ in time $\Otil(T(n) + n^2)$ with probability at least $1-O \left(2^ {-\lg^2(n)}\right)$.
\end{corollary}
\begin{proof}\textcolor{red}{TOPROVE 34}\end{proof}
 
\section{Conclusion and Open Problems}
\label{sec:conc_and_open_prob}
We have given a worst-case to average-case reduction for counting sub-hypergraphs and for counting database queries. We demonstrate the usefulness of our improved reduction by giving tight lower-bounds for average-case hypercycle counting for short hypercycles. 

Additionally, we present new algorithms and new lower bounds for hypercycle in the worst-case. We get tight bounds for the weighted problem of minimum-hypercycle. We get tight bounds for short hypercycle lengths for the unweighted problem. We show a new faster algorithm for $k$-hypercycle which depends on the running time of fast matrix multiplication. However, these results leave many problems open. 


\subsection{Unweighted Hypercycle Open Problems}
Fundamentally the open problems here represent getting clear answers about the running time of the unweighted hypercycle problem when $k\geq \lambda_3^{-1}(u)+1$. Some specific open problems which we think would mark progress towards understanding this longer-cycle regime are:
\begin{enumerate}
    \item When $k = \lambda_3^{-1}(u)+1$ can you show a lower bound of $n^{\lambda_3^{-1}(u)-o(1)}$ for unweighted $k$-hypercycle? Note that if you could show this you would be giving a tight lower bound assuming $\omega=2$. 
    \item \textbf{(Extending the previous question)} When $ 2u-1> k \geq \lambda_3^{-1}(u)+1$ can you show a lower bound of $n^{k-1-o(1)}$ for unweighted $k$-hypercycle? 
    \item Can you give a reduction which shows that if (counting, directed) $k$-hypercycle in a $u$-uniform graph requires $T(n)$ time then so does (counting, directed) $(k+1)$-hypercycle? Note that we have a reduction which shows that if directed $k$-hypercycle in a $u$-uniform graph requires $T(n)$ time then so does directed $(k+u-1)$-hypercycle (directedness or something similar is needed for hypercycle lengths which are a multiple of $u$). This generalizes the idea of adding a partition to your graph with a matching which works for $u=2$. 
    \item \textbf{(Proving the previous point can't be done in general)} Can you show that for some $k$ and $u$ (counting, directed) $k$-hypercycle in a $u$-uniform graph requires $T(n)$ time and (counting, directed) $(k+1)$-hypercycle in a $u$-uniform graph can be solved in $o(T(n))$ time? For example, if you could show for some $u$ that $k = \lambda_3^{-1}(u)+1$ hypercycle could be solved in $n^{\lambda_3^{-1}(u)-\epsilon}$ for some $\epsilon >0$ this would be satisfied.
    \item Can you give a faster algorithm for the unweighted $k$-hypercycle problem than what we offer in this paper for any $k$ and $u$? 
\end{enumerate}


\subsection{Existential Hypercycle Open Problems}
There are interesting patterns we have noticed in $k$-hypercycles in $u$-uniform hypergraphs which  relate to the existence of graphs instead of the existence of algorithms. We note in the introduction that a theorem exists showing that $k$-hypercycles must exist in sufficiently dense graphs \cite{allen2015tight}. However, as that theorem is currently written it doesn't show that e.g. graphs with $n^{u-1}$ edges must have a $(2u)$-hypercycle. We note that when $k$ is not a multiple of $u$ you can create an extremely dense graph with no hypercycles. Specifically, create a $u$ partite with $n/u$ nodes in each partition and add every possible hyperedge which includes one node from each partition. This is metaphorically similar to no odd-cycles existing in a complete bi-partite graph. We will now give some concrete open problems related to this issue of multiple-of-$u$-hypercycles and density. 

\begin{enumerate}
    \item In $u=2$ uniform undirected graphs there is an interesting pattern which emerges. A fully dense bipartite graph contains no odd cycles, however, even cycles must exist even in relatively sparse graphs. Specifically, for constant $k$ in a graph with sparsity $\Omega(n^{1+1/k})$ there must exist a $2k$-cycle. How does this relate to hypergraphs of larger uniformity? Hypercycles of length $k = 0 \mod u$ can exist in a $u$-partite hypergraph, however hypercycles of length $k' \ne 0 \mod u$ do not exist in even a complete $u$-paritite hypergraph. This looks like it follows a metaphorically similar structure to graphs where $u=2$. Certainly it does for $k' \ne 0 \mod u$. However, we have not yet been able to characterize the density at which $k$-hypercycles are guaranteed to exist when $k = 0 \mod u$. A construction with $\Theta(n^u)$ edges where no $k$-hypercycle exists would settle the question, as would  a proof that a $k$-hypercycle must exist in any graph with $\Omega(n^{u-\epsilon})$ hyperedges for some constant $\epsilon >0$.
    \item To make the above question more concrete: what is the lowest hyperedge density such that a $6$-hypercycle is guaranteed to exist in any graph with that density in a $3$-uniform hypergraph? Is this density $\Theta(n^3)$? Is this density $\Omega(n^2)$?
    \item To make the above question (potentially) easier: You are given a tripartite 3-uniform hypergraph, $G$, with partitions $V_1, V_2, V_3$. Furthermore you are guaranteed that for every pair of nodes $(v_i, v_j) \in V_i \times V_j$ there are exactly $d$ edges of the form $(v_i, v_j, v_k)$ where $v_k \in V_k$ and $i\ne j \ne k$. This is a generalization of degree. What is the degree $d$ at which a $6$-hypercycle is guaranteed?
    \item Given a close reading of the proof of Theorem 1 from `Tight cycles in hypergraphs'(\cite{allen2015tight}) can you show that in a $u$-uniform hypergraph $G$ with at least $|E| \geq \frac{2k}{n} \binom{n}{u}$ hyperedges there must be a $k$-hypercycle? (This is what would happen if you could set $\delta = 2k/n$ and still have the proof go through.)
    \item For even cycles in 2-uniform graphs the longer the cycle the smaller the sparsity at which it is guaranteed to exist. Can something similar be proven for $u$-uniform graphs in general? 
\end{enumerate}


\subsection{Counting Color Coding}

We would love to say that counting constant sized subhypergraphs in the worst-case is equivalent in hardness up to log factors to counting constant sized subhypergraphs in the average-case. The issue we have here is, surprisingly, in the worst-case. We would like to show that counting a subhypergraph $H$ in a hypergraph is equivalent to counting $H$ in a $|H|$-partite graph. The issue is that standard approaches for this, even in $2$-uniform graphs, allow this reduction for \emph{detection} but not for counting. For specific graph structures (notably cliques) there are ways to build this reduction. However, for most graph structures getting the counts to line up seems untenable. Such a reduction would strengthen our results, but, also strengthen the many results which use color-coding a sub-routine.  
\let\realbibitem=\bibitem
\def\bibitem{\par \vspace{-0.5ex}\realbibitem}

\bibliographystyle{alpha}
\bibliography{my} 

\appendix






\section{Discussion}
\label{sec:appendix_discussion}
We start with a proof from the main body of the paper and then continue onto general discussion. 

\subsection{Proof of Recursion Lemma}
\label{sec: appendixLemmaRecursion}

We provide the proof of Lemma \ref{lem: inclusion}.

\lemmaInclusion*
\begin{proof}\textcolor{red}{TOPROVE 35}\end{proof}

\subsection{Why Enumerating and Deciding  is Often Easy on Average}
\label{subsec:whyEnumIsEasy}
To build intuition we will start with easy graph cases. Then we will explain why enumerating or deciding small graph structures is always easy in random graphs. Then we will explain why a similar result holds true for databases. 

First, to build intuition, consider the case of triangle. Counting triangles is equivalently hard, up to log factors, in the worst-case and average-case \cite{UniformCliqueABB}. However, any set of $3$ nodes in an Erd{\H{o}}s-R{\'{e}}nyi graph have a $1/8$ chance of being a triangle. This makes enumerating and deciding if a clique exists easy. To enumerate we can start by taking linear time iterating through possible cliques to build up a backlog. Then after every $O(1)$ possible cliques that have been checked enumerate a new clique. With high probability there will be a saved clique to return. For deciding the existence of a clique one can simply return `yes' and be correct with probability at least $1 - (1-1/8)^{n/3}$. 


\subsubsection{Hypergraphs}
The core ideas of both cases apply to all small graphs. If a subgraph (or subhypergraph) has a constant number of nodes $k$ then any one particular set of $k$ nodes will have a constant probability of being the relevant graph structure. There are at most $2^k$ edges and hyperedges in the subgraph and the chance that each of those edges exists or doesn't in the requested direction is $2^{-2^k}$. While this is an ugly looking relationship, it is constant if $k$ is constant (note if there are fewer edge constraints the relationship is much less negative). Now, given that the graph structure has a constant probability of existing we can say the probability of our subhypergraph existing in an Erd{\H{o}}s-R{\'{e}}nyi graph is at least 
$$1- (1 -2^{-2^k})^{n/k}.$$
If $k$ is constant this is $1 - 2^{-\Theta(n)}$. Enumerating these graph structures will similarly be easy with high probability. The expected number of these graph structures is high and enumerating possible subhypergraphs and returning when you find a subhypergraph which meets the condition is sufficient. 


\subsubsection{Databases}
What about in databases? Well, similarly we have a case where we have a small structure we are looking for. In this case, rows that correspond to a query of interest. Every row exists iid with probability $1/2$, so once again, given a choice of elements the relevant queried rows exist with constant probability. This will, once again, make deciding very easy (simply return yes and you will be correct with high probability). When enumerating we can once again take the approach of taking linear time to build up a large number of instances and then after checking $O(1)$ possible query entries return an answer. If we check $\text{LARGE\_CONSTANT} \cdot 2^{2^|\text{SIZE\_OF\_QUERY}|}$ entries each time the probability that we ever run out of instances to return is low. 
 
\end{document}
