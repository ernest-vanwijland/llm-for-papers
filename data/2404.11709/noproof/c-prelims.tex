%We denote by $[r]$ the set $\{1,2,\ldots,r\}$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{CSPs}
%
An instance of the \emph{constraint satisfaction problem} (CSP) is a triple
$\cP=(V,D,\cC)$, where $V$ is a set of variables, $D$ is a set of domain values,
and $\cC$ is a set of constraints. Every constraint in $\cC$ is a pair
$\ang{\bs,\rel}$, where $\bs\in V^r$ is the constraint scope and $\rel\subseteq
D^r$ is the constraint relation of arity $r=ar(R)$. Given a CSP instance $\cP$, the
task is to determine whether there is an assignment $s:V\to D$ that assigns to
every variable from $V$ a value from $D$ in such a way that
all the constraints are satisfied; i.e.,
$(s(v_1),\ldots,s(v_r))\in\rel$ for every constraint
$\ang{(v_1,\ldots,v_r),\rel}\in\cC$. An assignment satisfying all the
constraints is also called a \emph{solution}.

Let $D$ be a fixed finite set. A finite set $\Gm$ of relations over $D$ is
called a \emph{constraint language} over $D$. We denote by $\CSP(\Gm)$ the
class of CSP instances in which all constraint relations belong to $\Gm$. A mapping $\vr:D\to D$ is an \emph{endomorphism} or \emph{unary polymorphism} of $\Gm$ if, for any $\rel\in\Gm$ (say, $r$-ary) and any $(\vc ar)\in\rel$, the tuple $(\vr(a_1)\zd\vr(a_r))$ belongs to $\rel$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Bounded width}

Intuitively, CSPs of bounded width are those CSPs  for which unsatisfiable
instances can be refuted via local propagation. An obvious obstruction to bounded width, in
addition to NP-hard CSPs, is CSPs encoding systems of linear
equations~\cite{Feder98:monotone}. A celebrated result of Barto and Kozik
established that CSPs of bounded width are precisely those CSPs that cannot
simulate, in a precise sense, linear equations~\cite{Barto14:local}. 
While bounded width has several
characterizations~\cite{LaroseZadori07:au,Maroti2008existence,Bulatov09:width,Barto14:local,Kozik15:au},\footnote{One characterization implies that checking whether a constraint language has bounded
width is decidable~\cite{Kozik15:au}.} we will rely on the result of
Kozik~\cite{Kozik21:sicomp} that established that every CSP of bounded width can
be solved through constraint propagation of a very restricted type, so-called
\emph{Singleton Linear Arc-Consistency} (SLAC). 

In order to explain SLAC, we need to start with
\emph{Arc-Consistency} (AC). AC is one of the basic levels of local consistency
notions. It is a property of a CSP and also an algorithm
turning an instance $\cP\in\CSP(\Gm)$ into an equivalent subinstance
$\cP'\in\CSP(\Gm)$ that satisfies the AC property. Intuitively, given an instance $\cP=(V,D,\cC)\in\CSP(\Gm)$,
the AC algorithm starts with setting the domain $D_v=D$ for every variable $v\in
V$. Then, it prunes the sets $\{D_v\}_{v\in V}$ in an iterative fashion,
terminating (in polynomial time in the size of $\cP$) with a maximal subinstance
of $\cP$ that satisfies the AC condition; namely, for every variable $v\in V$, every value $a\in
D_v$, and every constraint $\ang{\bs,\rel}\in\cC$ such that $\bs[i]=v$ for some $i$, there is a tuple $\ba\in\rel$ with
$\ba[i]=a$. 
%
The resulting subinstance $\cP'$ is \emph{equivalent} to $\cP$
in the sense that $\cP$ has a solution if and only if $\cP'$ has a solution. We
say that AC \emph{solves} an instance $\cP$ if $\cP$ has a solution whenever
$\cP'$ is consistent; i.e., none of the sets $D_v$ in $\cP'$ is empty.
%
AC is not strong enough to solve all CSPs of bounded width (e.g., \textsc{2-SAT}) but its
full power is understood~\cite{Feder98:monotone,Dalmau99}.

Equivalently, Arc-Consistency can be described in terms of a Datalog
program~\cite{Kolaitis95:jcss}. In general, a Datalog program derives facts about an
instance $\cP\in\CSP(\Gm)$
using a fixed set of rules that depend on the constraint language $\Gm$. The
rules are defined using relations from $\Gm$ called
\emph{extensional databases} (EDBs) as well as a number of auxiliary relations
called \emph{intensional databases} (IDBs). Each rule consists of a \emph{head},
which is a single IDB, and the \emph{body}, which is a sequence of IDBs and
EDBs. The execution of the program updates the head IDB whenever the body of the
rule is satisfied, that is, every EDB and IDB in the body is satisfied. The computation of the program ends when no relation can be
updated, or when the goal predicate is reached. If we require that a Datalog
program should only include unary IDBs and that every rule should have at most one EDB
then the power of the program for CSPs amounts to AC. 
%
In detail, the AC Datalog program has a unary relation (IDB) $T_S(v)$ for each 
subset $S\sse D$. Then for every $\ang{(\vc vr),\rel}\in\cC$ and for any
IDBs $T_{S_1}\zd T_{S_m}, T_S$ the program contains the rule
\[
T_S(v_i):-\rel(\vc vr),T_{S_1}(v_{i_1})\zd T_{S_m}(v_{i_m})
\]
if for any $\ba\in\rel$ such that $\ba[i_j]\in S_j$ we have $\ba[i]\in S$.
%
The Arc-Consistency algorithm is \emph{Linear} if $m=1$ for every rule in the
corresponding Datalog program. 

The Singleton Arc-Consistency (SAC) algorithm is a modification of
the AC algorithm~\cite{DB97}. SAC updates the sets $\{D_v\}_{v\in V}$
as follows: it removes $a$ from $D_v$ if the current
instance augmented with the constraint fixing the value $a$ to the variable $v$ is
found inconsistent by the AC algorithm. 
%
Finally, the Singleton Linear Arc-Consistency algorithm is a modification of SAC
(due to Kozik~\cite{Kozik21:sicomp} and Zhuk~\cite{Zhuk20:jacm}) that uses the
Linear AC algorithm rather than the AC algorithm. Kozik has shown that SLAC
solves all CSPs of bounded width~\cite{Kozik21:sicomp}.
%
As with AC, SLAC is not only an algorithm but also a condition (of the instance
$\cP'$ produced by the algorithm). We say that an instance
$\cP$ is SLAC-consistent if the SLAC algorithm, given in Figure~\ref{fig:slac},
does not change the instance.

\begin{figure}
\begin{itemize}\setlength\itemsep{-3pt}
\item[Input:]
A CSP instance $\cP=(V,D,\cC)$.
\item[Output:]
A SLAC-consistent instance $\cP'$ equivalent to $\cP$
\item[1.]
{\bf for each} $v\in V$ {\bf set} $D_v=D$
\item[2.]
$\cP'=\cP+\sum_{v\in V}\ang{v,D_v}$
\item[3.]
{\bf until} the process stabilizes
\begin{itemize}
\item[3.1]
{\bf pick} a variable $v\in V$
\item[3.2]
{\bf for each} $a\in D_v$ {\bf do}
\begin{itemize}
\item[3.2.1]
{\bf run} Linear Arc-Consistency on $\cP'+\ang{v,\{a\}}$
\item[3.2.2]
{\bf if} the problem is inconsistent, {\bf set} $D_v=D_v-\{a\}$
\end{itemize}
\item[]
{\bf endfor}
\end{itemize}
\item[]
{\bf enduntil}
\item[4.]
{\bf return} $\cP'$
\end{itemize}
%\vspace*{-0.7cm}
\vspace*{-1.2cm}
\caption{SLAC.}\label{fig:slac}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Multi-dimensional Fourier transform}\label{sec:multi-FT}

Let $U_d$ be the set of $d$-th roots of unity, that is,
$U_d=\{\ld_k=e^{\frac{2\pi i}d k}\mid 0\le k<d\}$.
The \emph{Fourier transform} (FT) of a function $f:U_d^n\to U_d$ is defined, for 
$\ba\in U_d^n$, as
$
FT(f,\ba)=\sum_{\bb\in U_d^n}f(\bb)\ld_1^{\ba\cdot\bb}$.
Then it is not hard to see that 
$
f(\ba)=\sum_{\bb\in U_d^n}FT(f,\bb)\ld_1^{\ba\cdot\bb}$,
which gives rise to a representation of $f$ by a polynomial
\[
f(\ov x)=\sum_{\bb\in U_d^n}FT(f,\bb)\ov x^{\bb'},
\]
where $\bb'=(\vc kn)$ and $\bb[j]=\ld_{k_j}$. This representation is
unique~\cite{ODonnell14:book}.

\paragraph{Linear operators and Hilbert spaces}
%
Let $V$ be a complex vector space. A \emph{linear operator} on $V$ is a linear
map from $V$ to $V$. The identity linear operator on $V$ is denoted by $I$. The
linear operator that is identically $0$ is denoted by $0$. 
%
Let $A$ and $B$ be two linear operators. Their pointwise addition is denoted by $A+B$, their
composition is denoted by $AB$, and the pointwise scaling of $A$ by a scalar
$c\in\zC$ is denoted by $cA$. All of these are linear operators and thus we can
plug linear operators in a polynomial $P$. 
%
We say that operators $A$ and $B$ \emph{commute} if
$AB=BA$. A collection of linear operators $A_1,\ldots,A_n$ \emph{pairwise commute} if $A_iA_j=A_jA_i$ for every $i,j\in [n]$. 
%
If $A_1,\ldots,A_n$ pairwise commute then $P(A_1,\ldots,A_n)$ is well defined.
%
$\zC[x_1,\ldots,x_n]$ denotes the ring of polynomials with complex coefficients and commuting variables $x_1,\ldots,x_n$. 
%
A linear operator is \emph{bounded} if it maps bounded subsets to bounded
subsets. Let $A$ be a densely defined linear operator, i.e., $A$ is defined
almost everywhere. We denote by $A^*$ its \emph{adjoint}~\cite{Folland94}
and call $A$ \emph{normal} if $A$ commutes with its adjoint, i.e., $AA^*=A^*A$.
A linear operator $U$ is called \emph{unitary} if $UU^*=U^*U=I$, the identity
operator.

A \emph{Hilbert space} is a complex vector space with an inner product whose
norm induces a complete metric.
All Hilbert spaces of finite dimension $d$ are
isomorphic to $\zC^d$ with the standard complex inner product. Thus, 
after the choice of basis, linear operators on a $d$-dimensional Hilbert space
can be identified with matrices in $\zC^{d\times d}$, and operator composition
becomes matrix multiplication. 
%
Thus, for Hilbert spaces of finite dimension we will
freely switch between the operator and matrix terminology.
%
A \emph{diagonal} matrix has all off-diagonal
entries equal to $0$. 
For a matrix $A$, the adjoint operator $A^*$ is the conjugate transpose.
%
Recall that $(AB)^*=B^*A^*$.
%
We will use the following form of the so-called \emph{strong spectral
theorem}.
%
\begin{theorem}[\cite{Halmos2017introduction}]
\label{the:SST}
Let $\vc Ar$ be normal matrices. If $\vc Ar$ pairwise
commute then there exists a unitary matrix $U$ and diagonal matrices 
$\vc Er$ such that $A_i=U^{-1}E_iU$ for every $i\in[r]$.
\end{theorem}

In the infinite-dimensional case, the Strong Spectral Theorem is more
complicated. Firstly, it involves general $L^2$- and $L^\infty$-spaces. Let
$(\Omega,\cM,\mu)$ be a measure space, i.e., $\Omega$ is a set, $\cM$ is a
$\sigma$-algebra on the set $\Omega$ (i.e. $\cM$ is a nonempty collection of
subsets of $\Omega$ containing $\Omega$ and closed under complements, countable intersections, and
countable unions), and $\mu$ is a measure on $(\Omega,\cM)$ (i.e. $\mu$ is
nonnegative and countably additive). Then $L^2(\Omega,\mu)$ denotes
the collection of square integrable measurable functions, up to almost
everywhere equality, and $L^\infty(\Omega,\mu)$ denotes the
collection of essentially bounded measurable functions, up to almost everywhere equality; all measure-theoretic terms in
these definitions refer to $\mu$, cf.~\cite{Folland94} for details. Instead of diagonal matrices, the General Strong Spectral Theorem uses \emph{multiplication operators} on a $L^2(\Omega,\mu)$-space. Let $V$ be a complex vector space of functions mapping an index set $X$ to $\zC$. A multiplication operator of $V$ is a linear operator whose value at a function $f:X\to\zC$ in $V$ is given by pointwise multiplication by a fixed function $a:X\to\zC$. In other words, the multiplication operator given by $a$ is
\[
(T_a(f))(x)=a(x)f(x)\qquad\text{for each $x\in X$}.
\]

\begin{theorem}[General Strong Spectral Theorem~\cite{Folland94}]\label{the:general-sst}
Let $\vc Ar$ be normal bounded linear operators on a Hilbert space $\cH$. If $\vc Ar$ pairwise commute then there exist measure space $(\Omega,\cM,\mu)$, a unitary map $U:\cH\to L^2(\Omega,\mu)$, and functions $\vc ar\in L^\infty(\Omega,\mu)$ such that $A_i=U^{-1}T_{a_i}U$ for every $i\in[r]$.
\end{theorem}

