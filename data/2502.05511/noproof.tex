\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsthm,amsfonts,amsmath,amssymb,mathtools}
\usepackage{enumerate,graphicx}
\usepackage{xspace}
\usepackage{boxedminipage}
\usepackage{url}
\usepackage{accents}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{fullpage}
\usepackage{tikz}
\usepackage{natbib}
\usepackage[bookmarks=false,
breaklinks=false,pdfborder={0 0 1},colorlinks=true,allcolors=blue]{hyperref} \usepackage{placeins}

\graphicspath{{img/}}

\DeclareRobustCommand{\evict}{\mathrm{evict}}

\usepackage{style}

\def\script#1{\mathcal{#1}}
\def\sP{\script{P}}


\usepackage{algorithm}
\usepackage{algpseudocode}


\newcommand{\ali}[1]{\textcolor{red}{[Ali: #1]}}
\newcommand{\chirag}[1]{\textcolor{blue}{[Chirag: #1]}}




\author{
    Chirag Pabbaraju\thanks{Stanford University. Email: \texttt{cpabbara@cs.stanford.edu.}}
    \and
    Ali Vakilian\thanks{Toyota Technological Institute at Chicago. Email: \texttt{vakilian@ttic.edu.}}
}


\title{New and Improved Bounds for Markov Paging}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
    In the Markov paging model, one assumes that page requests are drawn from a Markov chain over the pages in memory, and the goal is to maintain a fast cache that suffers few page faults in expectation. While computing the optimal online algorithm $(\mathrm{OPT})$ for this problem naively takes time exponential in the size of the cache, the best-known polynomial-time approximation algorithm is the dominating distribution algorithm due to Lund, Phillips and Reingold (FOCS 1994), who showed that the algorithm is $4$-competitive against $\mathrm{OPT}$. We substantially improve their analysis and show that the dominating distribution algorithm is in fact $2$-competitive against $\mathrm{OPT}$. We also show a lower bound of $1.5907$-competitiveness for this algorithm---to the best of our knowledge, no such lower bound was previously known.
\end{abstract} 
\newpage
\section{Introduction}
\label{sec:intro}


The online paging problem is a fundamental problem in the area of online
algorithms. There are $n$ pages in slow memory, and requests for these pages arrive in a sequential manner. We are allowed to maintain a fast cache of size $k$, which initially comprises of some $k$ pages. At time step $t$, if the page that is requested, say $p_t$, exists in the cache, this corresponds to a cache hit: we suffer a zero cost, the cache stays as is, and we move on to the next request. Otherwise, we incur a cache miss/page fault, suffer a unit cost, and are forced to evict some page from the cache so as to bring $p_t$ from the slow memory into the cache. A paging algorithm/policy is then specified by how it chooses the page to evict whenever it suffers a cache miss.

An optimal offline algorithm for this problem is the algorithm that has entire knowledge of the page request sequence, and thereafter makes its eviction choices in a way that minimizes the total number of cache misses it incurs. The classical Farthest-in-Future algorithm \citep{belady1966study}, which at any cache miss, evicts the page that is next requested latest in the remainder of the sequence, is known to be an optimal offline policy. In the spirit of competitive analysis as introduced by \cite{sleator1985amortized}, one way to benchmark any online algorithm (i.e., one which does not have knowledge of the page request sequence) is to compute the ratio of the number of page faults that the algorithm suffers, to the number of page faults that the optimal offline algorithm suffers, on a \textit{worst-case} sequence of page requests. It is known that any deterministic online algorithm has a worst-case ratio that is at least $k$, while any randomized online algorithm has a worst-case ratio of $\Omega(\log k)$.

Taking a slightly more optimistic view, one can also consider benchmarking an algorithm against the best \textit{online} algorithm, that does not know beforehand the realized sequence of page requests. Additionally, in the context of beyond worst-case analysis, one can impose assumptions on the sequence of page requests to more accurately model the behavioral characteristics of real-world page requests on computers. For example, page requests generally follow the \textit{locality of reference} principle, either in time (the next time a particular page is requested is close to its previous time) or in space (the page that will be requested next is likely to be in a nearby memory location).

The Markov Paging model, introduced by \cite{karlin1992markov}, is one of the ways to model such locality of reference in the page requests. The model assumes that page requests are drawn from a (known) Markov chain over the entire set of $n$ pages. Once such a distributional assumption over the page requests is imposed, one can ask how an online paging algorithm fares, in comparison to the optimal online algorithm that suffers the smallest number of page misses \textit{in expectation} over the draw of a page sequence from the distribution. As it turns out, one can compute such an optimal online algorithm, but only in time exponential in the cache size $k$. Therefore, one seeks efficient polynomial-time algorithms that are approximately optimal.

In 1994, \cite{lund1994ip} proposed an extremely elegant randomized algorithm for the Markov Paging problem, known as the dominating distribution algorithm. The dominating distribution algorithm, whenever it suffers a cache miss, evicts a random page drawn from a special distribution, which has the property that a randomly drawn page is likely to be next requested latest among all the existing pages in the cache. This algorithm, which has since become a popular textbook algorithm due to its simplicity (e.g., see Chapter 5 in \cite{borodin2005online}, or the lecture notes by \cite{roughgardennotes}), runs in time polynomial in $k$; furthermore, \cite{lund1994ip} show that the algorithm suffers only 4 times more cache misses in expectation than the optimal online algorithm. Since then, this has remained state-of-the-art---we do not know any other polynomial-time algorithms that achieve a better performance guarantee. It has nevertheless been conjectured that the above guarantee for the dominating distribution algorithm is suboptimal (e.g., see Section 6.2 in \cite{roughgardennotes}).


Our main result in this work establishes an improved upper bound for the dominating distribution algorithm.

\begin{theorem}
    \label{thm:dominating-distribution-improved-bound}
    The dominating distribution algorithm suffers at most 2 times more cache misses in expectation compared to the optimal online algorithm in the Markov Paging model.\end{theorem}
In fact, as mentioned in \cite{lund1994ip}, our guarantee for the performance of the dominating distribution algorithm holds more generally for \textit{pairwise-predictive} distributions. These are distributions for which one can compute any time, for any pair of pages $p$ and $q$ in the cache, the probability that $p$ is next requested before $q$ in the future (conditioned on the most recent request).

While the dominating distribution algorithm is a randomized algorithm, \cite{lund1994ip} also propose and study a simple deterministic algorithm for the Markov Paging model, known as the median algorithm. On any cache miss, the median algorithm evicts the page in cache that has the largest median time at which it is requested next. \cite{lund1994ip} show that the median algorithm suffers at most 5 times more cache misses in expectation than the optimal online algorithm---to the best of our knowledge, this is the state of the art for deterministic algorithms. As an additional convenient consequence of our improved analysis, we are also able to improve the performance guarantee for the median algorithm.

\begin{theorem}
    \label{thm:median-improved-bound}
    The median algorithm suffers at most 4 times more cache misses in expectation compared to the optimal online algorithm in the Markov Paging model.
\end{theorem}

Given the improved performance guarantee in \Cref{thm:dominating-distribution-improved-bound}, one can ask: is this the best bound that we can show for the dominating distribution algorithm? Or is there hope to show that it is \textit{the} optimal online algorithm? A detail here is that the dominating distribution algorithm is defined as any algorithm satisfying a specific property (see \eqref{eqn:dominating-distribution-property}); in particular, there can exist different dominating distribution algorithms. Our upper bound (\Cref{thm:dominating-distribution-improved-bound}) holds uniformly for \textit{all} dominating distribution algorithms. However, our next theorem shows a lower bound that at least one of these is significantly suboptimal. 

\begin{theorem}
    \label{thm:dominating-distribution-lower-bound}
    There exists a dominating distribution algorithm that suffers at least $1.5907$ times more cache misses in expectation compared to the optimal online algorithm in the Markov Paging model.
\end{theorem}

\Cref{thm:dominating-distribution-lower-bound} shows that one cannot hope to show optimality uniformly for all dominating distribution algorithms. To the best of our knowledge, no such lower bounds for the dominating distribution algorithm have been previously shown. While we believe that the bound in \Cref{thm:dominating-distribution-improved-bound} is the correct bound, it is an interesting open direction to close the gap between the upper and lower bound. 

Finally, we also consider a setting where the algorithm does not exactly know the Markov chain generating the page requests, but only has access to a dataset of past page requests. In this case, one can use standard estimators from the literature to approximate the transition matrix of the Markov chain from this dataset. But can an approximate estimate of the transition matrix translate to a tight competitive ratio for a paging algorithm, and if so, how large of a dataset does it require to achieve it? The robustness of the analysis\footnote{In fact, we borrow this robustness from the original analysis of \cite{lund1994ip}.} of \Cref{thm:dominating-distribution-improved-bound} lets us derive a precise learning-theoretic result (\Cref{thm:learning-markov-chains} in \Cref{sec:robustness}) showing that the dominating distribution algorithm, when trained on a dataset of size $O(n^2/\eps^2)$, is no more than $\frac{2}{1-2\eps}$ times worse than the optimal online algorithm on a fresh sequence of page requests. 

This result is especially relevant in the context of data-driven and learning-augmented algorithms. For instance, by treating the learned Markov chain as a learned oracle and combining it with a worst-case approach, such as the Marker algorithm, similarly to the approach proposed in~\citep{mahdian2012online,lykouris2021competitive}, the resulting algorithm achieves $O(1)$-consistency and $O(\log k)$-robustness guarantees for the online paging problem.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}\hline
    Algorithm & Reference & Upper Bound & Lower Bound \\\hline
    \multirow{4}{*}{} & \multirow{2}{*}{\cite{lund1994ip}} & 4 & \multirow{2}{*}{-} \\
      Dominating Distribution  &  & (Theorem 3.5) & \\ \cline{2-4}
      (Randomized) & \multirow{2}{*}{This Work} & \textbf{2} & \textbf{1.5907} \\
      & & (\Cref{thm:dominating-distribution-improved-bound}) & (\Cref{thm:dominating-distribution-lower-bound}) \\ \hline 
    \multirow{4}{*}{} & \multirow{2}{*}{\cite{lund1994ip}} & 5 & \textbf{1.511}\footnotemark  \\
      Median  &  & (Theorem 2.4) & (Theorem 5.4) \\ \cline{2-4}
      (Deterministic) & \multirow{2}{*}{This Work} & \textbf{4} & \multirow{2}{*}{-} \\
      & & (\Cref{thm:median-improved-bound}) & \\ \hline
    \end{tabular}
    \caption{State of the art for Markov Paging (best-known bounds are in bold). Both the median and the dominating distribution algorithm are due to \cite{lund1994ip}.}
    \label{table:summary}
\end{table}
\footnotetext{\cite{lund1994ip} only provide a proof for a lower bound of 1.4, but mention that they also obtained 1.511.}

\subsection{Other Related Work}
\label{sec:related-work}



There is a rich literature by this point on studying the online paging problem under assumptions on the permissible page requests that are supposed to model real-world scenarios (see e.g., the excellent surveys by \cite{irani2005competitive} and \cite{dorrigiv2005survey}). In particular, several models are motivated by the aforementioned locality of reference principle. The access graph model, proposed originally by \cite{borodin1991competitive}, and developed further in the works of \cite{irani1992strongly}, \cite{fiat1995randomized} and \cite{fiat1997truly}, assumes an underlying graph on the pages, which a request sequence is supposed to abide by. Namely, if a page $p_t$ has been requested at time $t$, then only the neighbors of $p_t$ in the graph may be requested at time $t+1$. In this sense, the Markov Paging model can be thought of as a probabilistic variant of the access graph model.
\cite{torng1998unified} models locality of reference based on the ``working sets'' concept, introduced by~\cite{denning1968working}, and also shows how a finite lookahead of the page sequence can be used to obtain improved guarantees. A related form of competitive analysis, proposed by \cite{koutsoupias2000beyond}, assumes that there is a family of valid distributions, and page sequences are drawn from some distribution belonging to this family. The goal of an algorithm is then to be simultaneously competitive with the optimal algorithm for every distribution in the family. A particular family of interest suggested by \cite{koutsoupias2000beyond} (which is incomparable to the Markov Paging model) is that of \textit{diffuse adversaries}, which has since been developed further in follow-up works by \cite{young1998bounding, young2000line} and \cite{becchetti2004modeling}. Finally, \cite{angelopoulos2009paging} study paging under the \textit{bijective analysis} framework, which compares the performance of two algorithms under bijections on page request sequences.




 \section{Background and Setup}
\label{sec:background}



\subsection{Markov Paging}
\label{sec:markov-paging}

The Markov Paging model assumes that the page requests are drawn from a time-homogeneous Markov chain, whose state space is the set of all pages. More precisely, the Markov Paging model is specified by an initial distribution on the $n$ pages, and a transition matrix $M \in [0,1]^{n \times n}$, where $M_{i,j}$ specifies the probability that page $j$ is requested next, conditioned on the most recently requested page being $i$. The form of the initial distribution will not be too important for our purposes, but for concreteness, we can assume it to be the uniform distribution on the $n$ pages. It is typically assumed that the transition matrix $M$ is completely known to the paging algorithm/page eviction policy---however, the realized page sequence is not. Upon drawing $T$ page requests from the Markov chain, the objective function that a page eviction policy $\mcA$ seeks to minimize is:
\begin{align}
    \label{eqn:objective}
    \E[\cost(\mcA, T)] &= \E_{M, \mcA}\left[\sum_{t=1}^T\Ind[\text{$\mcA$ suffers a cache miss at time $t$}]\right],
\end{align}
where the expectation is with respect to both the random page request sequence drawn from $M$, and the randomness in the policy $\mcA$. We denote by $\opt$ the policy that minimizes the objective in \eqref{eqn:objective}. For $c \ge 1$, an eviction policy $\mcA$ is said to $c$-competitive against $\opt$ if for every $T$, $ \E[\cost(\mcA, T)] \le c \cdot \E[\cost(\opt, T)]$.

It is worth emphasizing again that the competitive analysis above is with respect to the optimal \textit{online} strategy, in that $\opt$ does not know beforehand the realized sequence of page requests. Contrast this to the best \textit{offline} strategy, which also additionally knows the realized sequence of page requests. As mentioned previously, the Farthest-in-Future policy \citep{belady1966study}, which at any cache miss, evicts the page that is next requested latest in the remainder of the sequence, is known to be an optimal offline policy. 

It is indeed possible to compute $\opt$ exactly---however, the best known ways do this are computationally very expensive, requiring an exponential amount of computation in $k$.

\begin{theorem}[Theorems 1, 2 in \cite{karlin1992markov}]
    \label{thm:opt-computation}
    The optimal online policy that minimizes $\lim_{T \to \infty}\frac{1}{T}\cdot\E[\cost(\mcA, T)]$ over all policies $\mcA$ can be computed exactly by solving a linear program in $n\binom{n}{k}$ variables. Furthermore, for any finite $T$, an optimal online policy that minimizes $\E[\cost(\mcA, T)]$ can be computed in time $T \cdot n^{\Omega(k)}$. \end{theorem}

In the latter case above when $T$ is finite, the optimal online policy can be computed, for example, via dynamic programming (using the ``Bellman operator''), where one writes the recurrence for taking a single step of the optimal policy, and unrolls time backwards from $T$. However, the state space in the dynamic program comprises of all $\{$cache state, requested page$\}$ pairs---there are $n^{\Omega(k)}$ many of these. Similarly, the linear program in the case where $T \to \infty$ also comprises of a single variable for each such state. Unfortunately, we do not know of any better algorithms that are both optimal and run in polynomial time in $k$. Therefore, one seeks efficient polynomial time (in $k$) algorithms that are approximately optimal, i.e., achieve $c$-competitiveness with $\opt$ for $c$ as close to $1$ as possible.

Towards this, \cite{karlin1992markov} showed that several intuitive eviction policies (e.g., on a cache miss, evict the page in cache that has the largest \textit{expected} time to be requested next) are necessarily at least an $\Omega(k)$ factor suboptimal compared to $\opt$. They then showed a policy $\mcA$ that is provably $O(1)$-competitive against $\opt$; however, the constant in the $O(1)$ is somewhat large. Thereafter, \cite{lund1999paging}\footnote{We reference the journal version \citep{lund1999paging} in lieu of the conference version \citep{lund1994ip} hereafter.} proposed a simple and elegant polynomial-time policy, referred to as the \textit{dominating distribution algorithm}, and showed that it achieves $4$-competitiveness against $\opt$. We describe this policy ahead.

\subsection{Dominating Distribution Algorithm}
\label{sec:dominating-distribution}

The dominating distribution algorithm, which was proposed by \cite{lund1999paging} and is denoted $\mcA_\dom$ hereon, operates as follows. At any page request, if $\mcA_\dom$ suffers a cache miss, it computes a so-called \textit{dominating} distribution $\mu$ over the currently-existing pages in the cache. Thereafter, it draws a page $p \sim \mu$, and evicts $p$. First, we will specify the properties of this dominating distribution. 

Intuitively, we want $\mu$ to be a distribution such that a \textit{typical} page drawn from $\mu$ will be highly likely to be next requested later than \textit{every} other page in the cache. Formally, suppose that the most recently requested page (that caused a cache miss) is $s$. Fix any two pages $p$ and $q$ (not necessarily in the cache), and let
\begin{align}
    \label{eqn:alpha-q-p-def}
    \alpha(p<q|s) := \Pr_M[\text{$p$ is next requested before $q$ }|\text{ $s$ is the most recently requested page}],
\end{align}
and let $\alpha(p<p|s)=0$ for all pages $p$. Here, the probability is only over the draw of page requests from the Markov chain.
The claim is that these $\alpha(p<q|s)$ values can be computed efficiently, in total time $O(n^4)$ for all pairs $p,q$ in cache, provided that we know the transition matrix $M$. To see this, let $x_s=\alpha(p<q|s)$. Note that $x_p=1$, $x_q=0$. For any other page $r \neq p,q$, note that
\begin{align*}
    x_r = M_{r,1}x_1 + \dots + M_{r,n}x_n.
\end{align*}
Thus, upon solving the linear system given by
\begin{align}
    \label{eqn:linear-system-for-alpha}
    \begin{bmatrix}
        M_{1,1} - 1 & M_{1,2} & \dots & M_{1,n} \\
        M_{2,1} & M_{2,2} -1 & \dots & M_{1,n} \\
        \vdots & \vdots & \cdots & \vdots\\
        \boldsymbol{e_p} \\
        \vdots & \vdots & \cdots &\vdots \\
        \boldsymbol{e_q} \\
        \vdots & \vdots & \cdots & \vdots \\
        M_{n,1} & M_{n,2} & \dots & M_{n,n}-1
    \end{bmatrix}
    \begin{bmatrix}
        x_1 \\ x_2 \\ \vdots \\ x_p \\ \vdots \\ x_q \\ \vdots \\ x_n
    \end{bmatrix} = 
    \begin{bmatrix}
        0 \\ 0 \\ \vdots \\ 1 \\ \vdots \\ 0 \\ \vdots \\ 0
    \end{bmatrix},
\end{align}
where $\boldsymbol{e_p}$ and $\boldsymbol{e_q}$ are row vectors with a $1$ in the $p^{\text{th}}$ and $q^{\text{th}}$ coordinates, respectively, and $0$ elsewhere, $x_s$ is the desired value $\alpha(p<q|s)$. In this way, we can solve a linear system for each of the $\le n^2$ possible pairs for $q,p$, and compute all $\alpha(p<q|s)$ values in time $O(n^4)$. For notational convenience, we will hereafter frequently denote $\alpha(p<q|s)$ simply by $\alpha(p<q)$, implicitly assuming conditioning on the most frequently requested page.


Equipped with all these $\alpha(p<q)$ values, let us define $\mu$ to be a distribution over the pages in the cache satisfying the following property: for every fixed page $q$ in the cache,
\begin{align}
    \label{eqn:dominating-distribution-property}
    \E_{p \sim \mu}[\alpha(p<q)] \le \frac{1}{2}.
\end{align}
This is the required dominating distribution. What may be somewhat surprising here is that such a dominating distribution, which satisfies the condition in \eqref{eqn:dominating-distribution-property} provably \textit{always} exists, and furthermore can be constructed efficiently by solving a linear program with just $O(k)$ variables (i.e., in $\poly(k)$ time).
\begin{theorem}[Theorem 3.4 in \cite{lund1999paging}]
    \label{thm:dominating-distribution-exists}
    A distribution $\mu$ satisfying the condition in \eqref{eqn:dominating-distribution-property} necessarily exists and can be computed by solving a linear program in $O(k)$ variables.
\end{theorem}
Thus, the total computation required by $\mcA_\dom$ at each cache miss is only $\poly(k)$ (to solve the linear program that constructs $\mu$), assuming all $\alpha(p<q)$ values are precomputed initially. In summary, the overall computation cost of $\mcA_\dom$ across $T$ page requests is at most $T \cdot \poly(n, k)$.

It remains to argue that if $\mcA_\dom$ evicts $p \sim \mu$ whenever it suffers a cache miss, then it fares well in comparison to $\opt$. A convenient observation towards showing this is the following claim, whose proof follows from the definition of $\mu$:
\begin{claim}
    \label{claim:dominating-distribution-probability}
    Let $s$ be the most recently requested page. The dominating distribution $\mu$ satisfies the following property: for every fixed page $q$ in the cache, we have that
    \begin{align}
        \Pr_{p \sim \mu, M}[\text{$q$ is next requested no later than $p$ }|\text{ $s$ is the most recently requested page}] \ge \frac{1}{2}.
    \end{align}
\end{claim}
\begin{proof}\textcolor{red}{TOPROVE 0}\end{proof}

Using this property of $\mu$, \cite{lund1999paging} show that $\mcA_\dom$ incurs only $4$ times as many cache misses as $\opt$ in expectation. The following section provides this part of their result.

 \section{4-competitive Analysis of \cite{lund1999paging}}
\label{sec:lpr}

We restate and provide a more detailed proof of the crucial technical lemma from \cite{lund1999paging}, which is particularly useful for our improved $2$-competitive analysis in Section~\ref{sec:tight-analysis}.

\begin{lemma}[Lemma 2.5 in \cite{lund1999paging}]
    \label{lem:lpr}
    Let $\mcA$ be a paging algorithm. Suppose that whenever $\mcA$ suffers a cache miss, the page $p$ that it chooses to evict is chosen from a distribution such that the following property is satisfied: for every page $q$ in the cache, the probability (over the choice of $p$ and the random sequence ahead, conditioned on the most recently requested page) that $q$ is next requested no later than the next request for $p$ is at least $1/c$. Then $\mcA$ is $2c$-competitive against $\opt$.
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 1}\end{proof}

\begin{corollary}
    \label{corollary:dom-is-4-competitive}
    The dominating distribution algorithm $\mcA_\dom$ is 4-competitive against $\opt$.
\end{corollary}
\begin{proof}\textcolor{red}{TOPROVE 2}\end{proof}

\begin{remark}
    \label{remark:suboptimal-fifo}
    Consider setting $c=1$ in \Cref{lem:lpr}: this corresponds to $\mcA$ effectively being an \textit{offline} algorithm, which \textit{knows} which page in the cache is going to next be requested farthest in the future compared to all the other pages in the cache. We already know that such an algorithm is optimal, i.e., is 1-competitive against $\opt$. However, the guarantee given by \Cref{lem:lpr} for such an algorithm is still only $2$-competitiveness. This at least suggests that there is scope to improve the guarantee to $c$-competitiveness. \end{remark}
 \section{Sources of Looseness in the Analysis}
\label{sec:looseness}
We systematically identify the sources of looseness in the above analysis with illustrative examples, before proceeding to individually tighten them in the subsequent section.

\subsection{A Conservative Approach to Handling Doubly-Charged Pages}
\label{sec:looseness-double-counting}

Recall that in the summation $\sum_{t \le T} \beta(t)$ above, a cache miss for $\opt$ may be double-counted if the same page is assigned two charges. Although one way to address this overcounting is to divide the summation by 2, this approach is overly conservative, as it \textit{under}counts every cache miss in $\opt$ that results from a request to a singly-charged page. For instance, consider the following situation:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{img/double-counting.png}
    \caption{Request for $q$ (a singly charged page) at $t_2$ constitutes a unit cache miss for $\opt$, but the division by 2 undercounts this (and every other singly-charged cache miss in $\opt$).}
    \label{fig:double-counting}
\end{figure}
Here, at time $t_1$, $\mcA$ evicts a page $p$. Suppose that $p$ continues to live in the cache of $\opt$ after the request at $t_1$, and hence $c(p)$ is assigned to some $q$ in $\mcA$'s cache. Now, say that $q$ is requested at time $t_2$, which is before $t_3=r(t_1, p)$. Furthermore, assume that at $t_2$, $q$ only had the single charge on itself (by $p$), i.e., $q$ was not evicted by $\mcA$ in the time between $t_1$ and $t_2$. Then, $\beta(t_1)=1$, but we are wastefully dividing it by 2 in our calculation.

\subsection{Inexhaustive Clearing of Charges upon a Page Request}
\label{sec:looseness-uncleared-charges}

Consider the first item in the charging scheme (\Cref{item:clear-charges})---whenever a page $s$ is requested, any charges that $s$ might be \textit{giving} are cleared (i.e., $c(s)=\emptyset$). Intuitively, this is supposed to account for the fact that, while $s$ was holding some page $c(s)$ responsible for being requested before $s$ itself, either this did happen, in which case we happily clear the already-paid charge, or this did not quite happen and $s$ got requested before $c(s)$, in which case we should let go of the charge and focus on the future. However, consider instead the case where $s$ does not have a charge on any other page, but is itself the bearer of a charge by some other page, say $p$. In this case, $s$ has successfully paid the charge that was expected of it---\textit{but this charge would only be cleared upon the next request to $p$!} If it so happens that $p$ is next requested \textit{after} the time horizon $T$, then even if $s$ successfully paid the charge due to $p$, since this charge was not cleared when it was requested, it would be counted in $\mcO$ as part of the open charges post time $T$, and wastefully subtracted in the calculation. This is concretely illustrated in the situation below:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.45]{img/uncleared-charges.png}
    \caption{Here, $\beta(t_1)=1$, and $\opt$ suffers a cache miss at $t_2$. However, $p$ still holds a charge on $s$ at time $T$ because it is requested at $t_3 > T$. Thus, this charge is included in $\mcO$, canceling out the contribution due to the cache miss at $t_2$.}
    \label{fig:uncleared-charges}
\end{figure}
This suggests that whenever a page is requested, we should clear not only the charges it gives but also any charges it {\em bears}, preventing unnecessary inclusion in $\mcO$. This approach ensures that a page discards its imposed charge immediately upon ``paying it off" rather than with a delay.

\subsection{No Accounting for Uncharged, Non-first-timer Pages}
\label{sec:looseness-uncharged-non-first-time}

Finally, observe that in the accounting of cache misses for $\opt$, we only count those that occur due to requests to charged/savior pages (as counted by the $\beta(t)$'s), and those that occur due to first-time requests to pages not initially in the cache (as counted by $\mcI$). However, $\opt$ can also suffer cache misses due to a request to an \textit{uncharged} page. Namely, if there is a request to a page $q$ that was previously evicted by $\opt$, but at the time that it is requested, $q$ is bearing no charges at all, then the cache miss due to $q$ is not being counted in the calculation. This is illustrated by the scenario below: 
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.45]{img/uncharged-eviction.png}
    \caption{At $t_3$, $q$ does not have any charges on it, but still causes a cache miss for $\opt$.}
    \label{fig:uncharged-eviction}
\end{figure}
$\mcA$ evicts $p$ at time $t_1$ and assigns a charge to $q \neq p$, implying that $q$ is not in the cache of $\opt$ after the request at $t_1$ (but was instead previously evicted by $\opt$). Next, at $t_2$, $p$ is requested, and this clears the charge it had on $q$. Since $p$ got requested before $q$, $\beta(t_1)=0$. Then, at $t_3$, $q$ is requested---$q$ has no charges on it at this point. Notice that this still causes a cache miss for $\opt$ at $t_3$. However, this cache miss is not accounted for in our calculation, either by $\beta(t_1)$, or by $\mcI$ (since this is not the first time that $q$ is being brought into the cache).
 \section{Tightening the Analysis to 2-competitiveness}
\label{sec:tight-analysis}
Having identified the loose ends in the analysis of \cite{lund1999paging} above, we are able to tighten their analysis and prove the following lemma:
\begin{lemma}
    \label{lem:tight-analysis}
    Let $\mcA$ be a paging algorithm. Suppose that whenever $\mcA$ suffers a cache miss, the page $p$ that it chooses to evict is chosen from a distribution such that the following property is satisfied: for every page $q$ in the cache, the probability (over the choice of $p$ and the random sequence ahead, conditioned on the most recently requested page) that $q$ is next requested no later than the next request for $p$ is at least $1/c$. Then $\mcA$ is $c$-competitive against $\opt$.
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 3}\end{proof}

\begin{corollary}
    \label{corollary:dom-is-2-competitive}
    The dominating distribution algorithm $\mcA_\dom$ is 2-competitive against $\opt$.
\end{corollary}
\begin{proof}\textcolor{red}{TOPROVE 4}\end{proof}

\begin{remark}
    \label{remark:optimal-fifo}
    As in \Cref{remark:suboptimal-fifo}, if we set $c=1$ in \Cref{lem:tight-analysis}, our lemma says that a policy that has essentially seen the future and evicts the page that is next scheduled to be requested latest is 1-competitive against $\opt$, i.e., it is optimal. Thus, our analysis, while establishing the best-possible guarantee for algorithms satisfying the condition of the lemma, additionally recovers an alternate, charging-scheme-based proof of the optimality of the Farthest-in-Future eviction policy.
\end{remark}

\begin{remark}
    \label{remark:2-correct-answer-for-dom}
    The factor of 4 in the analysis of \cite{lund1994ip} constituted a factor of 2 arising due to doubly-charged pages, and a factor of 2 arising from the property of the dominating distribution algorithm. While we got rid of the first factor, the second factor appears to be necessary, stemming from an inherent property (\Cref{eqn:dominating-distribution-property}) of the algorithm itself. It would indeed be very interesting to see if this is not the case, and if the upper bound could further be improved from 2.
\end{remark}

\Cref{lem:tight-analysis} also allows us to improve the approximation guarantee for another intuitive \textit{deterministic} algorithm considered by \cite{lund1999paging}, namely the \textit{median} algorithm. At any cache miss, the median algorithm evicts the page in cache that has the largest median time of next request. For deterministic algorithms satisfying the condition of \Cref{lem:lpr}, \cite{lund1999paging} employ a slightly more specialized analysis of the charging scheme in \Cref{fig:charging-scheme} (Lemma 2.3 in \cite{lund1999paging}) to obtain a $(c+1)$-competitive guarantee against $\opt$ (instead of $2c$-competitiveness). Thereafter, by arguing that the median algorithm satisfies the condition with $c=4$, (Theorem 2.4 in \cite{lund1999paging}), they are able to show that the median algorithm is 5-competitive against $\opt$. Our tighter analysis in \Cref{lem:tight-analysis} applies to any algorithm (deterministic/randomized), and hence also improves the guarantee for deterministic algorithms obtained by \cite{lund1999paging}. More importantly, it improves the performance guarantee that we can state for the median algorithm.

\begin{corollary}
    \label{corollary:median-is-4-competitive}
    The median algorithm is 4-competitive against $\opt$.
\end{corollary}
 \section{Lower bound for Dominating Distribution Algorithms}
\label{sec:lb}

In this section, we show that there exist problem instances where a dominating distribution algorithm\footnote{Note that we cannot hope to prove a lower bound that applies to \textit{all} dominating distribution algorithms, since the optimal Farthest-in-Future algorithm is technically also a dominating distribution algorithm.} can provably be at least $c$ times worse than $\opt$, for $c \ge 1.5907$. We start with a warm-up analysis that captures the central idea behind the lower bound, and shows a bound of 1.5, before generalizing the analysis to improve the bound. Our lower bound instances throughout are small and simple: they comprise of a Markov chain on $n=3$ pages with a cache size $k=2$.

\subsection{Warm-up: A 1.5-competitive Lower Bound}
\label{sec:1.5-lb}

Consider a simple setting with 3 total pages, and a cache of size 2. At each time step independently, page 1 is requested with probability $1-\eps$, and page 2 and 3 are requested each with probability $\eps/2$. This corresponds to the Markov chain with the transition matrix
\begin{align*}
    \begin{bmatrix}
        1-\eps & \eps/2 & \eps/2 \\
        1-\eps & \eps/2 & \eps/2 \\
        1-\eps & \eps/2 & \eps/2
    \end{bmatrix}.
\end{align*}

We start with the initial cache being $[1,2]$. The reference algorithm $\mcA_{\rf}$ we will compete against always keeps page 1 in its cache. If it suffers a cache miss, it swaps out the other page with the requested page. At any time $t$, the probability that $\mcA_{\rf}$ suffers a miss is therefore exactly $\eps/2$, and hence the expected total number of misses through $T$ timesteps is $\eps T/2$.

Now, consider $\mcA_{\dom}$. We want to capitalize on the fact that $\mcA_\dom$ evicts page 1 with some positive probability, in contrast to $\mcA_\rf$. Namely, observe that 
\begin{align}
    \Pr[\text{$\mcA_\dom$ suffers cache miss at time $t$}] &= \Pr[\text{$1$ in cache of $\mcA_\dom$ at $t$}] \cdot \frac{\eps}{2} + \nonumber\\
    & \Pr[\text{$1$ not in cache of $\mcA_\dom$ at $t$}] \cdot (1-\eps) \nonumber \\
    &= p_t \cdot \frac{\eps}{2} + (1-p_t) \cdot (1-\eps), \label{eqn:misses-A-dom}
\end{align}
where we denote $p_t = \Pr[\text{$1$ in cache of $\mcA_\dom$ at $t$}]$. The latter probability is non-zero for $\mcA_\dom$, which already makes its expected total number of misses larger than that of $\mcA_\rf$. We will therefore aim to maximize this difference.

Observe that 
\begin{align*}
    p_t &= \Pr[\text{$1$ requested at $t-1$}] + \Pr[\text{$1$ in cache of $\mcA_\dom$ at $t-1$}] \cdot \Pr[\text{$1$ not requested at $t-1$}] \cdot \\
    &\Pr[\text{$1$ not evicted by $\mcA_\dom$ at $t-1 ~\big|$ $1$ not requested, $1$ in cache of $\mcA_\dom$ at $t-1$}] \\
    &= 1-\eps + p_{t-1} \cdot \eps \cdot \Pr[\text{$1$ not evicted by $\mcA_\dom$ at $t-1 ~\big|$ $1$ not requested, $1$ in cache of $\mcA_\dom$ at $t-1$}].
\end{align*}
We can analytically calculate the last probability. Say the cache of $\mcA_\dom$ at $t-1$ is, without loss of generality, $[1,2]$. Given that $1$ is not requested, we have that either of $2$ or $3$ are requested, each with probability $1/2$. If $2$ is requested, there is no cache miss. If on the other hand, $3$ is requested, $\mcA_\dom$ calculates a dominating distribution $\mu$ over $[1,2]$. This can be easily calculated. Let $\alpha(p<q)$ again be the probability that $p$ is requested next before $q$ (conditioned on the current page, which in this case, does not matter since the distributions at every time step are independent and identical). We have that
\begin{align*}
    &\alpha(1<1) = \alpha(2<2) = 0, \\
    &\alpha(2<1) = \eps/2 + \eps/2 \cdot \alpha(2<1)
    \implies \quad \alpha(2<1) = \frac{\eps/2}{1-\eps/2}, \\
    &\alpha(1<2) = 1-\eps + \eps/2 \cdot \alpha(1<2)
    \implies \quad \alpha(1<2) = \frac{1-\eps}{1-\eps/2}. 
\end{align*}
The condition for the dominating distribution is that, for every fixed page $q$ in the cache,
\begin{align*}
    \E_{p \sim \mu}[\alpha(p<q)] \le 1/2.
\end{align*}
Letting $\mu(1)=x$ so that $\mu(2)=1-x$, this translates to
\begin{align*}
    &(1-x)\cdot \alpha(2<1) \le 1/2, \quad x\cdot \alpha(1<2) \le 1/2 \\
    \implies \qquad& \frac{3\eps-2}{2\eps} \le x \le \frac{2-\eps}{4-4\eps}.
\end{align*}
We want $x$ to be large as possible, because we want $\mcA_\dom$ to evict $1$ with the highest feasible probability, so that it will suffer a lot of cache misses. Thus, we set $x = \frac{2-\eps}{4-4\eps}$. This gives us that,
\begin{align*}
    &\Pr[\text{$1$ not evicted by $\mcA_\dom$ at $t-1 ~\big|$ $1$ not requested, $1$ in cache of $\mcA_\dom$ at $t-1$}] \\
    &= \frac12 + \frac{1}{2} \cdot (1-x) = 1-\frac{x}{2} = \frac{6-7\eps}{8-8\eps}.
\end{align*}
In total, we get that
\begin{align*}
    p_t &= \underbrace{1-\eps}_{c} + p_{t-1}\cdot \underbrace{\frac{\eps(6-7\eps)}{8-8\eps}}_{d}. 
\end{align*}
Unrolling the recurrence, and using that $p_{1}=1$, we obtain that for $t \ge 2$,
\begin{align*}
    p_t &= c(1+d+\dots+d^{t-2}) + d^{t-1} = c\cdot \frac{1-d^{t-1}}{1-d} + d^{t-1}.
\end{align*}
Summing up $\eqref{eqn:misses-A-dom}$ until $T$, and substituting $p_t$ from above, we get that
\begin{align*}
    \E[\cost(\mcA_\dom, T)] &= T(1-\eps) + \left(\frac{3\eps}{2}-1\right)\sum_{t=1}^{T}p_t \\
    &= T(1-\eps) + \left(\frac{3\eps}{2}-1\right)\left[\frac{c}{1-d}\left(T-\frac{1-d^T}{1-d}\right)+\frac{1-d^T}{1-d}\right].
\end{align*}
Taking the limit as $T \to \infty$, we get that
\begin{align*}
    \lim_{T \to \infty}\frac{\E[\cost(\mcA_\dom, T)]}{\E[\cost(\mcA_\rf, T)]} &= \frac{1-\eps+\left(\frac{3\eps}{2}-1\right)\left(\frac{c}{1-d}\right)}{\eps/2}.
\end{align*}
Substituting the values of $c$ and $d$, and taking the limit as $\epsilon \to 0$, the ratio above converges to $1.5$.

\subsection{A Slightly More General Analysis that Gives a Better Lower Bound}
\label{sec:1.5907-lb}

In the instance above, instead of assigning $\eps/2$ mass equally to pages 2 and 3, we can also imagine splitting the $\eps$ mass unequally between these pages. Namely, let the underlying distribution on the pages be such that, at each time step, page 1 is requested with probability $1-\eps$, page 2 is requested with probability $\eps_1$ and page 3 is requested with probability $\eps-\eps_1$, where the regime we want to keep in mind is $1-\eps \ge \eps_1 \ge \eps-\eps_1$. Note that $\eps_1=\eps/2$ corresponds to the instance above. Let the initial cache be $[1,2]$.

The reference algorithm $\mcA_\rf$ still always maintains page 1 in its cache. Let
\begin{align*}
    p_t &= \Pr[\text{$\mcA_\rf$'s state is $[1,2]$ at $t$}].
\end{align*}
We have that
\begin{align*}
    p_t = p_{t-1} \cdot (1-\eps+\eps_1) + (1-p_{t-1}) \cdot \eps_1 
    = \eps_1 + p_{t-1} \cdot (1-\eps) 
    = \eps_1 \left(\frac{1-(1-\eps)^{t-1}}{\eps}\right) + (1-\eps)^{t-1},
\end{align*}
where we unrolled the recurrence in the last step, and used that $p_1=1$. Then,
\begin{align*}
    \Pr[\mcA_\rf \text{ suffers miss at }t] = p_t \cdot (\eps-\eps_1) + (1-p_t) \cdot \eps_1
    = \eps_1 + (\eps-2\eps_1)\cdot p_t,
\end{align*}
and hence
\begin{align}
    \E[\cost(\mcA_\rf, T)] &= T\eps_1 + (\eps-2\eps_1) \sum_{t=1}^T p_t \nonumber \\
    &= T\eps_1 + (\eps-2\eps_1)\left[ \frac{\eps_1}{\eps}\left( T - \frac{1-(1-\eps)^T}{\eps} \right) + \frac{1-(1-\eps)^T}{\eps} \right]. \label{eqn:ref-gen-misses}
\end{align}
Now, we analyze the behavior of $\mcA_\dom$. Let
\begin{align*}
    &p_t = \Pr[\text{$\mcA_\dom$'s state is $[1,2]$ at $t$}] \\
    &q_t = \Pr[\text{$\mcA_\dom$'s state is $[1,3]$ at $t$}] \\
    &r_t = \Pr[\text{$\mcA_\dom$'s state is $[2,3]$ at $t$}],
\end{align*}
where $p_1=1, q_1=0, r_1=0$. Then, we have that
\begin{align}
    \label{eqn:miss-eqn}
    \Pr[\mcA_\dom \text{ suffers miss at }t] &= p_t \cdot (\eps-\eps_1) + q_t \cdot \eps_1 + r_t \cdot (1-\eps).
\end{align}
 Observe further that
\begin{align*}
    p_t &= p_{t-1} \cdot \Pr[\text{1 or 2 requested at }t-1] + q_{t-1} \cdot \eps_1 \cdot \Pr[\text{$\mcA_\dom$ evicts 3 from }[1,3]] \\
    &\qquad+ r_{t-1} \cdot (1-\eps) \cdot \Pr[\text{$\mcA_\dom$ evicts 3 from }[2,3]] \\
    &= p_{t-1} \cdot (1-\eps+\eps_1) +  q_{t-1} \cdot \eps_1 \cdot \Pr[\text{$\mcA_\dom$ evicts 3 from }[1,3]] \\
    &\qquad+ r_{t-1} \cdot (1-\eps) \cdot \Pr[\text{$\mcA_\dom$ evicts 3 from }[2,3]] \\
    q_t &= q_{t-1} \cdot \Pr[\text{1 or 3 requested at }t-1] + p_{t-1} \cdot (\eps-\eps_1) \cdot \Pr[\text{$\mcA_\dom$ evicts 2 from }[1,2]] \\
    &\qquad+ r_{t-1} \cdot (1-\eps) \cdot \Pr[\text{$\mcA_\dom$ evicts 2 from }[2,3]] \\
    &= q_{t-1} \cdot (1-\eps_1) + p_{t-1} \cdot (\eps-\eps_1) \cdot \Pr[\text{$\mcA_\dom$ evicts 2 from }[1,2]] \\
    &\qquad+ r_{t-1} \cdot (1-\eps) \cdot \Pr[\text{$\mcA_\dom$ evicts 2 from }[2,3]] \\
    r_t &= r_{t-1} \cdot \Pr[\text{2 or 3 requested at }t-1] + p_{t-1} \cdot (\eps-\eps_1) \cdot \Pr[\text{$\mcA_\dom$ evicts 1 from }[1,2]] \\
    &\qquad+ q_{t-1} \cdot \eps_1 \cdot \Pr[\text{$\mcA_\dom$ evicts 1 from }[1,3]] \\
    &= r_{t-1} \cdot \eps + p_{t-1} \cdot (\eps-\eps_1) \cdot \Pr[\text{$\mcA_\dom$ evicts 1 from }[1,2]]  + q_{t-1} \cdot \eps_1 \cdot \Pr[\text{$\mcA_\dom$ evicts 1 from }[1,3]].
\end{align*}
We can calculate each of the eviction probabilities above while respecting the properties that $\mcA_\dom$ must satisfy. Namely, consider that the cache state is $[1,2]$. Let $\mu$ be the dominating distribution that $\mcA_\dom$ constructs, where $\mu(1)=x$ and $\mu(2)=1-x$. We have that
\begin{align*}
    \alpha(2<1) &= \eps_1 + (\eps-\eps_1)\alpha(2<1) \implies\quad \alpha(2<1) = \frac{\eps_1}{1-\eps+\eps_1} \\
    \alpha(1<2) &= 1-\alpha(2<1) = \frac{1-\eps}{1-\eps+\eps_1}.
\end{align*}
The dominating distribution condition requires that
\begin{align*}
    &(1-x)\cdot\alpha(2<1) \le \frac{1}{2}, \quad x\cdot\alpha(1<2) \le \frac{1}{2} \\ 
    \implies \qquad & \frac{\alpha(2<1)-1/2}{\alpha(2<1)} \le x \le \frac{1}{2\alpha(1<2)}.
\end{align*}
We choose to set the upper condition to be tight, which results in
\begin{align*}
    x &= \Pr[\text{$\mcA_\dom$ evicts 1 from }[1,2]] = \frac{1-\eps+\eps_1}{2-2\eps}, \\
    1-x &= \Pr[\text{$\mcA_\dom$ evicts 2 from }[1,2]] = \frac{1-\eps-\eps_1}{2-2\eps}.
\end{align*}
Now, consider the same calculation, where the cache state is $[1,3]$, $\mu(1)=x$ and $\mu(3)=1-x$. We have that
\begin{align*}
    \alpha(3<1) &= \eps-\eps_1 + \eps_1 \cdot \alpha(3<1) \implies\quad \alpha(3<1) = \frac{\eps-\eps_1}{1-\eps_1} \\
    \alpha(1<3) &= 1-\alpha(3<1) = \frac{1-\eps}{1-\eps_1}.
\end{align*}
The dominating distribution condition requires
\begin{align*} 
    \frac{\alpha(3<1)-1/2}{\alpha(3<1)} \le x \le \frac{1}{2\alpha(1<3)}.
\end{align*}
Again, we make the upper bound tight to get
\begin{align*}
    x &= \Pr[\text{$\mcA_\dom$ evicts 1 from }[1,3]] = \frac{1-\eps_1}{2-2\eps}, \\
    1-x &= \Pr[\text{$\mcA_\dom$ evicts 3 from }[1,3]] = \frac{1+\eps_1-2\eps}{2-2\eps}.
\end{align*}
Finally, consider the calculation, where the cache state is $[2,3]$, $\mu(2)=x$ and $\mu(3)=1-x$. We have that
\begin{align*}
    \alpha(3<2) &= \eps-\eps_1 + (1-\eps) \cdot \alpha(3<2) \implies\quad \alpha(3<2) = \frac{\eps-\eps_1}{\eps} \\
    \alpha(2<3) &= 1-\alpha(3<2) = \frac{\eps_1}{\eps}.
\end{align*}
The dominating distribution condition requires
\begin{align*} 
    \frac{\alpha(3<2)-1/2}{\alpha(3<2)} \le x \le \frac{1}{2\alpha(2<3)},
\end{align*}
so we set
\begin{align*}
    x &= \Pr[\text{$\mcA_\dom$ evicts 2 from }[2,3]] = \frac{\eps}{2\eps_1}, \\
    1-x &= \Pr[\text{$\mcA_\dom$ evicts 3 from }[2,3]] = \frac{2\eps_1-\eps}{2\eps_1}.
\end{align*}
Substituting all these eviction probabilities, and writing the system of equations for $p_t,q_t,r_t$ above in matrix form, we obtain
\begin{align*}
    \begin{bmatrix}
        p_t \\ q_t \\ r_t
    \end{bmatrix}
    &=
    \begin{bmatrix}
       1-\eps+\eps_1  & \eps_1 \cdot \frac{1+\eps_1-2\eps}{2-2\eps} & (1-\eps) \cdot \frac{2\eps_1-\eps}{2\eps_1} \\
       (\eps-\eps_1) \cdot \frac{1-\eps-\eps_1}{2-2\eps} & 1-\eps_1 & (1-\eps) \cdot \frac{\eps}{2\eps_1} \\
       (\eps-\eps_1) \cdot \frac{1-\eps+\eps_1}{2-2\eps} & \eps_1 \cdot \frac{1-\eps_1}{2-2\eps} & \eps
    \end{bmatrix}
    \begin{bmatrix}
        p_{t-1} \\ q_{t-1} \\ r_{t-1}
    \end{bmatrix} \\
    &= B^{t-1} \begin{bmatrix}
        p_{1} \\ q_{1} \\ r_{1}
    \end{bmatrix}
    = B^{t-1} \begin{bmatrix}
        1 \\ 0 \\ 0
    \end{bmatrix},
\end{align*}
where we denoted the matrix by $B$ and rolled out the recurrence. Substituting in \eqref{eqn:miss-eqn}, we have that
\begin{align*}
    \Pr[\mcA_\dom \text{ suffers miss at }t] &= 
    \begin{bmatrix}
        \eps-\eps_1 & \eps_1 & 1-\eps
    \end{bmatrix}
    B^{t-1} \begin{bmatrix}
        1 \\ 0 \\ 0
    \end{bmatrix},
\end{align*}
and thus,
\begin{align}
    \E[\cost(\mcA_\dom, T)] &= \begin{bmatrix}
        \eps-\eps_1 & \eps_1 & 1-\eps
    \end{bmatrix}
    (I + B + B^2 + \dots + B^{T-1}) \begin{bmatrix}
        1 \\ 0 \\ 0
    \end{bmatrix}. \label{eqn:dom-gen-misses}
\end{align}
Now that we have exact expressions given by \eqref{eqn:ref-gen-misses} and \eqref{eqn:dom-gen-misses}, we can do a computer search over assignments to $T, \eps, \eps_1$---each assignment gives a lower bound for $\frac{\E[\cost(\mcA_\dom, T)]}{\E[\cost(\mcA_\rf, T)]}$. For example, our (admittedly limited) search yields
\begin{align*}
    \frac{\E[\cost(\mcA_\dom, T)]}{\E[\cost(\mcA_\rf, T)]} \ge 1.5907,
\end{align*}
for $\eps=10^{-5}, T=10^8, \eps_1=0.7069\eps$.

\begin{remark}
    \label{remark:potential-improving-lower-bound}
    While we do believe that further tuning $\eps, \eps_1$ and $T$ will likely not improve the lower bound by too much, it is conceivable that a better lower bound may be obtained by going beyond $n=3, k=2$ (albeit with messier calculations). For example, there appears to be scope for improvement within instances having the same blueprint as above for slightly larger values of $n$ and $k$, where there are certain high-probability pages that $\mcA_\rf$ always keeps in the cache.
\end{remark}
 \section{Learning the Markov Chain from Samples}
\label{sec:robustness}

It is worth pointing out that the form of \Cref{lem:tight-analysis} allows us to obtain performance guarantees even when we only have approximate estimates of the $\alpha(p<q)$ values, as also noted in passing by \cite{lund1999paging}. In particular, suppose that we only have $\eps$-approximate (multiplicate or additive) estimates $\hat{\alpha}(p<q)$ of $\alpha(p<q)$, that still satisfy $\hat{\alpha}(p<q) + \hat{\alpha}(q<p)=1$, and $\hat{\alpha}(p<p)=0$. Suppose that at each cache miss, we use these $\hat{\alpha}(p<q)$ values to compute a dominating distribution $\hat{\mu}$, and draw the page $p$ to evict from $\hat{\mu}$.

Even with such an approximate dominating distribution, we can still guarantee either $\frac{2}{1-2\eps}$-competitiveness (in the case that $\hat{\alpha}(p<q) \in [\alpha(p<q)-\eps, \alpha(p<q)+\eps]$), or $\frac{2-2\eps}{1-2\eps}$-competitiveness (in the case that $\hat{\alpha}(p<q) \in [(1-\eps)\alpha(p<q), (1+\eps)\alpha(p<q)]$). This follows as a direct consequence of \Cref{claim:dominating-distribution-probability} and \Cref{lem:tight-analysis}.

Perhaps the first scenario to consider here is when we do not assume prior knowledge of the transition matrix $M$, but only have access to samples previously drawn from the Markov chain. For example, we can imagine that the algorithm designer has available a large training dataset of past page requests. This dataset can be used to derive estimates of the entries in the transition matrix $M$, for instance, using one of the several existing estimators \citep{hao2018learning, wolfer2021statistical, huang2024non}. In fact, recall that the computation of the $\alpha(p<q)$ values requires only for us to solve a linear system determined by the entries in the transition matrix (\Cref{eqn:linear-system-for-alpha}). Hence, if we have accurate estimates for the entries in $M$, we can use the theory of perturbed linear systems to bound the resulting error in the estimates of the $\alpha(p<q)$ values. Thereafter, using the argument from the previous paragraph, we can obtain a performance guarantee for the competitiveness of a dominating distribution algorithm that uses these estimates.

We can turn the above informal argument into a formal learning-theoretic result. Formally, suppose that every entry in $M$ is at least some $\delta > 0$. In this case, the Markov chain is irreducible (meaning that there is a positive, and unique probability of eventually getting from any state to another). Thus, in this case, for every fixed $p,q$, the linear system \eqref{eqn:linear-system-for-alpha} has a (unique) solution, meaning that matrix associated with it is invertible. The relevant quantity here will be the conditioning of the \textit{worst} linear system that we might ever have to solve. Towards this, let $L_{p,q}$ be the matrix associated with the linear system in \eqref{eqn:linear-system-for-alpha} for pages $p,q$, and define:
\begin{align}
    \label{eqn:gamma-def}
    \gamma &= \sup_{p \neq q} \|L_{p,q}^{-1}\|_\infty,
\end{align}
where for a square matrix $A \in \R^{n \times n}$, $\|A\|_\infty = \sup_i \sum_{j}|A_{i,j}|$. Observe from \eqref{eqn:linear-system-for-alpha} that $1 \le \|L_{p,q}\|_\infty \le 2$ for every $p,q$.

We choose to adopt the following result of \cite{hao2018learning} for our exposition:

\begin{theorem}[Theorem 4 in \cite{hao2018learning}]
    \label{thm:learning-markov-chains}
    Suppose we unroll a Markov chain to obtain $m$ samples $X_1,\dots,X_m$, where the initial distribution of $X_1$ is arbitrary, but the transition matrix $M \in [0,1]^{n \times n}$ of the Markov chain satisfies $M_{i,j} \ge \delta > 0$ for every $i,j$. Then, there exists an estimator $\hat{M}=\hat{M}(X_1,\dots,X_m)$ that satisfies
    \begin{align*}
        \E_{X_1,\dots,X_m}\|M(i,:) - \hat{M}(i,:)\|_2^2 \le O \left(\frac{1}{m\delta}\right)
    \end{align*}
    for every $i \in [n]$, where $M(i,:)$ (respectively $\hat{M}(i,:)$) denotes the $i^\text{th}$ row of $M$ (respectively $\hat{M}$).
\end{theorem}

Using this theorem, we can obtain the following result:

\begin{theorem}
    \label{thm:approx-lpr-from-samples}
    Suppose that the page requests are generated from an unknown Markov chain where every entry in the transition matrix $M$ is at least $\delta > 0$. Let $\gamma$ be as defined in \eqref{eqn:gamma-def}. Given a training dataset of $m = O\left(\frac{\gamma^2n^2}{\eps^2\delta}\right)$ past page requests from $M$, there is an algorithm $\mcA$ which is $\frac{2}{1-2\eps}$-competitive against $\opt$ with probability at least $0.99$ over the $m$ samples.
\end{theorem}
\begin{proof}\textcolor{red}{TOPROVE 5}\end{proof}
 
\section*{Acknowledgements}
Chirag is supported by Moses Charikar and Gregory Valiant's Simons Investigator Awards. The authors would like to thank Avrim Blum for helpful pointers.

\bibliographystyle{abbrvnat}
\bibliography{ref}

\end{document}
