\documentclass[11pt]{article}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{fancybox}
\usepackage{comment}
\usepackage{xcolor}
\usepackage{nameref}
\usepackage[bottom]{footmisc}


\definecolor{ForestGreen}{rgb}{0.1333,0.5451,0.1333}
\definecolor{DarkRed}{rgb}{0.8,0,0}
\definecolor{Red}{rgb}{1,0,0}
\usepackage[linktocpage=true,
pagebackref=true,colorlinks,
linkcolor=ForestGreen,citecolor=ForestGreen,
bookmarks,bookmarksopen,bookmarksnumbered]
{hyperref}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage{subfig}

\usepackage{thm-restate}

\usepackage{float}
\usepackage{cleveref}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{pseudotheorem}{Pseudotheorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{pseudoclaim}[theorem]{Pseudoclaim}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{invariant}[theorem]{Invariant}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{conjecture}{Conjecture}[section]

\newtheorem{property}[theorem]{Property}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}

\newtheorem*{theorem*}{Theorem}
\newtheorem*{corollary*}{Corollary}
\newtheorem*{conjecture*}{Conjecture}
\newtheorem*{lemma*}{Lemma}
\newtheorem*{thm*}{Theorem}
\newtheorem*{prop*}{Proposition}
\newtheorem*{obs*}{Observation}
\newtheorem*{definition*}{Definition}
\newtheorem*{example}{Example}
\newtheorem*{remark*}{Remark}
\newtheorem*{rec*}{Recommendation}

\newenvironment{fminipage}{\begin{Sbox}\begin{minipage}}{\end{minipage}\end{Sbox}\fbox{\TheSbox}}

\newenvironment{algbox}[0]{\vskip 0.2in
\noindent 
\begin{fminipage}{6.3in}
}{
\end{fminipage}
\vskip 0.2in
}


\let\muchl\ll

\def\pleq{\preccurlyeq}
\def\pgeq{\succcurlyeq}
\def\pge{\succ}
\def\ple{\prec}

\def\Approx#1{\approx_{#1}}

\def\bvec#1{{\mbox{\boldmath $#1$}}}




\def\prob#1#2{\mbox{Pr}_{#1}\left[ #2 \right]}
\def\pvec#1#2{\vec{\mbox{P}}^{#1}\left[ #2 \right]}
\def\expec#1#2{{\mathbb{E}}_{#1}\left[ #2 \right]}
\def\var#1{\mbox{\bf Var}\left[ #1 \right]}

\def\defeq{\stackrel{\mathrm{def}}{=}}
\def\setof#1{\left\{#1  \right\}}
\def\sizeof#1{\left|#1  \right|}


\def\trace#1{\mathrm{Tr} \left(#1 \right)}

\def\floor#1{\left\lfloor #1 \right\rfloor}
\def\ceil#1{\left\lceil #1 \right\rceil}

\def\dim#1{\mathrm{dim} (#1)}
\def\sgn#1{\mathrm{sgn} (#1)}

\def\union{\cup}
\def\intersect{\cap}
\def\Union{\bigcup}
\def\Intersect{\bigcap}

\def\abs#1{\left|#1  \right|}

\def\norm#1{\left\| #1 \right\|}
\def\smallnorm#1{\| #1 \|}

\newcommand\grad{\boldsymbol{\nabla}}
\newcommand\D[2]{D#1[#2]}

\newcommand*\diff{\mathop{}\!\mathrm{d}}
\newcommand*\Diff[1]{\mathop{}\!\mathrm{d^#1}}

\newcommand\ip[1]{\left< #1 \right>}


\newcommand{\sym}[1]{\mathrm{sym} (#1)}



\def\calC{\mathcal{C}}
\def\calD{\mathcal{D}}
\def\calE{\mathcal{E}}
\def\calF{\mathcal{F}}
\def\calG{\mathcal{G}}
\def\calL{\mathcal{L}}
\def\calS{\mathcal{S}}
\def\calT{\mathcal{T}}
\def\calM{\mathcal{M}}

\newcommand\calDD{\boldsymbol{\calD}}

\newcommand\DDelta{\boldsymbol{\mathit{\Delta}}}
\newcommand\Ppsi{\boldsymbol{\mathit{\Psi}}}
\newcommand\PPsi{\boldsymbol{\mathit{\Psi}}}
\newcommand\ppsi{\boldsymbol{\mathit{\psi}}}
\newcommand\pphi{\boldsymbol{\mathit{\phi}}}
\newcommand\PPhi{\boldsymbol{\Phi}}
\newcommand\LLambda{\boldsymbol{\mathit{\Lambda}}}
\newcommand\PPi{\boldsymbol{\Pi}}

\newcommand\ppi{\boldsymbol{\pi}}
\newcommand\cchi{\boldsymbol{\chi}}
\newcommand\aalpha{\boldsymbol{\alpha}}
\newcommand\bbeta{\boldsymbol{\beta}}
\newcommand\ggamma{\boldsymbol{\gamma}}
\newcommand\ddelta{\boldsymbol{\delta}}

\newcommand\rrho{\boldsymbol{\rho}}
\newcommand\xxi{\boldsymbol{\xi}}
\newcommand\ttau{\boldsymbol{\tau}}



\newcommand\er{R_{\text{eff}}}

\newcommand\bell{\boldsymbol{\mathit{\ell}}}
\def\aa{\pmb{\mathit{a}}}
\newcommand\bb{\boldsymbol{\mathit{b}}}
\newcommand\cc{\boldsymbol{\mathit{c}}}
\newcommand\dd{\boldsymbol{\mathit{d}}}
\newcommand\ee{\boldsymbol{\mathit{e}}}
\newcommand\ff{\boldsymbol{\mathit{f}}}
\renewcommand\gg{\boldsymbol{\mathit{g}}}
\newcommand\hh{\boldsymbol{\mathit{h}}}
\newcommand\ii{\boldsymbol{\mathit{i}}}
\newcommand\jj{\boldsymbol{\mathit{j}}}
\newcommand\kk{\boldsymbol{\mathit{k}}}
\renewcommand\ll{\boldsymbol{\mathit{l}}}
\newcommand\pp{\boldsymbol{\mathit{p}}}
\newcommand\qq{\boldsymbol{\mathit{q}}}
\newcommand\bs{\boldsymbol{\mathit{s}}}
\newcommand\nn{\boldsymbol{\mathit{n}}}
\newcommand\rr{\boldsymbol{\mathit{r}}}
\renewcommand\ss{\boldsymbol{\mathit{s}}}
\def\tt{\boldsymbol{\mathit{t}}}
\newcommand\uu{\boldsymbol{\mathit{u}}}
\newcommand\vv{\boldsymbol{\mathit{v}}}
\newcommand\ww{\boldsymbol{\mathit{w}}}
\newcommand\yy{\boldsymbol{\mathit{y}}}
\newcommand\zz{\boldsymbol{\mathit{z}}}
\newcommand\xx{\boldsymbol{\mathit{x}}}

\newcommand\veczero{\boldsymbol{0}}
\newcommand\vecone{\boldsymbol{1}}

\newcommand\matzero{\boldsymbol{0}}
\newcommand\matone{\boldsymbol{1}}

\newcommand{\matlow}{\boldsymbol{\mathit{{\mathcal{L}}}}}
\newcommand{\matlowtil}{\boldsymbol{\mathit{\widetilde{\mathcal{L}}}}}
\newcommand{\matlowhat}{\boldsymbol{\mathit{\widehat{\mathcal{L}}}}}

\newcommand{\matup}{\boldsymbol{\mathit{{\mathcal{U}}}}}


\renewcommand\AA{\boldsymbol{\mathit{A}}}
\newcommand\BB{\boldsymbol{\mathit{B}}}
\newcommand\CC{\boldsymbol{\mathit{C}}}
\newcommand\DD{\boldsymbol{\mathit{D}}}
\newcommand\EE{\boldsymbol{\mathit{E}}}
\newcommand\GG{\boldsymbol{\mathit{G}}}
\newcommand\HH{\boldsymbol{{H}}}
\newcommand\II{\boldsymbol{\mathit{I}}}
\newcommand\JJ{\boldsymbol{\mathit{J}}}
\newcommand\KK{\boldsymbol{\mathit{K}}}
\newcommand\NN{\boldsymbol{\mathit{N}}}
\newcommand\MM{\boldsymbol{\mathit{M}}}
\newcommand\LL{\boldsymbol{\mathit{L}}}
\newcommand\PP{\boldsymbol{\mathit{P}}}
\newcommand\RR{\boldsymbol{\mathit{R}}}
\renewcommand\SS{\boldsymbol{\mathit{S}}}
\newcommand\TT{\boldsymbol{\mathit{T}}}
\newcommand\UU{\boldsymbol{\mathit{U}}}
\newcommand\WW{\boldsymbol{\mathit{W}}}
\newcommand\VV{\boldsymbol{\mathit{V}}}
\newcommand\XX{\boldsymbol{\mathit{X}}}
\newcommand\YY{\boldsymbol{\mathit{Y}}}



\newcommand\AAtil{\boldsymbol{\mathit{\tilde{A}}}}
\newcommand\BBtil{\boldsymbol{\mathit{\tilde{B}}}}
\newcommand\LLtil{\boldsymbol{\mathit{\tilde{L}}}}
\newcommand\MMtil{\boldsymbol{\mathit{\tilde{M}}}}
\newcommand\PPtil{\boldsymbol{\mathit{\tilde{P}}}}
\newcommand\XXtil{\boldsymbol{\mathit{\tilde{X}}}}

\newcommand\AAn{\boldsymbol{\mathcal{A}}}
\newcommand\ZZ{\boldsymbol{\mathit{Z}}}

\newcommand\AAhat{\boldsymbol{\widehat{\mathit{A}}}}
\newcommand\AAapprox{\boldsymbol{\widetilde{\mathit{A}}}}
\newcommand\DDhat{\boldsymbol{\widehat{\mathit{D}}}}
\newcommand\DDapprox{\boldsymbol{\widetilde{\mathit{D}}}}
\newcommand\LLhat{\boldsymbol{\widehat{\mathit{L}}}}
\newcommand\LLapprox{\boldsymbol{\widetilde{\mathit{L}}}}
\newcommand\MMhat{\boldsymbol{\widehat{\mathit{M}}}}
\newcommand\MMapprox{\boldsymbol{\widetilde{\mathit{M}}}}
\newcommand\ZZhat{\boldsymbol{\widehat{\mathit{Z}}}}

\newcommand\DDtil{\boldsymbol{\widetilde{\mathit{D}}}}

\newcommand\fftil{\boldsymbol{\tilde{\mathit{f}}}}
\newcommand\xxtil{\boldsymbol{\tilde{\mathit{x}}}}
\newcommand\yytil{\boldsymbol{\tilde{\mathit{y}}}}
\newcommand\zztil{\boldsymbol{\tilde{\mathit{z}}}}
\newcommand\wwtil{\boldsymbol{\tilde{\mathit{w}}}}
\newcommand\ddeltatil{\boldsymbol{\tilde{\mathit{\delta}}}}

\newcommand\Otil{\widetilde{O}}

\newcommand\ddeltabar{\boldsymbol{\bar{\mathit{\delta}}}}
\newcommand\ddeltahat{\boldsymbol{\hat{\mathit{\delta}}}}


\newcommand\xhat{{\hat{{x}}}}
\newcommand\uhat{{\hat{{u}}}}
\newcommand\uuhat{\boldsymbol{\mathit{\hat{u}}}}
\newcommand\vhat{{\hat{{v}}}}
\newcommand\what{{\hat{{w}}}}

\newcommand\Ghat{{\widehat{{G}}}}
\newcommand\GGhat{\boldsymbol{\widehat{G}}}

\newcommand\Ehat{{\widehat{{E}}}}


\newcommand\R{\mathbb{R}}
\newcommand\N{\mathbb{N}}

\newcommand\ffhat{\boldsymbol{\hat{\mathit{f}}}}

\newcommand\cchat{\boldsymbol{\widehat{\mathit{c}}}}
\newcommand\xxhat{\boldsymbol{\mathit{\widehat{x}}}}
\newcommand\yyhat{\boldsymbol{\widehat{\mathit{y}}}}
\newcommand\xxbar{\overline{\boldsymbol{\mathit{x}}}}
\newcommand\yybar{\overline{\boldsymbol{\mathit{y}}}}
\newcommand\xxstar{{\boldsymbol{\mathit{x}}^{*}}}
\newcommand\yystar{{\boldsymbol{\mathit{y}}^{*}}}


\newcommand\ffbar{\overline{\boldsymbol{\mathit{f}}}}


\newcommand\energy{\mathcal{E}}

\newcommand{\expct}[2]{{}\mathop{\mathbb{E}}_{#1}\left[#2\right]}
\newcommand{\E}[1]{\mathop{{}\mathbb{E}}\left[#1\right]}
\newcommand{\Var}[1]{\mathop{{}Var}\left[#1\right]}
\newcommand{\Ex}[1]{{}\mathop{\mathbb{E}}_{#1}}
\newcommand\tr{\mathrm{Tr}}




\newcommand{\schurto}[2]{\ensuremath{\textsc{Sc}\!\left[#1\right]_{#2}}}


\renewcommand{\sc}[2]{\schurto{#1}{#2}}

\newcommand{\trp}{\top}

\newcommand{\pinv}{+}


\newcommand{\proj}{\PPi}

\DeclareMathOperator{\nnz}{nnz}
\DeclareMathOperator{\rot}{Rot}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\val}{val}

\DeclareMathOperator*{\diag}{diag}
\DeclareMathOperator*{\Span}{span}

\DeclareMathOperator*{\im}{im}



\newenvironment{tight_enumerate}{
\begin{enumerate}
 \setlength{\itemsep}{2pt}
 \setlength{\parskip}{1pt}
}{\end{enumerate}}
\newenvironment{tight_itemize}{
\begin{itemize}
 \setlength{\itemsep}{2pt}
 \setlength{\parskip}{1pt}
}{\end{itemize}}
\newenvironment{tight_description}{
\begin{description}
 \setlength{\itemsep}{2pt}
 \setlength{\parskip}{1pt}
}{\end{description}}

\newcommand*{\vertbar}{\rule[-1ex]{0.5pt}{2.5ex}}
\newcommand*{\horzbar}{\rule[.5ex]{2.5ex}{0.5pt}}

\newcommand{\polylog}{\text{ polylog}}




\algdef{SE}[SUBALG]{Indent}{EndIndent}{}{\algorithmicend\ }\algtext*{Indent}
\algtext*{EndIndent}


 \usepackage{fullpage}
\usepackage{orcidlink}
\usepackage{xcolor}
\usepackage{bbm}
\usepackage{subfig}
\usepackage{graphicx}

\newcommand{\aurelio}[1]{{\textbf{ \color{magenta} Aurelio: #1}}}
\newcommand{\paper}[2]{\href{file://refs/#1.pdf}{#1: #2}}
\newcommand{\papershort}[1]{\href{file://refs/#1.pdf}{#1}}

\newcommand{\todo}[1]{{\bf \color{red} TODO: #1}}
\newcommand{\todolow}[1]{{\bf \color{o range} TODOLOW: #1}}

\newcommand{\mprobst}[1]{{\bf \color{Red} Max: #1}}

\DeclareMathOperator{\dirlap}{dirlap}
\DeclareMathOperator{\outdef}{outdef}
\DeclareMathOperator{\outexc}{outex}
\DeclareMathOperator{\cost}{cost}

\DeclareMathOperator{\cutval}{cut\_val}
\DeclareMathOperator{\mincut}{mincut}
\DeclareMathOperator{\vol}{vol}
\DeclareMathOperator{\dist}{dist}

\newcommand\dir{\overrightarrow}
\DeclareMathOperator{\supp}{supp}

\title{Near-Optimal Algorithm for Directed Expander Decompositions}

\date{}
\newcommand*\samethanks[1][\value{footnote}]{\footnotemark[#1]}
\author{Aurelio L. Sulser\thanks{The research leading to these results has received funding from the starting grant “A New Paradigm for Flow and Cut Algorithms” (no. $TMSGI2\_218022$) of the Swiss National Science Foundation.} \\ ETH Zurich \\ asulser@ethz.ch \\ \and Maximilian Probst Gutenberg\samethanks \hspace{0.5em}\orcidlink{0000-0003-3522-156X}
 \\ ETH Zurich \\ maximilian.probst@inf.ethz.ch}

\begin{document}


\pagenumbering{gobble}

\maketitle

\begin{abstract}







In this work, we present the first algorithm to compute expander decompositions in an $m$-edge \emph{directed} graph with near-optimal time $\tilde{O}(m)$\footnote{In this article, we use $\tilde{O}(\cdot)$ notation to suppress factors logarithmic in $m$, i.e. $O(m \log^c m) = \tilde{O}(m)$ for every constant $c > 0$.}. Further, our algorithm can maintain such a decomposition in a dynamic graph and again obtains near-optimal update times. Our result improves over previous algorithms \cite{bernstein2020deterministic, hua2023maintaining} that only obtained algorithms optimal up to subpolynomial factors.

In order to obtain our new algorithm, we present a new push-pull-relabel flow framework that generalizes the classic push-relabel flow algorithm \cite{goldberg1988new} which was later dynamized for computing expander decompositions in \emph{undirected} graphs \cite{henzinger2020local, saranurak2019expander}. We then show that the flow problems formulated in recent work \cite{hua2023maintaining} to decompose directed graphs can be solved much more efficiently in the push-pull-relabel flow framework. 

Recently, our algorithm has already been employed to obtain the currently fastest algorithm to compute min-cost flows \cite{vdB2024decrMincost}. We further believe that our algorithm can be used to speed-up and simplify recent breakthroughs in combinatorial graph algorithms towards fast maximum flow algorithms \cite{chuzhoy2024faster, chuzhoy2024maximum, bernstein2024maximum}.
\end{abstract}

\pagebreak



\pagebreak
\pagenumbering{arabic}

\section{Introduction}
Over the past two decades, expanders and expander decompositions have been pivotal in advancing on fundamental algorithmic graph problems. The development and application of the first fast algorithm to compute near-expander decompositions was given in the development of the first near-linear time Laplacian solvers \cite{spielman2004nearly}, a breakthrough in modern graph algorithms. Subsequently, a line of research \cite{henzinger2020local, wulff2017fully, nanongkai2017dynamic,nanongkai2017dynamicMinimum} has focused on strengthening this result by developing fast flow-based pruning techniques that refine near-expander decompositions into expander decompositions. This line of research culminated in \cite{saranurak2019expander} where a new, faster, simpler, and more user-friendly expander decomposition framework was presented. This advancement has catalyzed the widespread use of expander decompositions as a tool in graph algorithms and was instrumental in the recent surge of applications of expander decompositions in both static and dynamic graph settings for various cut, flow, and shortest path problems \cite{spielman2004nearly, kelner2014almost, henzinger2020local, wulff2017fully, nanongkai2017dynamic,nanongkai2017dynamicMinimum,chuzhoy2019new,bernstein2020deterministic,liu2020vertex, bernstein2020fully,van2021minimum,saranurak2021simple,chalermsook2021vertex, li2021deterministic,chuzhoy2021deterministic, goranci2021expander, chuzhoy2021decremental,bernstein2022deterministic, bernstein2022deterministic, kyng2022derandomizing, jin2022fully, van2023deterministic, kyng2023dynamic, chen2023almost, jin2024fully, chuzhoy2024maximum, bernstein2024maximum, vdB2024decrMincost}. In this work, we study the problem of computing and maintaining expander decompositions in \emph{directed} graphs, defined as follows. 

\begin{definition}[Directed Expander Decomposition]\label{def:expdecomIntro}
Given an $m$-edge directed graph $G$, we say a partition $\mathcal{X}$ of the vertex set of $G$ and a subset of edges $E^r \subseteq E$ forms an $(\beta, \phi)$-expander decomposition if 
\begin{enumerate}
    \item \label{Def:ED-item1} $\forall X \in \mathcal{X}$, $G[X]$ is a $\phi$-expander meaning for all cuts $(S, \bar{S}): \frac{\min\{e_G(S, \bar{S}), e_G(\bar{S}, S)\}}{\min\{\vol_G(S), \vol_G(\bar{S})\}} \geq \phi$, and
    \item \label{Def:ED-item2} $|E^r| \leq \beta \cdot \phi \cdot m$, and 
    \item \label{Def:ED-item3} the graph $(G \setminus E^r) / \mathcal{X}$, that is the graph $G$ minus the edges in $E^r$ where expander components in $\mathcal{X}$ are contracted into supernodes, is a directed acyclic graph (DAG).
\end{enumerate}
\end{definition}

In our algorithm, we implicitly maintain an ordering of the partition sets in $\mathcal{X}$ and let $E^r$ be the edges that go 'backward' in this ordering of expander components. Note that we can only obtain a meaningful bound on the number of such 'backward' edges since a bound on \emph{all} edges between expander components cannot be achieved as can be seen from any graph $G$ that is acyclic (which implies that $\mathcal{X}$ has to be a collection of singletons by  \Cref{Def:ED-item1} forcing all edges to be between components). Directed expanders and expander decompositions have been introduced in \cite{bernstein2020deterministic} in an attempt to derandomize algorithms to maintain strongly connected components and single-source shortest paths in directed graphs undergoing edge deletions. Recently, \cite{hua2023maintaining} gave an alternative algorithm to compute and maintain directed expander decomposition that refines the framework from \cite{bernstein2020deterministic} and heavily improves subpolynomial factors. Besides working on directed graphs, this algorithm also yields additional properties for expander decompositions that cannot be achieved with existing techniques - even in undirected graphs. In this article, we further refine these techniques to obtain an algorithm that is optimal up to logarithmic factors in $m$ - as opposed to subpolynomial factors. Since their invention, directed expander decompositions and the techniques to maintain such decompositions have been pivotal in the design of fast dynamic graph data structures and in ongoing research for fast 'combinatorial' maximum flow algorithms. We discuss in \Cref{subsec:appl} these recent lines of research and how our algorithm benefits recent breakthrough results. For an in-depth discussion of expander decomposition techniques and applications both in directed and undirected graphs, we refer the interested reader to \Cref{subsec:prevWork}.

\subsection{Our Contribution} 
In this article, we finally give a simple algorithm that generalizes the algorithm from \cite{saranurak2019expander} in a clean way. Further, our algorithm is the first to obtain near-optimal runtimes for both static and dynamic expander decompositions in directed graphs. Our result is summarized in the theorem below.

\begin{theorem}\label{Main-thm}Given a parameter $\phi \leq c/ \log^{12} m$ for a fixed constant $c > 0$, and a directed $m$-edge graph $G$ undergoing a sequence of edge deletions, there is a randomized data structure that constructs and maintains a $(O(\log^{19} m), \Omega(\phi/\log^{12} m), O(1/\log^8 m))$-expander decomposition \footnote{Here we use the augmented expander decomposition definition \ref{def:augmentedED}.} $(\mathcal{X}, E^r)$ of $G$. The initialization of the data structure takes time $O(m \log^{20}(m)/\phi)$ and the amortized time to process each edge deletion is $O(\log^{28}(m)/\phi^2)$.
\end{theorem} 

Further, our algorithm has the property that it is refining for up to $O(\phi \cdot \psi \cdot m)$ edge deletions meaning that $\mathcal{X}$ is a refinement of its earlier versions (every expander component in $\mathcal{X}$ is a subset of an expander component in any earlier expander decomposition) and the size of $E^r$ does never exceed $\tilde{O}(\phi m)$. Our algorithms are deterministic, however, they rely on calling a fast randomized algorithm to find balanced sparse cuts or certify that no such cut exists (see \cite{khandekar2009graph, louis2010cut}). Our new techniques are much simpler and more accessible than previous work, besides also being much faster. We hope that by giving a simpler algorithm for directed expander decompositions, we can help to make this tool more accessible to other researchers in the field with the hope that this can further accelerate recent advances in dynamic and static graph algorithms.

\subsection{Applications}
\label{subsec:appl}

Our new algorithms have direct applications to the currently fastest approaches for bipartite matching/ maximum flow/ min-cost flows and the data structures that are employed to obtain these results:
\begin{enumerate}
    \item Our algorithm is already used in the fastest min-cost flow algorithm that is known to-date \cite{vdB2024decrMincost} which achieves runtime $m \cdot e^{O(\log^{3/4}(m) \log\log(m))}$ yielding the first improvement over the recent breakthrough in \cite{chen2022maximum} achieving the first near-linear time algorithm for min-cost flows. In the framework of \cite{vdB2024decrMincost}, our algorithmic techniques are used to maintain an expander decomposition of an \emph{undirected} graph where it is heavily exploited that our algorithm maintains the expander decomposition such that it refines over time. This guarantee is pivotal in the construction of a fully-dynamic algorithm to maintain dynamic expander hierarchies which is the key data structure in the paper. While \cite{vdB2024decrMincost} could also have relied solely on the techniques \cite{hua2023maintaining} to obtain such a data structure with subpolynomial update and query times, these subpolynomial factors would have been substantially larger and would thus not have yielded a faster min-cost flow algorithm overall.

    \item In \cite{bernstein2020deterministic},  directed expander decompositions for decremental graphs were used to obtain the first algorithm to maintain $(1+\epsilon)$-approximate Single-Source Shortest-Paths (SSSPs) in a decremental graphs in time $o(mn)$, though only for the special case of dense graphs. This problem is well-motivated as a simple reduction based on the Multiplicative Weights Update (MWU) framework implies that the maximum flow problem can be solved approximately by solving approximate decremental SSSP. By standard refinement of flows this yields an exact maximum flow algorithm. Very recently, Chuzhoy and Khanna \cite{chuzhoy2024faster, chuzhoy2024maximum} showed that for the update sequence generated by the MWU to solve the bipartite matching problem - a special case of the maximum flow problem - decremental SSSP can be maintained in $n^{2+o(1)}$ time by refining the techniques from \cite{bernstein2020near, bernstein2020deterministic}. This yields the first near-optimal 'combinatorial'\footnote{We refrain from defining the scope of combinatorial algorithms here and refer the reader to \cite{chuzhoy2024faster, chuzhoy2024maximum} for a discussion.} algorithm for the bipartite matching problem for very dense graphs. While the above algorithms are 'combinatorial', they are still very intricate. Most of these complications stem from the maintenance of the directed expander decomposition used internally by the decremental SSSP data structure. We hope that our technique can help to simplify and speed-up these components to yield a simpler algorithm overall.

    \item In independent work \cite{bernstein2024maximum}, an alternative 'combinatorial' maximum flow that runs in $n^{2+o(1)}$ time was given. This algorithm cleverly extends push-relabel algorithms to run more efficiently when given an ordering of vertices that roughly aligns with the topological order induced by the acyclic graph formed from the support of an optimal maximum flow solution. To obtain this approximate ordering they compute a static expander hierarchy of the directed input graph. This generalizes the notion of directed expander decompositions further. In their work, they heavily build on the techniques from \cite{hua2023maintaining} to obtain the expander hierarchy. Unfortunately, the algorithm to obtain this hierarchy is very involved. We hope that our new techniques can help to simplify and speed-up their algorithms.    
\end{enumerate}







\subsection{Our Techniques} 

\paragraph{High-Level Strategy.} We obtain our result by following the high-level strategy of \cite{saranurak2019expander} for undirected graphs: we draw on existing literature (specifically \cite{khandekar2009graph, louis2010cut}) for an algorithm that either outputs a balanced sparse cut which allows us to recurse on both sides; or outputs a witness that no such cut exists. This witness can be represented as an expander graph $W$ that embeds into $G \cup F$ with low congestion where $F$ is a set of few \emph{fake} edges. In the second case, we set up a flow problem to extract a large expander (the first algorithm only finds balanced sparse cuts, so many unbalanced sparse cuts might remain) which suffices to again recurse efficiently. 























\paragraph{The (Dynamic) Flow Problem in \cite{saranurak2019expander}.} To outline our algorithm, we first sketch the techniques of \cite{saranurak2019expander}. In \cite{saranurak2019expander}, the following sequence of flow problems is formulated: initially, we add $\frac{1}{2\phi}$ units of source commodity to each endpoint of an edge in $F$ and then ask to route the commodity in $G$ where each vertex $v$ is a sink of value $\deg_G(v)$ and each edge has capacity $\frac{1}{2\phi}$. It then runs an (approximate) maximum flow algorithm on the flow problem. Whenever the algorithm detects that no feasible flow exists\footnote{Technically, the algorithm might already output cuts when some cut has capacity less than a constant times the amount of flow that is required to be routed through the cut.}, it finds a cut $(A, \overline{A})$ where $A$ is the smaller side of the cut and then poses the same problem for the network $G[\overline{A}]$ where this time the source commodity is assigned for each edge in $E_G(A, \overline{A}) \cup F$. The algorithm terminates once the flow problem can be solved and outputs the final induced graph. In \cite{saranurak2019expander}, it is shown that once a feasible flow exists then the (induced) graph is a $\Omega(\phi)$-expander. Further, it is shown that in the sequence of flow problems, each problem can be warm-started by re-using the flow computed in the previous instance to detect a cut induced on the remaining vertex set. This result is obtained by two main insights: 
\begin{enumerate}
    \item if the flow $\ff$ to find the cut $(A, \bar{A})$ is a \emph{pre-flow}, that is a flow that respects capacities and has no negative excess at any vertex (i.e. it does not route away more flow from a vertex than is inputted by the source), then injecting additional source flow for any edge $E_G(A, \bar{A})$ guarantees that the induced flow $\ff|_{\bar{A}}$ is a pre-flow in the flow problem formulated for $G[\bar{A}]$. That is because the amount of flow that was routed via such a cut edge is at most $2/\phi$ and thus placing $2/\phi$ new source commodity at the endpoint ensures that no negative excess exists in the induced flow $\ff|_{\bar{A}}$,
    \item the classic push-relabel framework can naturally be extended to warm-start on such a flow $\ff|_{\bar{A}}$ as it is built to just further refine pre-flows at every step.
\end{enumerate}
This dynamization of the push-relabel framework allows to bound the cost of computation of \emph{all} flow problems linearly in the amount of source commodity which in term is bounded by the number of edges that appear in either $F$ or one of the identified min-cuts. Finally, \cite{saranurak2019expander} shows that the amount of source commodity remaining in $\bar{A}$ decreases over the sequence of flow problems proportional to the volume of the set $A$ of vertices that are removed at each step. Indeed, they observe that at each vertex $v$ in $A$ at least $\deg(v)$ many commodity units are absorbed and that the total amount of source injected due to the cut edges $E_G(A,\bar{A})$ is bounded by $\frac{1}{2 \phi} \cdot e_G(A,\bar{A}) \leq \vol_G(A)/2$. This yields that the final induced graph is still large. Thus, the final graph outputted is a large expander, as desired. 

\begin{figure}
  \centering
  \subfloat[In directed graphs, cuts are asymmetric. While $(A, \bar{A})$ might be a sparse cut, the cut $(\bar{A}, A)$ might contain many edges. A straightforward extension of \cite{saranurak2019expander} would inject $2/\phi$ units of commodity to each endpoint of $E_G(A, \bar{A}) \cup F$. However, it is not clear with this approach how to bound the total amount of flow injected throughout the algorithm.]{\includegraphics[width=0.45\textwidth]{figs/NaiveInjection.jpg}\label{fig:SourceInjection-A}}
  \hfill
  \subfloat[We inject $\Theta(1/\psi)$ units of commodity at the end points of any witness embedding path (green) going through an edge of $E_G(A, \bar{A}) \cup F$. We can bound the total amount by $O(\vol(A)/\text{poly}(\psi))$. But the injection might well be in the interior of $A, \bar{A}$ possibly leaving negative excess at the endpoints of the cut edges.]{\includegraphics[width=0.45\textwidth]{figs/SophisticatedInjection.jpg}\label{fig:SourceInjection-B}}
  \caption{Injection of Commodity due to edges in $E_G(A, \bar{A}) \cup F$}
\end{figure}

\paragraph{The (Dynamic) Flow Problem in Directed Graphs.} In directed graphs, while the above flow problem upon becoming feasible also certifies that the remaining graph is a $\Omega(\phi)$-expander, the argument that the sequence of flow problems terminates does not work: the asymmetry of cuts might force us for a small cut $E_G(A, \bar{A})$ to induce on $\bar{A}$ while having many edges in $E_G(\bar{A}, A)$ each of which would add $2/\phi$ source flow to the new flow problem (see \Cref{fig:SourceInjection-A}). Hence, we might end up injecting up to $\Omega(\vol_G(A)/\phi)$ more flow due to the cut edges. This makes it seemingly impossible to argue that the amount of source commodity in the next flow problem is smaller. To recover the argument that the sequence of flow problems terminates (with the remaining expander graph being large) both \cite{bernstein2020deterministic, hua2023maintaining} suggest setting up the flow problems more carefully such that each cut $(A, \bar{A})$ that is found in this sequence and induced upon is a \emph{sparse cut}. Here, we only describe the less lossy flow problem formulation developed in \cite{hua2023maintaining}. To ensure that each cut $(A, \bar{A})$ that is found is a sparse cut, \cite{hua2023maintaining} proposes a slightly different flow problem: instead of adding source commodity $\frac{1}{2\phi}$ per endpoint of an edge that is fake or not fully contained in the induced graph, it tailors the amount of new source commodity using the witness graph $W$, possibly injecting much less source commodity in the process. Concretely, we have that $W$ is a $\psi$-expander over the same vertex set as $G$ with degrees similar to degrees in $G$ up to a factor of $\Theta(\text{poly}(\psi))$ and an embedding $\Pi$ into $G \cup F$ with congestion $O(\phi/\psi)$, for $\phi = \tilde{\Theta}(1)$. To set-up the flow problem, we inject $\Theta(1/\psi)$ units at the endpoints of any edge $e$ in the witness $W$ whose embedding path $\Pi(e)$ goes through an edge in $E_G(A, \bar{A}) \cup F$. We note that any such witness embedding path $\Pi(e)$ either crosses the sparse cut $(A, \bar{A})$ or has an endpoint in $A$. This allows to bound the additional source injected by $O(\vol_G(A)/\text{poly}(\psi)) = \tilde{O}(\vol_G(A))$ where we use that $\psi = \tilde{\Theta}(1)$. But while correctness and termination of the flow problem sequence are now ensured, this leaves a significant problem: the current flow $\ff$ that was used to find the cut $(A, \bar{A})$ no longer has the property that $\ff|_{\bar{A}}$ is a \emph{pre-flow} in the flow problem formulated on network $G[\bar{A}]$ even if $\ff$ is a pre-flow. While capacity constraints are still enforced, i.e. $\ff|_{\bar{A}}$ still is a pseudo-flow (see \cite{hochbaum2008pseudoflow} for reference on pseudo-flow), some vertices might now have negative excess since the additional commodity might be injected in the interior of $\bar{A}$ far from the cut $(A, \bar{A})$ (see \Cref{fig:SourceInjection-B}). Indeed, for an edge $(u,v)$ in $E_G(A, \bar{A})$ a lot of flow might have been routed through $(u,v)$ but no additional commodity might be injected at $v$ since all witness embedding paths passing through $(u,v)$ might not end in $v$. Thus, dynamizing the push-relabel framework does not appear natural for this sequence of problems as it crucially requires that the maintained flow is a pre-flow at all times. In \cite{hua2023maintaining}, an involved batching technique is used instead (based on the technique in \cite{nanongkai2017dynamicMinimum}) that does not use dynamic flow problems but instead reduces to few static flow problems, however, at the loss of quality and runtime by subpolynomial factors.


\paragraph{The Push-Pull-Relabel Framework.} The main technical contribution of this paper is a new framework that refines pseudo-flows as efficiently as the push-relabel framework refines pre-flows. Thus, we give a generalization of the latter widely-used and well-studied framework that we believe might have applications well beyond our problem. Recall that the classic push-relabel framework maintains labels $\bell$ for all vertices and a pre-flow $\ff$. In each iteration, it 'pushes' positive excess flow at a vertex $v$ to a vertex at a lower label (to be precise to a vertex at level $\bell(v) - 1$); or if no 'push' is possible, it increases the labels of some vertices: it 'relabels'. Using a clever potential-based analysis, one can show that it suffices to only increase the labels to a certain threshold before all flow is settled. In our framework, we allow deleting edges, without compensating by adding source commodity at the endpoints, which might create negative excess leaving $\ff$ a pseudo-flow (instead of a pre-flow). Now, while our framework applies the same strategy for 'pushes' and 'relabels', we also need a new operation 'pull'. Intuitively, our algorithm tries to 'pull' back the source commodity that now causes the negative excess (this unit of commodity was 'pushed' earlier to some other vertices). To do so, a vertex $v$ with negative excess can 'pull' commodity from vertices at a higher level (again it can only pull from a vertex at level $\bell(v) + 1$). But it is not difficult to construct an example where this strategy does not suffice: therefore, we also need to sometimes decrease the label of a vertex to ensure correctness. However, the latter change to the 'relabel' operation breaks the property that labels are non-decreasing over time. A property that is crucial in the existing efficiency analysis. Instead, we give a much more careful argument to analyze the potentials that bound the number of push, pull, and relabeling operations that deal with the non-monotonicity of the levels over time. The argument is sketched below. Combining this framework with the above-discussed set-up of dynamic flow problems as proposed in \cite{hua2023maintaining} then yields the first near-optimal algorithm to compute an expander decomposition in a directed graph. Further, our technique extends seamlessly to also deal with edge deletions to $G$, yielding an algorithm to prune expander graphs that undergo edge deletions.

\paragraph{A Sketch of the Runtime of Push-Pull-Relabel.} The run-time analysis in standard push-relabel considers the run-time contribution of the push and relabel operations separately. Using a potential argument, one can then relate the contribution of the push operations to the relabeling operations. A similar argument albeit much more delicate also allows to relate the contribution of the push and the pull operations to the contribution of the relabeling operations in the extended push-pull-relabel algorithm. What might seem more daunting is to bound the run-time contribution of the relabelings given that the level function $\bell$ is no longer point-wise non-decreasing. Let us revisit the argument to bound the run-time contribution of the relabelings in the push-relabel of \cite{saranurak2019expander}. Any relabeling of $v$, incurs a cost of $O(\deg(v))$ as each incident edge has to be checked before a relabeling. At such a relabeling of $v$, the sink of $v$, which has by choice capacity $\deg_G(v)$, must be full and any commodity unit in it remains there till termination. Since the label of $v$ does not decrease and is bounded by $h$, we may thus charge for the run-time contribution of the relabelings of $v$ each unit in the sink of $v$ exactly $h$. Overall vertices, we conclude that any commodity unit was charged at most $h$ units. In the push-pull-relabel algorithm, a commodity unit might end up in various sinks. So a more clever charging argument needs to be devised. To guide intuition an analogy to flows of protons and electrons is useful. The protons correspond to commodity units and the electrons to the lack of commodity units. We are now moving protons and electrons around in the network and whenever a proton and an electron meet at a vertex they form a neutron which stays put at the vertex indefinitely. The neutrons will provide a mean to charge work in the analysis. The sink of each vertex $v$ can absorb $\deg(v)$ commodity units or put differently $\deg(v)$ protons. Electrons only form when we delete an edge $(u,v)$, i.e. exactly $\ff^+(u,v)$ new electrons form at $v$. By choice, we now say that if we perform a push from $u$ to $v$ of one unit then exactly one proton moves from $u$ to $v$, while if we perform a pull from $u$ to $v$ then exactly one electron moves from $v$ to $u$. Since we only perform a push away from $v$ if there are more than $\deg_G(v)$ free protons (not part of a neutron) at $v$ and a pull towards $v$ if there are free electrons at $v$, we find that $\min(\textbf{n}(v) + \deg_G(v)/2, \textbf{p}(v))$, where $\textbf{p}(v)$ denotes the number of protons at $v$ (including the ones in a neutron) and $\textbf{n}(v)$ denotes the number of electrons at $v$, is non-decreasing. This fact allows us to conclude that whenever we change from increasing $\bell(v)$ to decreasing $\bell(v)$ at least $\deg(v)/2$ new neutrons have formed at $v$. Since any neutron at $v$ stays put indefinitely, we can charge the run-time contributions of the relabelings of $v$ to the number of neutrons at $v$. 

\paragraph{Roadmap.} In the remainder of the article, we first give preliminaries in \Cref{sec:prelim}, then present our new push-pull-relabel framework in \Cref{sec:pushpullRelabel} and finally show how to obtain our result in \Cref{Main-thm} using the new framework in \Cref{sec:dirExpanderDecomp}.

\section{Preliminaries}
\label{sec:prelim}

\paragraph{Graphs.} We let $\deg_G \in \R^{V(G)}$ denote the degree vector of graph $G$. For all vertex $v \in V$, we have $\deg_G(v)$ equal to the number of edges incident to $v$ (both incoming and outgoing are counted). Moreover, for any subset of edges $D \subseteq E(G)$ we denote by $G_{D}$ the graph with vertex set $V(G)$ and edge set $D$ and by $\deg_D$ the degree vector of the subgraph $G_{D}$. We denote by $\vol_G(S)$ for any $S \subseteq V$, the sum of degrees of vertices in $S$. We denote by $E_G(A, B)$ for any $A, B \subseteq V$ the set of directed edges in $E(G)$ with tail in $A$ and head in $B$. We define $e(G) = |E(G)|$ and $e_G(A,B) = |E_G(A,B)|$. For any partition $\mathcal{P}$ of $V(G)$, we denote the graph obtained by contracting each partition class to a single vertex by $G/\mathcal{P}$. Two vertices in $G/\mathcal{P}$ are adjacent if there is an edge between the corresponding partition classes in $G$. Moreover, for any vertex $v \in V(G)$ we denote by $\mathbbm{1}_v \in \R^{V(G)}$ the vector with all entries equal to zero apart from the entry at $v$ equaling one. 

\paragraph{Flows.} We call a tuple $(G, \cc, \Delta, \nabla)$ a flow problem, if $G$ is a directed graph, the capacity function $\cc: V(G) \times V(G) \rightarrow \R^{\geq 0}$ is such that for all $(u,v) \not \in E$ we have $\cc(u,v) = 0$, and $\Delta, \nabla: V(G) \rightarrow \R^{\geq 0}$ denote the source and the sink capacities.
We denote flows on $G$ as functions $\ff: V(G) \times V(G) \rightarrow \R$ such that $\ff$ is anti-symmetric, i.e. $\ff(u,v) = - \ff(v,u)$. Given a vertex $v \in V(G)$ we introduce the notation $\ff(v) = \sum_u \ff(v,u)$ and likewise $\cc(v) = \sum_u \cc(v,u) + \cc(u,v).$ Moreover, we write $\ff^+(u,v) = \max(\ff(u,v), 0)$. Given a flow $\ff$, we say a vertex $v \in V(G)$ has $\Gamma(v) = \Delta(v) - \ff(v)$ excess. We say that it has positive excess if $\Gamma(v) > \nabla(v)$ and $v$ has negative excess if $\Gamma(v) < \nabla(v)/2.$ For a subset $\tilde{V} \subseteq V(G)$, we induce the flow $\ff$, and the sink $\nabla$, source $\Delta$ and edge capacities $\cc$ onto $G[\tilde{V}]$ in a function sense and write $\ff|_{\tilde{V}}, \nabla|_{\tilde{V}}, \Delta|_{\tilde{V}}, \cc|_{\tilde{V}}$. Moreover, for any subset $E \subseteq E(G)$, we write $\ff|_{E}$ for the flow induced by $\ff$ onto the subgraph of $G$ consisting only of the edges $E$. We say that a flow $\ff$ is a \emph{pseudo-flow} if it satisfies the capacity constraints:
\[\forall (u,v) \in V(G) \times V(G): -\cc(v,u) \leq \ff(u,v) \leq \cc(u,v).\] We say $\ff$ is a \emph{pre-flow} if $\ff$ is a pseudo-flow and has no negative excess at any vertex. We say a flow $\ff$ is \emph{feasible} if it is a pre-flow and additionally no vertex has positive excess. Moreover, for any subset $S \subseteq V$ we denote by $\Delta(S), \nabla(S)$ the sum $\sum_{v \in S} \Delta(v), \sum_{v \in S} \nabla(v)$ respectively and for any subset $D \subseteq E(G)$ we denote by $\cc(D)$ the sum $\sum_{d \in D} \cc(d).$



\paragraph{Expanders.} 
Given graph $G = (V,E)$, we say a cut $(S, \bar{S})$ is $\phi$-out sparse if $e_G(S) \leq e(G)$ and $e_G(S, V \setminus S) < \phi \cdot \vol_G(S)$. We say $G$ is a $\phi$-out expander if it has no $\phi$-out-sparse cut. We say $G$ is a $\phi$-expander if $G$ and $G^{rev}$, the graph where all edges of $G$ are reversed, are both $\phi$-out expander. The next lemma that is folklore and crucial in our expander pruning argument.

\begin{lemma} \label{lm:helper}
    Given a $\phi$-expander $G=(V,E)$, then take $S \subseteq V$ and a set of edge deletions $D$. We have that $e_{G \setminus {D}}(S, V \setminus S)  < \frac{\phi}{4} \cdot \operatorname{vol}_G(S)$ implies $\min(\operatorname{vol}_G(S), \operatorname{vol}_G(V \setminus S)) < \frac{4\cdot |D|}{3\phi}.$
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 0}\end{proof}

\paragraph{Graph Embeddings.} Given two graphs $H$ and $G$ over the same vertex set $V$, we say that $\Pi$ is an embedding of $H$ into $G$ if for every edge $e = (u,v) \in E(H)$, $\Pi(e)$ is a simple $uv$-path in $G$. We define the congestion of an edge $e \in E(G)$ induced by the embedding $\Pi$ to be the maximum number of paths in the image of $\Pi$ that contain $e$. We define the congestion of $\Pi$ to be the maximum congestion achieved by any such edge $e \in E(G)$. 
Moreover, for any edge $e \in E(G)$ we will denote by $\Pi^{-1}(e)$ the set of edges $f \in E(H)$ such that $e$ is an edge on the path $\Pi(f)$. Given an entire set of edges $D \subseteq E(G)$, we denote by $\Pi^{-1}(D)$ the set of edges $f \in E(H)$ such that some edge of the path $\Pi(f)$ is in $D$. Given two graphs $H_1, H_2$ on the same vertex set and embeddings $\Pi_1 : H_1 \rightarrow G, \Pi_2 : H_2 \rightarrow G$ then we denote by $\Pi_1 \cup \Pi_2 : H_1 \cup H_2 \rightarrow G$ the embedding of the graph $H_1 \cup H_2 = (V(H_1), E(H_1) \cup E(H_2))$ .

\paragraph{Expander Decompositions with Witnesses.} For the rest of the article, we use a definition of expander decompositions that encodes much more structure than given in \Cref{def:expdecomIntro}. In particular, the definition below incorporates the use of witness graphs which are instrumental to our algorithm. 

\begin{definition}\label{def:Witness}
    Given a directed graph $G$, we say $(W, \Pi)$ is a $(\phi, \psi)$-out-witness for $G$ if 1) $W$ is a $\psi$-out-expander, and 2) $\Pi$ embeds $W$ into $G$ with congestion at most $\frac{\psi}{\phi}$, and 3) $ \forall v \in V(W): \deg_{G}(v) \leq \deg_{W}(v) \leq \frac{\deg_G(v)}{\psi}$. If $(W, \Pi)$ is a $(\phi, \psi)$-out-witness for $G$ and for $G^{rev}$, then we say that $(W, \Pi)$ is a $(\phi, \psi)$-witness for $G$.

\begin{fact}
    If $(W_1, \Pi_1)$ is a $(\phi, \psi)$-out-witness for $G$ and $(W_2, \Pi_2)$ is a $(\phi, \psi)$-out-witness for $G^{rev},$ then $(W_1 \cup W_2, \Pi_1 \cup \Pi_2)$ is a $(\psi\phi/4, \psi^2/2)$-witness for $G$.
\end{fact}

\begin{proof}\textcolor{red}{TOPROVE 1}\end{proof}

\end{definition}

The next fact establishes that a $(\phi, \psi)$-(out-)witness for $G$ certifies that $G$ is a $\phi$-(out-)expander, justifying the name witness.

\begin{fact}[see \cite{hua2023maintaining}, Claim 2.1]\label{fact}
If $(W, \Pi)$ is a $(\phi,\psi)$-witness for $G$, then $G$ is a $\phi$-expander.
\end{fact}

\begin{proof}\textcolor{red}{TOPROVE 2}\end{proof}

\begin{definition}[Augmented Expander Decomposition]\label{def:augmentedED}
    We call a collection $\mathcal{X}$ and a subset $E^r \subseteq E$ a $(\beta, \phi, \psi)$-expander decomposition of a graph $G$, if 
    \begin{enumerate}
        \item \label{Def:ED-item1} $\forall (X, W, \Pi) \in \mathcal{X}$, $G[X]$ has a $(\phi, \psi)$-witness $(W, \Pi)$,
        \item \label{Def:ED-item2} $|E^r| \leq \beta \cdot \phi \cdot e(G)$,
        \item \label{Def:ED-item3} $(G \setminus E^r)/ \mathcal{P}$ is a DAG, where $\mathcal{P} = \{X \mid (X, W, \Pi) \in \mathcal{X}\}$.
    \end{enumerate}
    Given two expander decompositions $(\mathcal{X}_1,E^r_1)$ of the graph $G$ and  $ (\mathcal{X}_2,E^r_2)$ of the graph $G \setminus \mathcal{D}$, where $\mathcal{D} \subseteq E(G)$, we say $(\mathcal{X}_2,E^r_2)$ refines $(\mathcal{X}_1,E^r_1)$ if 1) for all partition classes $X_2$, where $(X_2, W_2, \Pi_2) \in \mathcal{X}_2$, there is a class $X_1$, where 
    $(X_1, W_1, \Pi_1) \in \mathcal{X}_1$, such that $X_2 \subseteq X_1$ and 2) $E_1^r \subseteq E_2^r \cup \mathcal{D}$.
\end{definition}







\begin{comment}
\paragraph{Vectors and matrices. } We denote vectors as bold lowercase letters $\xx$. For $\xx \in \R^n$ and $S \subseteq [n]$ we let $\xx(S)$ denote the sum of the entries of $\xx$ in the coordinates of $S$, i.e. $\xx(S) = \sum_{i \in S} \xx(i)$, and we let $\xx[S] \in \R^n$ denote $\xx$ restricted to $S$, i.e. $\xx[S](i) = \xx(i)$ if $i \in S$ and $\xx[S](i) = 0$ otherwise. We use $\mathbf{0}$ and $\mathbf{1}$ to denote the all-$0$ and the all-$1$ vectors respectively. We use $\mathbf{1}_u$ to denote the indicator vector which is zero everywhere but for coordinate $u$ where it is equal $1$. We use $\supp(\xx)$ to denote the support of a set, i.e. the set of coordinates in which $\xx$ is non-zero.

\paragraph{Graphs.} In this article, we work with both undirected and directed graphs, uncapacitated and capacitated. An undirected, capacitated graph $G=(V,E,\cc)$ consists of a vertex set $V$, an edge set $E$ where each edge is represented as a two-element set, i.e. if there is an undirected edge between $u$ and $v$ in $G$, then $\{u,v\} \in E$, and finally we have capacities $\cc \in \R^{|E|}_{\geq 0}$. We sometimes write $G = (V,E)$ which we take to be equivalent to the triple $(V, E, \vecone)$. We let $\mathbf{deg}_G$ denote the degree vector of graph $G$ where for each vertex $v \in V$, we have $\mathbf{deg}_G(v)$ equal to the number of edges incident to $v$. We denote by $\vol_G(S)$ for any $S \subseteq V$, the sum of degrees of vertices in $S$. We denote by $E(A, B)$ for any $A, B \subseteq V$ the set of edges in $E$ with one endpoint in $A$ and another in $B$. For a graph $G$ and a positive integer $\alpha$, we write $\alpha \cdot G$ to denote the graph tuple $(V, E, \alpha \cdot \cc)$.

For a directed graph $\dir{G} = (\dir{V}, \dir{E}, \dir{\cc})$, we have $\dir{V}$ again being the vertex set, and $\dir{E}$ be a set of two-tuples, where $(u,v) \in \dir{E}$ if and only if there is an edge directed from $u$ to $v$. We write $\dir{G} \gets \textsc{Directify}(G)$ to denote a transformation of an undirected graph $G$ into a directed graph where $\dir{V} = V$, $\dir{E} = \{ (u,v) | \{u,v\} \in E\}$ and each such tuple $(u,v)$ receives capacity $ \dir{\cc}(u,v) = \cc(\{u,v\})$. We let $\mathbf{deg^{out}}_{\dir{G}}$ be the out-degree vector of $\dir{G}$, i.e. the for vertex $v$, $\mathbf{deg^{out}}_{\dir{G}}(v)$ is the number of edges in $\dir{E}$ with tail $v$. We denote by $\dir{E}(A, B)$ for any $A, B \subseteq V$ the set of edges in $E$ with tail in $A$ and head in $B$. Given any set $S \subseteq V$, we let $\dir{G}[S]$ denote the graph induced by the vertex set $S$.

For convenience, we extend the capacity functions $\cc$ / $\dir{\cc}$ to all two-element sets $\{u,v\} \subseteq V$/ tuples $(u,v) \in V^2$ to be zero everywhere where it is not defined. 

\paragraph{The Incidence Matrix.} We define $\BB_{\dir{G}} \in \R^{|\dir{V}| \times |\dir{E}|}$ to be the edge-vertex incidence matrix 
\begin{align*}
    \BB_{\dir{G}}(v, e) = \begin{cases} 
        1 & \text{if } e = (u,v) \\
        -1 & \text{if } e = (v,u) \\
        0 & \text{otherwise}
    \end{cases}
\end{align*}

\paragraph{Flows.} For flows, we only consider directed, capacitated graphs $\dir{G} = (\dir{V}, \dir{E}, \dir{\cc})$ where all anti-parallel edges are present in $\dir{E}$, i.e. if $(u,v) \in \dir{E}$ then so is $(v,u)$. We call a flow $\ff \in \R^{|\dir{E}|}$ \emph{feasible} if $\mathbf{0} \leq \ff \leq \dir{\cc}$. We let $\ss \in \R^{|\dir{V}|}_{\geq 0}$ denote a source vector, and $\tt \in \R^{|\dir{V}|}_{\geq 0}$ a sink vector. We say that $\ss$ and $\tt$ are valid if $\vecone^{\trp} (\ss - \tt) \leq 0$. We assume that all source and sink vector pairs that we work with are valid.

We define the source and sink excess $\xx^{\text{source}}_{\ss, \tt, \dir{G}, \ff} = \max(\ss - \tt - \BB_{\dir{G}} \ff, \veczero)$ and $\xx^{\text{sink}}_{\ss, \tt, \dir{G}, \ff} = \max(- \ss + \tt + \BB_{\dir{G}} \ff, \veczero)$  which are given by the source and sink demands not routed by $\ff$ respectively. If $\xx^{source}_{\ss, \tt, \dir{G}, \ff} = \veczero$ all the flow is said to be routed. 

We define the residual graph to be $\dir{G}_{\ff} = (\dir{V}, \dir{E}_{\ff}, \dir{\cc}_{\ff})$ where we have $\dir{\cc}_{\ff}(u,v) = \max\{0, \dir{\cc}(u,v) - \ff(u,v) + \ff(v,u)\}$ for all $(u,v) \in V^2$, and $(u,v)$ in $E_{\ff}$ if and only if $\dir{\cc}_{\ff}(u,v) > 0$. We then typically want to solve the problem of routing the residual source vector $\xx^{\text{source}}_{\ss, \tt, \dir{G}, \ff}$ and residual sink vector $\xx^{\text{source}}_{\ss, \tt, \dir{G}, \ff}$.

\paragraph{Push-Relabel Maximum Flow Algorithm. } We next explain the algorithm behind the famous Push-Relabel framework by Tarjan and Goldberg and state one of the main theorems of their paper on correctness. We give the details for the implementation and a runtime analysis in the later part of the paper.

The Push-Relabel Algorithm maintains a labeling $\ell$ over the vertex set and initializes each label also called the \emph{level} of a vertex to $0$. It initializes a flow $\ff$ also to be the zero-flow. It then iteratively manipulates $\ell$ and $\ff$ as follows. As long as it can find an \emph{active} vertex, that is a vertex $v$ with $\ell(v) < n$ and $\xx^{\text{source}}_{\ss, \tt, \dir{G}, \ff}(v) > 0$, it either finds that
\begin{itemize}
    \item \textsc{Push}: $v$ has an edge in $G_{\ff}$ to a lower-level vertex $u$, i.e. there is an edge $(v,u) \in E_{\ff}$ with $\ell(v) = \ell(u) + 1$: then, it add $\min\{ \xx^{\text{source}}_{\ss, \tt, \dir{G}, \ff}(v), \dir{\cc}_{\ff}(v,u) \}$ units of flow to the edge from $(v,u)$. 
    \item \textsc{Relabel}: or $v$ has no such edge incident in $E_{\ff}$, in this case, it find the edge $(v, u) \in E_{\ff}$ with smallest $\ell(u) \geq \ell(v)$ and increases the level $\ell(v)$ to $\ell(u) +1$, and if there is no such edge in $E_{\ff}$, sets $\ell(v)$ to $n$.
\end{itemize}
Once this process terminates, they output the flow $\ff'$ where $\ff'(u,v) = \max\{0, \ff(u,v) - \ff(v,u)\}$ for each edge $(u,v) \in \dir{E}$ (i.e. $\ff'$ is the flow $\ff$ after cancelling flows on anti-parallel edges).

Tarjan and Goldberg show that the order in which the active vertices are selected to update the labelling/ flow is not important for correctness.

They then show that the level $\ell(v)$ serves as a lower bound for each vertex $v$ on the distance from residual sink vertices in the residual graph $G_{\ff'}$. They then show the following result which allows us to establish the correctness of the algorithm to find maximum flows.

\begin{fact}[Push-Relabel]
    \label{fct:pushRelabel}
    Given a graph $G = (V,E, \dir{\cc})$, sources $\ss$ and sinks $\tt$, and an integer $1 \leq h \leq n$. Then, running the Push-Relabel Algorithm as explained above with the modification that vertices are no longer considered active if their level is $h$ or higher yields a flow $\ff'$ that is feasible with respect to $\dir{\cc}$ such that:
    \begin{enumerate}
        \item there is no path consisting of less than $h$ edges in the residual graph $G_{\ff'}$ from any vertex $s \in \supp(\xx^{\text{source}}_{\ss, \tt, \dir{G}, \ff'})$ to any vertex $t \in \supp(\xx^{\text{sink}}_{\ss, \tt, \dir{G}, \ff'})$.
        \item $\BB \ff' + \ss \geq \veczero$, i.e. the in-flow into a vertex (where the original source can be interpreted as in-flow) is at least as big as the out-flow at each vertex. 
    \end{enumerate}
\end{fact}
\begin{remark}
To obtain an actual Maximum Flow, one has to choose $h = n$ and then use that the residual graph of $\ff'$ and $\ff$ are identical, and that choosing $h = n$ amounts to proving the non-existence of any path in the residual network to route flow from a source to a sink. But this means that there is no augmenting path in the residual network which establishes optimality of the flow. While there might still be excess flow at some vertices, the remaining task is then to route this flow back to their respective source vertices which can be achieved by tracing the flow paths created by the algorithm.
\end{remark}
\end{comment}

\begin{comment}
\section{Our Framework}

\subsection{Push-Pull-Relabel}

For any edge $e$, we denote by $f^+(e) = \max\{f(e), 0\}$ and by $f^-(e) = \max\{-f(e), 0\}$. Moreover, $\forall v \in V(G): \operatorname{ab}_f(v) = \min\{f^-(v), \deg(v) \}$ and $\operatorname{ex}_f(v) = \Delta(v) - f^+(v) + f^-(v) - \operatorname{ab}_f(v).$

\begin{definition}
    Given a directed graph $G$, a source capacity $\Delta$ and an edge capacity $c$, then we call a function $f: E(G) \rightarrow \R$ a pre-flow if 
    \[\forall e=(u,v) \in E(G): f(u,v) \leq c(e).\]
    Given a level function $\ell: V(G) \longrightarrow [h]$, we call a tuple $(f, \ell)$ a state for $(G, c, \Delta)$ if $f$ is a pre-flow and additionally
    \[\forall u, v \in V(G): \left(\ell(u) > \ell(v) + 1 \right) \longrightarrow f(u, v) = c.\]
    We call the state $(f, \ell)$ valid if it satisfies
    \begin{enumerate}
        \item $\forall v \in V(G):  \left( f^-(v) + \Delta(v) < f^+(v) \right)\longrightarrow \ell(v) = 0$ 
        \item $\forall v \in V(G): \left(f^+(v) + \nabla(v) < \Delta(v) + f^-(v) \right) \longrightarrow \ell(v) = h.$
    \end{enumerate}
\end{definition}

$\Delta^+(v) = \Delta(v) + f^-(v) - f^+(v) - \nabla(v)$  and $\Delta^-(v) = f^+(v) - f^-(v) - \Delta(v)$. 

\begin{lemma}
    For any flow problem $(G, c, \Delta)$ and any invalid state $(f, \ell)$ the algorithm $\operatorname{PullPushRelabel}$ computes a valid state $(f', \ell')$ in time $O\left(h \cdot \sum_v \max(\Delta^+(v), \Delta^-(v))\right)$.
\end{lemma}
 
\newpage

\begin{algorithm}[H]
    \begin{algorithmic}
    \caption{$\operatorname{Unit-Flow}(G, h,(\Delta, f, l))$}\label{alg:UnitFlow}
    \While{$\exists v$ where $l(v) > 0$ and $\sum_{v}f(v,w) < -\deg(v)$}
        \State Let $v$ be a vertex with highest $l(v)$.
        \If{$\exists \operatorname{arc}(u, v)$ such that $r_f(u, v)>0, l(u)=l(v)+1$}
            \State $\operatorname{Pull}(u, v)$
        \Else
            \State Relabel $(v)$.
        \EndIf
    \EndWhile
    \While{$\exists v$ where $l(v)<h$ and $\Delta(v) - f(v) > \deg(v)$}
        \State Let $v$ be a vertex with smallest $l(v)$.
        \If{$\exists \operatorname{arc}(v, u)$ such that $r_f(v, u)>0, l(v)=l(u)+1$}
            \State $\operatorname{Push}(v, u)$
        \Else
            \State Relabel $(v)$.
        \EndIf
    \EndWhile
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
    \begin{algorithmic}
    \caption{$\operatorname{Push}(v,u)$}\label{alg:Push}
    \State Assertion: $\operatorname{ex}(u)=0$.
    \State $\psi=\min \left(\operatorname{ex}(v), r_f(v, u), \operatorname{deg}(u)-\operatorname{ex}(u)\right)$
    \State Send $\psi$ units of supply from $v$ to $u$:
    \State $f(v, u) \leftarrow f(v, u)+\psi, f(u, v) \leftarrow f(u, v)-\psi$
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
    \begin{algorithmic}
    \caption{$\operatorname{Pull}(u,v)$}\label{alg:Pull}
    \State $\psi=\min \left(\Delta^-(v), r_f(v, u), \operatorname{deg}(u)-\operatorname{ex}(u)\right)$
    \State Send $\psi$ units of supply from $v$ to $u$:
    \State $f(v, u) \leftarrow f(v, u)+\psi, f(u, v) \leftarrow f(u, v)-\psi$
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{$\operatorname{Relabel}(v,u)$}\label{alg:Relabel}
\begin{algorithmic}
    \If{$\sum_w f(v,w) < \Delta(v)$}
    \State $l(v) \leftarrow l(v) - 1$
    \Else
    \State $l(v) \leftarrow l(v) + 1$
    \EndIf
    
    \end{algorithmic}
\end{algorithm}


\newpage

\begin{proof}
    We introduce the potential function
    \[\Phi(t) = \sum_v \Delta_t^+(v) \cdot \ell(v)  + \sum_v \Delta_t^-(v) \cdot \left(h - \ell(v)\right) + \sum_{p \in \Delta_t^+} (2h - c_t(p)) \]
    where $c_0 = 0$ and   
\end{proof}


\subsection{Expander Decomposition}


\subsection{Expander Pruning}

\begin{definition}
    We call a directed graph $G$, a $\phi$-out-expander with $\psi$-witness $(W, \Pi)$. If there exists a $\psi$-out-expander $W$ embedded into $G$ with congestion at most $\frac{\psi}{\phi}$ such that 
    \[\forall v \in V(W): \deg_{W}(v) \leq \deg_{G}(\Pi(v)).\]
    We call a directed graph $G$, a $\phi$-expander with $\psi$-witness $(W, \Pi)$. If $G$ is a $\phi$-out-expander with $\psi$-witness $(W_1, \Pi_1)$ and $G^{rev}$ is a $\phi$-out-expander with $\psi$-witness $(W_2, \Pi_2)$.
\end{definition}


\begin{lemma} \label{lm:helper}
    Given a $\phi$-expander $G$ and a set of deletions $D$. Then for any sparse cut in $G' = G \setminus D$, we have $\forall S \subseteq V(G'):$
    \[\min\{ e_{G'}(S, V(G) \setminus S), e_{G'}(S, V(G) \setminus S)\}  < \frac{\phi}{2} \cdot \text{vol}_G(S) \longrightarrow vol_G(S) < \frac{2\cdot |D|}{\phi}\]
\end{lemma}






\begin{lemma}\label{lm:PruneOrCertify}
    Given a $\phi$-out-expander $G$ with a $\psi$-witness $(W, \Pi)$, a set of deletions $D$ in $G$, where $|D| \leq \phi \cdot m$, then, for any valid-state $(f,\ell)$ of a induced subgraph $\left(G\setminus D\right)[\tilde{V}]$, where $E(\tilde{V}, V(G) \setminus \tilde{V}) \subseteq D$, the algorithm $\operatorname{PruneOrCertify}$ returns a new valid-state $(f',\ell')$ and a cut $S$. Moreover, we either have
    \begin{enumerate}
        \item If $S$ is empty, then $\left(G\setminus D\right)[\tilde{V}]$ is a $\phi$-expander 
        \item Otherwise, the cut $S$ satisfies 

        \begin{enumerate}
            \item $\forall v \in \tilde{V}: \ell'(v) = h \longrightarrow v \in S$
            \item $e_{G \setminus D}(S, \tilde{V} \setminus S) \leq \phi \cdot vol_{G}(S)$
            \item $\sum_{e \in E(\tilde{V} \setminus S, S)} f'(e) \leq \phi \cdot vol_{G}(S)$
        \end{enumerate}
    \end{enumerate}
    The run time of the algorithm is $O\left(h \cdot \sum_{v \in \tilde{V}} (\Delta^+(v) + \Delta^-(v)) \right).$
\end{lemma}

\begin{algorithm}[H]
\caption{PruneOrCertify}\label{alg:PruneOrCertify}
\begin{algorithmic}
\State Compute $(f',\ell')$ by running the Unit Flow algorithm for $h=\frac{16 \log (m)}{\psi \phi}$ rounds on $(f, \ell, \Delta)$.
\State $k \leftarrow h$
\Repeat
\State $S \leftarrow S \cup\left\{v \in V \mid \ell'(v)=k\right\}$
\State $k \leftarrow k - 1$
\Until{$\phi \cdot \operatorname{vol}_G(S) \leq \operatorname{vol}_G(\left\{v \in V \mid \ell'(v)=k\right\})$}
\State return the state $(f',\ell')$ and the cut $S$ 
\end{algorithmic}
\end{algorithm}

\begin{proof}[Proof of Lemma \ref{lm:PruneOrCertify}]
It is clear that the $(f',\ell')$ returned by the $\operatorname{PushPullRelabel}$ algorithm is a valid-state. Hence, it suffices to treat the two cases separately.\\
\\
\textbf{Case 1:} Given the $\ell'$-feasible flow $f'$, let us construct a new $\frac{\psi}{}$-witness $\tilde{W}$ for the graph $\left(G \setminus D\right)[\tilde{V}]$ with an embedding $\tilde{\Pi}$ of congestion $\frac{2\psi}{\phi}$ and such that $\forall v \in \tilde{V}: \deg_G(v) \leq \deg_W(v)$. This will verify that $\left(G\setminus D\right)[\tilde{V}]$ is a $\frac{\phi}{}$-expander.



In order to construct $\tilde{W}, \tilde{\Pi}$ we first pick a path-decomposition of $f$ such that at any vertex exactly $\max(0, f^+(v) - f^-(v))$ paths begin and at most $\max(0, f^-(v) - f^+(v))$ end. We enumerate these paths.

We initialize $\tilde{W}$ as $W_0 = \Pi^{-1}((G \setminus D)[\tilde{V}])$.

For any vertex $v \in \tilde{V},$ we pick the first $\min(\max(0, f^+(v) - f^-(v)) , \Delta(v))$ paths starting with $v$. For any such path $p_{v,w}$ starting in $v$ and ending in $w$, we add the edge $e = (v,w)$ to $\tilde{W}$ and embed this edge through $\tilde{\Pi}(e) = p_{v,w}$. If $\max(0, f^+(v) - f^-(v)) < \Delta(v)$ then we additionally add $\Delta(v) - \max(0, f^+(v) - f^-(v))$ self-loops to $v$. We observe that we added exactly $\Delta(v)$ outedges to $v$ and since $(f', \ell')$ is valid we added at most $f^-(v) - f^+(v) + \Delta(v) \leq \nabla(v)$ incoming edges to $v$. Hence, we have that 
\[\deg_{\tilde{W}}(v) \leq \deg_{W_0}(v) + \nabla(v) + \Delta(v) \leq \deg_{W_0}(v) + \deg_W(v) + \frac{4}{\psi}\left(\deg_W(v) - \deg_{W_0}(v)\right) \leq \frac{5}{\psi} \deg_W(v)\]


It is clear that $\tilde{\Pi}$ is an embedding with congestion $\frac{2\psi}{\phi}$ and it remains to prove the following claim.\\
\\
\textbf{Claim:} $\tilde{W}$ is a $\frac{\psi}{4}$-expander.

\begin{proof}
    Assume by contradiction that there is $S \subseteq \tilde{V}: vol_{\tilde{W}}(S) \leq vol_{\tilde{W}}(\tilde{V} \setminus S)$ such that 
    \[e_{\tilde{W}}(S, \tilde{V} \setminus S) \leq \frac{\psi}{4} vol_{\tilde{W}}(S).\]
    Since $W$ is a $\psi$-expander, we have
    \[e_W(S, \tilde{V} \setminus S) + e_W(S, V(G) \setminus \tilde{V}) = e_W(S, W \setminus S) \geq \psi \cdot vol_W(S).\]
    We observe that any edge $e \in E_W(S, V(G) \setminus \tilde{V})$ and any edge $e \in E_{W}(S, \tilde{V} \setminus S) \setminus E_{W_0}(S, \tilde{V} \setminus S)$ contributes one to the sum $\sum_{v \in S} \Delta(v)$. Therefore, we have that 
    \[\sum_{v \in S} \Delta(v) \geq \frac{4}{\psi} \left( e_W(S, V(G) \setminus \tilde{V}) + e_{W}(S, \tilde{V} \setminus S) - e_{W_0}(S, \tilde{V} \setminus S) \right).\]
    Since we add to any vertex $v \in S$ at least $\Delta(v)$ outgoing edges and at most $\sum_{v \in S} \nabla(v)$ of these edges can end in $S$, we add at least $\sum_{v \in S} \Delta(v) - \sum_{v \in S} \nabla(v)$ edges going across the cut $(S, \tilde{V} \setminus S).$ Hence, the number of edges going across the cut is at least
    \[e_{W_0}(S, \tilde{V} \setminus S) + \sum_{v \in S} (\Delta(v) - \nabla(v)).\]
    Either $e_{W_0}(S, \tilde{V} \setminus S) \geq \frac{\psi}{} vol_{\tilde{W}}(S)$ or we can lower bound it by
    \[ \frac{4}{\psi} \left( e_W(S, V(G) \setminus \tilde{V}) + e_{W}(S, \tilde{V} \setminus S)\right) - 2 \cdot vol_W(S) \geq 4 \cdot vol_W(S) - 2 \cdot vol_W(S).\]
    Either way, we have that at least $\frac{\psi}{} vol_{\tilde{W}}(S)$ edges cross the cut.
\end{proof}
\textbf{Case 2:}
We simply need to prove that the while-loop breaks before $k = 0$. Let us enumerate the sets $S_i = \{v \in \tilde{V} \mid \ell'(v) \geq i\}.$ We observe that $vol(S_1) \leq m$. Thus, there exists $1 \leq i \leq h$ such that $vol_W(S_{i}) < (1 + \phi) \cdot vol_W(S_{i+1}).$ We observe that
\[e_{W}(S_{i+1}, \tilde{V} \setminus S_{i+1}) \leq e_{W}(S_{i+1}, S_{i}) + e_{W}(S_{i+1}, \tilde{V} \setminus S_{i}) \leq \left( vol_W(S_{i}) - vol_W(S_{i+1}) \right) + e_{W}(S_{i+1}, \tilde{V} \setminus S_{i}).\]
Since $(f',\ell')$ is a state, we have that the capacity of the edges $e \in E(S_{i+1}, \tilde{V} \setminus S_i)$ is saturated and the edges $e \in E(\tilde{V} \setminus S_i, S_{i+1})$ do not carry any flow. Moreover, since $(f',\ell')$ is valid we have that $\forall v \in S_{i+1}: f^+(v) \leq f^-(v) + \Delta(v)$. Hence, we can bound 
\[c \cdot e_{W}(S_{i+1}, \tilde{V} \setminus S_{i}) \leq \Delta(S_{i+1}) + f^-(S_{i+1}) \leq \Delta(S_{i+1}) + c \cdot \left( vol_W(S_{i}) - vol_W(S_{i+1}) \right).\]
Hence, we obtain the bound
\begin{align}
    e_{W}(S_{i+1}, \tilde{V} \setminus S_{i+1}) &\leq \frac{\Delta(S_{i+1})}{c} + 2 \cdot \left( vol_W(S_{i}) - vol_W(S_{i+1}) \right) \\
    &\leq \frac{\Delta(S_{i+1})}{c} + \phi \cdot vol_W(S_{i+1}) \\
    &\leq \phi \cdot vol_W(S_{i+1})
\end{align}
and thus the while loops breaks in the $i$-th iteration.

\end{proof}


\begin{theorem}[Expander Pruning]\label{thm:ExpanderPruning} Let $G=(V, E)$ be a $\phi$-expander with $m$ edges and $\psi$-witness $(W, \Pi)$. Given a set of deletions $D$, algorithm $\operatorname{ExpanderPruning}$ computes two sequences $\left(P_i\right)_i, \left(Q_i\right)_i$ of sets such that 

\begin{enumerate}
    \item $\forall i > 0: e_G\left(P_i, V_{i, i-1} \right) \leq \phi \cdot \operatorname{vol}(P_i) $
    \item $\forall i > 0: e_G\left(V_{i,i}, Q_i\right) \leq \phi \cdot \operatorname{vol}(Q_i) $
    \item $\sum_{i} \operatorname{vol}(P_i) + \operatorname{vol}(Q_i) \leq \frac{|D|}{\phi}$
    \item $(G \setminus D)\left[V \setminus \bigcup_i \left(P_i \cup Q_i\right)\right]$ is a $\phi$-expander
\end{enumerate}
where $V_{k,l} = V \setminus \left( \bigcup_{j \leq k} P_j \cup \bigcup_{j \leq l} Q_j \right).$ The total run time is $O\left(|D| \log m / \phi^2 \right)$.
\end{theorem}


\begin{algorithm}[H]
\caption{Expander Pruning}\label{alg:Expander Pruning}
\begin{algorithmic}
\State Let $f_0$ be the flow induced by $\Pi_1, \ell_0$ the trivial level set
\State Let $g_0$ be the flow induced by $\Pi_2, h_0$ the trivial level set 
\State $i \leftarrow 0$
\Repeat 
\State $i \leftarrow i + 1$
\State $(P_i, (f_i, \ell_i)) \leftarrow \text{PruneOrCertify}(G, D, \tilde{V} = V_{i-1,i-1}, (f_{i-1}, \ell_{i-1}))$
\State $(Q_i, (g_i, h_i)) \leftarrow 
\text{PruneOrCertify}(G^{rev}, D^{rev}, \tilde{V} = V_{i,i-1}, (g_{i-1}, h_{i-1}))$
\Until{$P_i, Q_i = \emptyset$}
\end{algorithmic}
\end{algorithm}

\begin{proof}
    We remark that the first, the second, and the fourth item follow immediately from Lemma \ref{lm:PruneOrCertify}. For the third item and the run time, we first observe that we can relate the third item and the run time to $\Delta^+_{f_i}, \Delta^+_{g_i}.$\\
    \\
    \textbf{Claim 1:} 
    \begin{align*}
        \sum_{i} \operatorname{vol}(P_i) &\leq \sum_{i} \Delta^+_{f_{i-1}}(V_{i-1,i-1})\\
        \sum_{i} \operatorname{vol}(Q_i) &\leq \sum_{i} \Delta^+_{g_{i-1}}(V_{i, i-1})
    \end{align*}
    \\
    \\
    \textbf{Claim 2:} The run time is bounded by \[h \cdot \left( \sum_{i} \left(\Delta^+_{f_i}(V_{i,i}) + \Delta^-_{f_{i}}(V_{i,i})\right) + \sum_{i} \left(\Delta^+_{g_i}(V_{i,i}) + \Delta^-_{g_{i}}(V_{i,i})\right) \right) \]
    

    Now that we have derived these relationships it remains to study the evolution of $\Delta^+_{f_i}, \Delta^+_{g_i}$ over index $i$.
    \\
    \\
    \textbf{Claim 3:} 
    \begin{align*}
        \Delta^+_{f_i}(V_{i,i}) & \leq \sum_{e \in E(V_{i,i}, P_i)} f(e) + \sum_{e \in E(Q_i, V_{i,i})} g(e) \\
        \Delta^-_{f_i}(V_{i,i}) & \leq \sum_{e \in E(P_i, V_{i,i})} f(e) + \sum_{e \in E(V_{i,i}, Q_i)} g(e)
    \end{align*}

    \textbf{Claim 4:} 
    \begin{align*}
        \Delta^+_{f_i}(V_{i,j}) & \leq \frac{\Delta^+_{f_{i-1}}(V_{i,j})}{2} \\
        \Delta^-_{f_i}(V_{i,j}) & \leq \frac{\Delta^-_{f_{i-1}}(V_{i,j})}{2}
    \end{align*}
    
    We note that combining claim 1 and claim 2, we readily obtain the third item:
    \begin{align*}
        \sum_{i} \operatorname{vol}(P_i) + \operatorname{vol}(Q_i) &\leq \sum_{i} \Delta^+_{f_{i}}(V_{i,i}) + \Delta^+_{g_{i}}(V_{i+1, i}) \\
        &\leq \sum_{i} \frac{1}{2^i} \cdot \left(\Delta^+_{f_0}(V) + \Delta^-_{g_0}(V_{1,0}) \right)\\
        &\leq \frac{|D|}{\phi} 
    \end{align*}

    
\end{proof}



\begin{algorithm}[H]
\caption{Expander Pruning}\label{alg:Expander Pruning}
\begin{algorithmic}
\State Let $f_0$ be the flow induced by $\Pi$
\For{$i \leq k$}
\State $P_i \leftarrow P_{i-1}$
\State $(f_i, \ell_i) \leftarrow (f_{i-1}, \ell_{i-1})$
\Repeat 
\State $(S, (f_i, \ell_i)) \leftarrow \text{PruneOrCertify}(G, D_i, \tilde{V} = V(G) \setminus P_i, (f_i, \ell_i, \Delta))$
\State $P_i \leftarrow P_i \cup S$
\Until{$S = \emptyset$}
\EndFor
\end{algorithmic}
\end{algorithm}




\begin{theorem}[Expander Pruning]\label{thm:ExpanderPruning} Let $G=(V, E)$ be a $\phi$-expander with $m$ edges. There is a deterministic algorithm with access to adjacency lists of $G$ such that, given an online sequence of $k \leq \phi m / 10$ edge deletions in $G$, can maintain pruned sets $P, Q \subseteq V$ such that the following property holds. Let $G_i$ and $P_i, Q_i$ be the graph $G$ and the set $P, Q$ after the $i$-th deletion. We have, for all $i$,
\begin{enumerate}
    \item $P_0, Q_0=\emptyset$ and $P_i \subseteq P_{i+1}, Q_i \subseteq Q_{i+1}$,
    \item $\operatorname{vol}_G\left(P_i\right), \operatorname{vol}_G\left(Q_i\right)  \leq \frac{2i}{\phi}$,
    \item $e_{G_i}\left(P_i, V \setminus (P_i \cup Q_{i})\right), e_{G_i}\left(V \setminus (P_i \cup Q_i), Q_i\right) \leq \frac{i}{2}$,
    \item $e_{G_i}(P_i, Q_i) \leq i$
    \item $G_i\left\{V \setminus (P_i \cup Q_i)\right\}$ is a $\phi / 6$-expander.
\end{enumerate}
The total time for updating $\left(P_i\right)_i, \left(Q_i\right)_i$ is $O\left(k \log m / \phi^3\right)$.
\end{theorem}

\begin{algorithm}[H]
\caption{Expander Pruning}\label{alg:Expander Pruning}
\begin{algorithmic}
\For{$i \leq k$}
\State $P_i \leftarrow P_{i-1}, Q_i \leftarrow Q_{i-1}$
\State $(f_i, \ell_i, \Delta_i) \leftarrow (f_{i-1}, \ell_{i-1}, \Delta_{i-1}), (g_i, h_i, \Delta_i) \leftarrow (g_{i-1}, h_{i-1}, \Delta_{i-1})$
\Repeat 
\State $(S, (f_i, \ell_i, \Delta_i)) \leftarrow \text{PruneOrCertify}(G, \tilde{V} = V(G) \setminus (P_i \cup Q_i), (f_i, \ell_i, \Delta_i))$
\State $P_i \leftarrow P_i \cup S$
\State $(T, (g_i, h_i, \Delta_i)) \leftarrow 
\text{PruneOrCertify}(G^{rev}, \tilde{V} = V(G) \setminus (P_i \cup Q_i), (g_i, h_i, \Delta_i))$
\State $Q_i \leftarrow Q_i \cup T$
\Until{$S, T = \emptyset$}
\EndFor
\end{algorithmic}
\end{algorithm}

\begin{proof}[Proof of Theorem \ref{thm:ExpanderPruning}]
    We begin with verifying that we correctly call $\operatorname{PruneOrCertify}$.\\
    \\
    \textbf{Claim:} Given, We have that $(f_{i-1}|_{G_i[V]}, \ell_i)$ is a valid state on $G_i[]$ for 
    \begin{proof}
        
    \end{proof}
    We enumerate the sets $S, T$ by $S_k, T_k$ over all loops. By condition two of Lemma \ref{lm:PruneOrCertify} we obtain, if $S_k, T_k$ belong to the $i$-th iteration of the for-loop.
    \begin{align}
        e_{G_i}\left(S_k, V \setminus \left(\bigcup_{j \leq k} S_j \cup \bigcup_{j \leq k-1} T_j \right)\right) &\leq \frac{\phi}{4} \cdot \text{vol}_G(S_k) \\
        e_{G_i}\left(T_k, V \setminus \left(\bigcup_{j \leq k} S_j \cup \bigcup_{j \leq k} T_j \right)\right) &\leq \frac{\phi}{4} \cdot \text{vol}_G(S_k)
    \end{align}
    Let $S_l, T_l$ be the last sets $S, T$ belonging to the $i$-th iteration. Then, we have 
    \[P_i = \bigcup_{k \leq l} S_k, Q_i = \bigcup_{k \leq l} T_k.\]
    Hence, 
    \begin{align}
        e_{G_i}\left(P_i, V \setminus (P_i \cup Q_{i}) \right) &\leq \sum_{k \leq l} e_{G_i}\left(S_k, V \setminus \left(\bigcup_{j \leq l} S_j \cup \bigcup_{j \leq l} T_j \right)\right) \\
        &\leq \frac{\phi}{4} \cdot \sum_{k \leq l} \text{vol}_G(S_k) = \frac{\phi}{4} \cdot \text{vol}_G(P_i) \label{eq1}
    \end{align}
    and similarly we obtain $e_{G_i}\left(V \setminus (P_i \cup Q_{i} \right), Q_i) \leq \phi \cdot \text{vol}_G(Q_i)$. Moreover, for any edge $e \in E_{G_i}(P_{i}, Q_{i})$ there are $k, j$ such that $e \in E_{G_i}(S_k, T_l)$. If $k \leq j$ then 
    \[e \in E_{G_i}\left(S_k, V \setminus \left(\bigcup_{j \leq k} S_j \cup \bigcup_{j \leq k-1} T_j \right)\right)\]
    and otherwise 
    \[e \in E_{G_i}\left(T_k, V \setminus \left(\bigcup_{j \leq k} S_j \cup \bigcup_{j \leq k} T_j \right)\right).\]
    Hence, 
    \begin{align}
        e_{G_i}(P_i, Q_i) &\leq \sum_{k \leq \ell} e_{G_i}(S_k, V \setminus (P^k \cup Q^{k-1})) + e_{G_i}(V \setminus (P^k \cup Q^{k}), T^{k}) \\
        &\leq \frac{\phi}{4} \cdot (\text{vol}_G(P_i) + \text{vol}_G(Q_i)) \label{eq2}
    \end{align}
    W.l.o.g. we assume that $\text{vol}_G(Q_i) \leq \text{vol}_G(P_i)$. Then inequalities \eqref{eq1}, \eqref{eq2} imply that 
    \[e_{G_i}(P_i, V \setminus P_i) \leq \frac{\phi}{2} \cdot \text{vol}_G(P_i) \]
    Therefore, by Lemma \ref{lm:helper} we have that 
    \[\text{vol}_G(Q_i) \leq \text{vol}_G(P_i) \leq \frac{2i}{\phi}.\]
    Using this bound in turn, we have that inequalities \eqref{eq1}, \eqref{eq2} imply items 3 and 4 of the theorem. Provided the algorithm ExpanderPruning terminates, item 5 follows from condition 1 of Lemma \ref{lm:PruneOrCertify}. It remains to prove that the algorithm terminates and the bound on the run-time.We remark that every time, we invoke PruneOrCertify either the $\ell$ is increased or the pre-flow $f$ was already a feasible flow. Hence, we can bound the run-time of ExpanderPruning by the sum of the run-time for each PruneOrCertify execution. Hence, we obtain the run-time bound
    \[O\left(\sum_{i \leq k} \sum_{v \in V}(\text{ab}_{f_i}(v) + \text{ab}_{g_i}(v) + \Delta_i(v)) \cdot (\ell_{i+1}(v) - \ell_i(v)) \right).\]
    We remark that for any vertex $v: \Delta_i(v), \text{ab}_{f_i}(v), \text{ab}_{g_i}(v)$ are increasing in $i$. Thus, the run-time is bounded by
    \[O\left(\sum_{v \in V}\left((\text{ab}_{f_k}(v) + \text{ab}_{g_k}(v) + \Delta_k(v)) \cdot \sum_{i \leq k} (\ell_{i+1}(v) - \ell_i(v)) \right)\right) = O\left(h \cdot \sum_{v \in V}(\text{ab}_{f_k}(v) + \text{ab}_{g_k}(v) + \Delta_k(v))\right).\]
    Moreover, we remark that
    \[\sum_{v \in V}(\text{ab}_{f_k}(v) + \text{ab}_{g_k}(v)) = O\left(\sum_{v \in V} \Delta_k(v)\right).\]
    Hence, the run-time is bounded by $O(h \cdot \sum_{v \in V} \Delta_k(v)).$ We note that the total source capacity is bounded by
    \begin{align}
        \sum_{v \in V} \Delta_k(v) &= O\left(\frac{4}{\psi} \cdot \text{cong}(\Pi) \cdot (vol_G(P_k \cup Q_k) + |D|)\right) \\
        &= O\left(\frac{|D|}{\phi^2}\right),
    \end{align}
    which yields the bound on the run-time.
\end{proof}

\subsection{Dynamic Expander Decomposition}

\end{comment}

\section{The Push-Pull-Relabel Framework}
\label{sec:pushpullRelabel}

In the push-relabel framework as presented in \cite{goldberg1988new}, we are trying to compute a feasible flow for a flow problem $(G, \cc, \Delta, \nabla)$ by maintaining a pre-flow $\ff$ together with a level function $\bell$. The algorithm then runs in iterations terminating once $\ff$ has no positive excess at any vertex. In each iteration of the algorithm, the algorithm identifies a vertex $v$ that still has positive excess at a vertex $v$. This positive excess is then pushed to neighbors on lower levels such that the capacity constraint is still enforced. If this is not possible $v$ is relabeled meaning that its label $\bell(v)$ is increased. In this section, we are extending the push-relabel framework to the dynamic setting, where we allow for increasing the source function $\Delta$ and the deletion of edges from $G$. To do so, we need to introduce the notion of negative excess. Because for a flow $\ff$ of the flow problem, it might happen that once we delete an edge $(u,v)$ there is more flow leaving the vertex $v$ than is entering or sourced, i.e. $\Gamma_t(v) < 0$. Hence, we need to extend the discussion to include negative excess in the dynamic version. Similar to the standard push-relabel algorithm, we maintain a pseudo-flow $\ff$ and a vertex labeling $\bell$ in so-called valid states $(\ff, \bell)$. The only difference is that in the standard push-relabel algorithm, $\ff$ is a pre-flow (not only a pseudo-flow). 

\begin{definition}\label{def:state}
    Given a level function $\bell: V(G) \rightarrow [h]$ and a pseudo-flow $\ff$, we call a tuple $(\ff, \bell)$ a state for $(G, \cc, \Delta, \nabla)$ if for all edges $e = (u, v)$ having $\bell(u) > \bell(v) + 1$ implies $\ff(e) = \cc(e).$\\
    We call the state $(\ff, \bell)$ valid if for all vertices $v \in V(G):$ 1) $\Gamma(v) < \nabla(v)/2$ implies $\bell(v) = 0$, 2) $\nabla(v) < \Gamma(v)$ implies $\bell(v) = h.$
\end{definition}

For the remainder of the paper, we have $h = O\left(\frac{\log(n)}{\phi}\right)$. To provide the reader with some intuition about the definitions, we remark that the pseudo-flow of a valid state is not feasible in the usual sense. Indeed, some vertices might have positive or negative excess. But these vertices are guaranteed to either be at level $h$ or at level $0$. Moreover, we point out that if a valid state $(\ff, \bell)$ has no vertices at level $h$, then $\ff$ might still not be a feasible flow since there might be a vertex $v$ with $\Gamma_t(v) < 0$. But it is straightforward to obtain from $\ff$ a feasible flow: extract from $\ff$ at each vertex $v$ exactly $\Delta(v)$ unit flow paths (possibly empty paths starting and ending in $v$). Let us briefly outline how we will use \Cref{lm:PushPullRelabel} in the directed expander pruning algorithm \ref{alg:DirectedExpanderPruning}. In the directed expander pruning algorithm, we start with an out-expander and an adversary performs a number of vertex or edge deletions. We aim to find a small pruning set of vertices such that if we prune away this small pruning set from the remaining graph, then we can certify that the obtained graph is still an expander. The classical way (see \cite{saranurak2019expander}) to either certify expansion of the remaining graph or to find a pruning set is by setting up a flow problem, where we inject for any deletion some additional source flow and where each vertex has sink capacity equal to its degree (this is the reason for the condition $\nabla \geq \deg $ in \Cref{lm:PushPullRelabel}). We will solve this flow problem using the flow provided by our \textsc{ValidState} algorithm (see \Cref{alg:ValidState}). We maintain this flow problem using the interface functions \textsc{IncreaseSource}, \textsc{RemoveEdges} under both adversarial deletions and under necessary pruning deletions. If the valid state computed after any such update has an additional vertex on level $h$, this will indicate that more vertices need to be pruned away. If on the other hand all vertices are on levels strictly below $h$, we will certify that the remaining graph is an expander.

\begin{lemma}\label{lm:PushPullRelabel}
Given a flow problem $(G = (V,E), \cc, \Delta, \nabla)$, where $\nabla \geq \deg$. Then, there is a deterministic data structure $\textsc{ValidState}(G, \cc, \Delta, \nabla)$ (see \Cref{alg:ValidState}) that initially computes a valid state $(\ff, \bell)$ and after every update of the form
\begin{itemize}
    \item $\textsc{IncreaseSource}(\mathbf{\delta}):$ where $\mathbf{\delta} \in \mathbb{N}_{\geq 0}^{n}$, we set $\Delta$ to $\Delta + \mathbf{\delta}$,
    \item $\textsc{RemoveEdges}(D)$: where $D \subseteq E(V) \setminus \mathcal{D}$, sets $\mathcal{D}$ to $\mathcal{D} \cup D$ (initially $\mathcal{D} = \emptyset$),
\end{itemize}
the algorithm explicitly updates the tuple $(\ff, \bell)$ such that thereafter $(\ff, \bell)$ is a valid state for the current flow instance $(G \setminus \mathcal{D}, \cc|_{E \setminus \mathcal{D}}, \Delta|_{E \setminus \mathcal{D}}, \nabla|_{E \setminus \mathcal{D}})$. The run-time is $O\left(h \cdot \left(\|\Delta\|_1 + \sum_{d \in \mathcal{D}} (1 + |\ff_{t_d}(d)|)\right)\right)$, where $\ff_{t_d}(d)$ is equal to $\ff(d)$ at the time $d$ is deleted and $\Delta$ is the variable at the end of the algorithm.
\end{lemma}

The user interface of the data structure $\textsc{ValidState}$ are the functions $\textsc{Init}, \textsc{IncreaseSource}$ and $ \textsc{RemoveEdges}$. These functions can be used to initialize or update the flow problem. After any such update the internal state $(\ff,\bell)$ has to be updated to remain valid for the new flow problem. To facilitate these necessary updates to $(\ff,\bell)$ these functions make calls to the internal functions $\textsc{PushRelabel}$ and $ \textsc{PullRelabel}$. As described before, the function $\textsc{PushRelabel}$ performs push and relabel operations to handle any positive excess, while the function $\textsc{PullRelabel}$ performs pull and relabel operations to handle any negative excess. Let us take a closer look at the individual functions: using $\textsc{Init}$ we set up the flow problem. It makes an internal call to $\textsc{PushRelabel}$ to compute the first valid state using the standard push-relabel algorithm. Note that at this point no negative excess has been introduced and thus we do not need to resort to any pull operations. The function $\textsc{IncreaseSource}$ can be used to increase the source of the current flow problem and again this does not introduce any negative excess and hence we can again update the valid state using the standard push-relabel algorithm. Using the function $\textsc{RemoveEdges}$, we can restrict the flow problem to a subgraph. The function induces the capacities $\cc, \Delta, \nabla$ and the flow $\ff$ to the subgraph and then makes calls to both $\textsc{PushRelabel}$ and $\textsc{PullRelabel}$ to update the state. The function $\textsc{PushRelabel}$ is just the standard push-relabel algorithm. We look for a vertex $v$ with positive excess $\Gamma(v) > \nabla(v)$ at level below $h$. We pick a vertex on the lowest level possible. We try to push flow along some unsaturated outgoing edge to a vertex on a lower level. If it is not possible to push flow, we increase the label of the vertex and repeat. The function $\textsc{PullRelabel}$ is the analog of the push-relabel algorithm for negative excess. Here, we look for a vertex $v$ with negative excess $\Gamma(v) < \nabla(v)/2$ at level above $0$. We pick a vertex on the highest level possible. We try to pull flow along some unsaturated incoming edge from a vertex on a higher level. If it is not possible to pull flow then all edges $(u,v)$ where $\bell(u) > \bell(v)$ must be saturated and it is safe to decrease the label of the vertex and repeat. 



\begin{proof}\textcolor{red}{TOPROVE 3}\end{proof}
\begin{comment}
    
\begin{claim}\label{proof:LmPushPullRelabel-cl3}
    The contribution to the run-time of the pull operations is bounded by $O(h \cdot (p + n))$.
\end{claim}
\begin{proof}
    Let us introduce the function $\Phi(t) = \sum_{v \in V} \Delta^-_t(v) \cdot (h - \bell_t(v))$. We remark that any pull operation of $\psi$ units from $u$ to $v$ decreases $\Delta^-_t(v)$ by $\psi$ and increases $\Delta^-_t(u)$ by at most $\psi$ while preserving all other $\Delta^-_t$ entries. Hence, any such push operation decreases the function $\Phi$. This allows us to bound the run-time contribution of the push operations by
    \[\sum_{0 \leq t} \max(\Phi(t) - \Phi(t + 1), 0).\]
    Since $\Phi(t) \geq 0$ for all $t$, it suffices to bound the increases to $\Phi$. The same sequence of inequalities as in \eqref{eq:IneqSeq}, yields the bound
    \begin{align*}
        \sum_{0 \leq t} \max(\Phi(t+1) - \Phi(t), 0) &\leq h \cdot (p + n) + \sum_v \sum_{0 \leq t} \left(\Delta^-_{t+1}(v) - \deg(v)\right) \cdot |\bell_{t+1}(v) - \bell_{t}(v)|.
    \end{align*}
    To bound the remaining term with $h \cdot n$, we follow the same argument as in \Cref{proof:LmPushPullRelabel-cl2}.
\end{proof}
\end{comment}

\begin{comment}
    
\begin{algorithm}[H]
    \begin{algorithmic}
    \caption{$\textsc{PushRelabel}(G, \cc, \Delta, \nabla, h, \ff, \bell)$}\label{alg:PushRelabel}
    \While{$\exists v$ where $\bell(v)<h$ and $\Gamma(v) > \nabla(v)$}
        \State Let $v$ be a vertex minimizing $\bell(v)$.
        \If{$\exists (v, u)$ such that $\cc_f(v, u)>0, \bell(v)=\bell(u)+1$}
            \State $\psi=\min \left(\Delta^+_f(v), \cc_f(v, u), \max(\deg(u) - \Delta^+_f(u), 0) \right)$
            \State $\ff(v, u) \leftarrow \ff(v, u)+\psi, \ff(u, v) \leftarrow -\ff(v, u)$ // Sends $\psi$ units of positive excess from $v$ to $u$
        \Else
            \State $\bell(v) \leftarrow \bell(v) + 1$
        \EndIf
    \EndWhile
    \State \Return $(\ff, \bell)$
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
    \begin{algorithmic}
    \caption{$\textsc{PullRelabel}(G, \cc, \Delta, \nabla, h, \ff, \bell)$}\label{alg:PullRelabel}
    \While{$\exists v$ where $\bell(v) > 0$ and $\Gamma(v) < 0$ }
        \State Let $v$ be a vertex maximizing $\bell(v)$
        \If{$\exists (u, v)$ such that $\cc_f(u, v)>0, \bell(u)=\bell(v)+1$ }
        \State $\psi=\min \left(\Delta^-_f(v), \cc_f(u, v), \deg(u) \right)$ 
        \State $\ff(v, u) \leftarrow \ff(v, u)+\psi, \ff(u, v) \leftarrow - \ff(v, u)$ // Sends $\psi$ units of negative excess from $v$ to $u$
        \Else
            \State $\bell(v) \leftarrow \bell(v) - 1$
        \EndIf
    \EndWhile
    \State \Return $(\ff, \bell)$
\end{algorithmic}
\end{algorithm}
\end{comment}

\begin{comment}
\begin{proof}
\mprobst{This proof could greatly benefit from using bullet points when analyzing each operation (currently called action but I would re-consider that naming). }

We remark that the run time of the PushPullRelabel algorithm is determined by the number of pushes, pulls, and relabels. In particular, each push and each pull contributes one flop\mprobst{I don't quite understand. What is a flop? https://www.merriam-webster.com/dictionary/flop this doesn't give me an answer. Maybe skip this entire first paragraph} while each relabelling of a vertex $v$ contributes $\deg(v)$ flops, since before we can relabel the vertex $v$ we must have verified that we cannot push/pull along an outgoing/incoming. We note at this point that if we cannot push/pull along an edge, we cannot do so in the future until we have relabeled the vertex.\\
Maintaining at each vertex $v \in V$, a linked-list $L[v]$ containing all non-saturated edges $(v,u)$ where $l(v) = l(u) + 1$, we can implement a push in time $O(1)$. We can maintain such a linked-list for every vertex by spending time $O(\deg(v))$ every time we re-label a vertex plus $O(1)$ time for each push and pull. We maintain a corresponding list $L'[v]$ for all pull operations.

Using linked lists of edges that are saturated/non-saturated at each vertex, we can implement each push/pull in time $O(1)$.
\\
It thus remains to bound the contribution of the pushes, pulls, and relabellings. Let us enumerate the pushes, pulls, relabellings as they occur and index them by $t$. Moreover, we introduce the following potential function \mprobst{Why does $\ell$ not have a $t$ subscript? Wouldn't it be better to just define $\Phi$ without $t$ and then denote by $\Phi^{(t)}$ the potential value after the $t$-th operation.}
 \[\Phi(t) = \sum_v \Delta_t^+(v) \cdot \ell(v)  + \sum_v \Delta_t^-(v) \cdot \left(h - \ell(v)\right) + \sum_{p \in \Delta_t^+} (2h - c_t(p)) \] 
 \mprobst{To me both are unclear: $p \in \Delta_t^+$, I don't recall that to be a set.. it is a function, and what is $c_t$ and especially $c_t(p)$?}
 \mprobst{If I am interpreting correctly, then it should be $ 2(h - c_t(p))$}
In the following, we will verify that each push, pull\mprobst{push/pull?} reduces the potential function by one and every relabelling of a vertex $v$ reduces it by $\deg(v)$. For easing the presentation of the argument, let us call units of $\Delta^+_0$ protons and units of $\Delta^-_0$ electrons. Each vertex $v$ can absorb $\deg(v)$ protons. If a proton (even it has been previously absorbed at the vertex) and an electron are present at the same vertex, then they form a neutron. In a push from $u$ to $v$, we are moving $\psi$ protons from $u$ to $v$. In a pull from $u$ to $v$ we are moving $\psi$ electrons from $v$ to $u$. We remark that a proton can be absorbed at most at one vertex and be part of at most one neutron.
\mprobst{My subjective opinion is that this analogy does not help the reader. I understand that you like to think about it that way but I personally don't benefit from that perspective. I would explain everything in formal terms and then offer in two sentences the analogy with electrons and protons if you really feel it is what you want to write.}
\\
\\
Assume that the $t$-th action is a push of $\psi$ units from $u$ to $v$, then we set $c_{t} = c_{t-1}$. Since we are considering an integer flow problem we have that $\psi \geq 1$. Moreover, since we are pushing from $u$ to $v$, we must have that $\ell(u) > \ell(v)$. Pushing $\psi$ units from $u$ to $v$ reduces $\Delta_{t-1}^+(u)$ by $\psi$ units\mprobst{This doesn't make so much sense with the time index fixed. Just omit then the sentence makes more sense?} while increasing $\Delta_{t-1}^+(v)$ by at most $\psi$ units or possibly decreasing $\Delta_{t-1}^-(v)$ by at most $\psi$ units. All other $\Delta$ terms are again preserved. Hence the potential function $\Phi$ decreases from $t$ to $t+1$ by at least one unit.\mprobst{$t-1$ to $t$?}\\
\\
Assume that the $t$-th action is a pull of $\psi$ units from $u$ to $v$, then we set $c_{t} = c_{t-1}$. Again we may assume that $\psi \geq 1$. Moreover, since we are pull from $u$ to $v$, we must have that $\ell(u) > \ell(v)$. Pulling $\psi$ units from $u$ to $v$ reduces $\Delta_{t-1}^-(v)$ by $\psi$ units while increasing $\Delta_{t-1}^-(v)$ by at most $\psi$ units or possibly decreasing $\Delta_{t-1}^+(v)$ by at most $\psi$ units. All other $\Delta$ terms are again preserved. Hence the potential function $\Phi$ decreases from $t$ to $t+1$ by at least one unit.\\
\\
Assume that the $t$-th action is a push-relabelling of $v$, then at least $\deg(v)$ protons must be currently absorbed at $v$\mprobst{push-relabelling is not defined.}. We increase for $\deg(v)$ protons $p$ absorbed at vertex $v$ the value of $c_{t+1}(p)$ by one. Hence, we have that the potential function decreases by at least $\deg(v)$.\mprobst{Argument is off, you might have $\Delta^+(v)$ have multiple elements, not you are increasing the level, the first term of the potential increases which might easily cancel what you have. You need to do some more mathy calculations here to not construct a proof that is not true.}\mprobst{time index off by one}\\
\\
\mprobst{The two paragraphs below don't convince me as a proof. Maybe just because I don't know what $c_t$ is but sth is off in how you analyze it.}
Assume that the $t$-th action is a pull-relabelling of $v$, then we must have at least $\deg(v)$ neutrons at vertex $v$. Consider the protons that are part of the last $\deg(v)$ neutrons that were formed at vertex $v$. Increase their value $c_{t-1}(p)$ by one. Hence, we have that the potential function decreases by at least $\deg(v)$.\\
\\
It remains to argue that for any proton, we have that $c_{t} \leq 2\cdot h$. Let us focus on the protons that are absorbed or are part of a neutron at a specific vertex $v$. Let us consider the level of $v$ as a function $\ell_{t}(v)$ with the index of the action as function argument. We observe that if at the $t$-th action the level of $v$ increases, i.e. $\ell_{t}(v) - \ell_{t-1}(v) = 1$, then at least $\deg(v)$ protons must currently be absorbed while if at the $t$-th action the level of $v$ decreasing no protons are currently absorbed. This implies that whenever a $\ell_{t}(v)$ changes from increasing to decreasing all (at least $\deg(v)$) absorbed protons form neutrons. Hence, while a proton is absorbed at a vertex $v$ the level of $v$ can only increase. This in turn implies that we charge at most $h$ units to a proton while it is absorbed. On the other hand, we remark that whenever $\ell_{t}(v)$ changes from increasing to decreasing at least $\deg(v)$ new neutrons are formed at $v$. Since we are always charging to the protons in the $\deg(v)$ newest neutrons. This in turn implies that while we are charging a proton contained in a neutron the level of $v$ can only decrease. Hence, we charge a proton at most $h$ while it is contained in a neutron.\\
\\
This established that the potential function remains non-negative over all actions. Hence, we can bound the run time by $\Phi(0) = O(h \cdot \sum_{v} \Delta^+(v) + \Delta^-(v))$. \mprobst{This sentence is just not true if the initial flow is non-zero. Even then it swallows the amount of flow placed that is absorbed.}
\end{proof}

\end{comment}

\section{Directed Expander Decompositions via the Push-Pull-Relabel Framework}
\label{sec:dirExpanderDecomp}

In this section, we discuss our main technical result that states that if $G$ is initially a $\phi$-expander, then an expander decomposition can be maintained efficiently. The algorithm behind this theorem heavily relies on the new push-pull-relabel algorithm presented in the previous section.

\begin{theorem}\label{thm:ExpanderPruning} Given a $\phi$-expander $G = (V, E)$ with $(\phi,\psi)$-witness $(W, \Pi)$, there is a deterministic data structure $\textsc{BidirectedExpanderPruning}(G, W, \Pi)$ (see \Cref{alg:BiDirectedExpanderPruning}). After every update of the form
\begin{itemize}
    \item $\textsc{RemoveEdges}(D)$: where $D \subseteq E$, sets $\mathcal{D}$ to $\mathcal{D} \cup D$ (initially $\mathcal{D} = \emptyset$),
\end{itemize}
the algorithm explicitly updates $\tilde{V} \subseteq V$ and the tuple $(E^r, \mathcal{P})$, where $E^r \subseteq E(G)$ and $\mathcal{P}$ is a partition of $V \setminus \tilde{V}$ (initially $E^r , \mathcal{P} = \emptyset$), such that both $E^r$ and $\mathcal{P}$ are non-decreasing and such that after the update 
\begin{enumerate}
    \item \label{itm:DEP-thm1} the graph $\tilde{G} = \left(G \setminus \mathcal{D}\right)\left[\tilde{V} \right]$ has a $\left(\frac{\phi \cdot \psi^6}{32000}, \frac{\psi^4}{800}\right)$-witness $(\tilde{W}, \Pi)$,
    \item \label{itm:DEP-thm2} $|E^r| \leq \frac{\phi}{4} \cdot \sum_{P \in \mathcal{P}} \operatorname{vol}_{G}(P)$
    \item \label{itm:DEP-thm3} $\sum_{P \in \mathcal{P}} \operatorname{vol}_{W}(P) \leq \frac{8}{\psi} \cdot |\Pi^{-1}(\mathcal{D})|$
    \item \label{itm:DEP-thm4} $(G \setminus (\mathcal{D} \cup E^r))/ (\mathcal{P} \cup \{\tilde{V}\})$ is a directed acyclic graph (DAG),
\end{enumerate}
provided $\frac{200}{\psi^2} \cdot |\Pi^{-1}(\mathcal{D})| < e(G)$. The run-time is $O\left(\frac{h}{\psi^2} \cdot |\Pi^{-1}(\mathcal{D})| + h \cdot \sum_{d \in \mathcal{D} \cup E_{\mathcal{P}}} (1 + |\ff_{t_d}(d)|) \right) = O\left(h \cdot \frac{|\mathcal{D}|}{\psi^2 \phi} \right)$, where $\mathcal{D}$ denotes the variable at the end of all updates and $E_{\mathcal{P}}$ denotes all intercluster edges of the partition $\mathcal{P} \cup \{\tilde{V}\}$.
\end{theorem}

Following the high-level approach of \cite{saranurak2019expander}, we obtain our main result \Cref{Main-thm} for the special case where $G$ is static by running a generalization of the cut-matching game to directed graphs \cite{khandekar2009graph, louis2010cut} and then apply \Cref{thm:ExpanderPruning} to handle unbalanced cuts. Combining this result again with \Cref{thm:ExpanderPruning}, we obtain our main result \Cref{Main-thm} in full generality. Both of these reductions have been known from previous work \cite{bernstein2020deterministic, hua2023maintaining}. We defer the former reduction to \Cref{subsec:staticExpDecom} and the latter to \Cref{subsec:dynExpanderDecomposition}. 

\subsection{Reduction to Out-Expanders}

In this subsection, we show that the task of maintaining an expander decomposition as described in \Cref{thm:ExpanderPruning} can be reduced to a simpler problem that only requires maintaining out-expanders (however under edge and vertex deletions). In particular, we reduce to the following statement whose proof is deferred to \Cref{subsec:outExpan}.

\begin{lemma}\label{lm:DirectedExpanderDecomp}For every $\phi$-out-expander $G = (V, E)$ with $(\phi,\psi)$-witness $(W, \Pi)$, there is a deterministic data structure $\textsc{DirectedExpanderPruning}(G, W, \Pi)$ (see \Cref{alg:DirectedExpanderPruning}). After every update of the form (initially $\tilde{V} = V, \mathcal{S} = \emptyset, E_{\mathcal{S}} = \emptyset, E_{\mathcal{S}}^+ = \emptyset, E_{\mathcal{S}}^- = \emptyset, \mathcal{D} = \emptyset$)
\begin{itemize}
    \item $\textsc{RemoveEdges}(D)$: where $D \subseteq E(\tilde{V}) \setminus \mathcal{D}$, sets $\mathcal{D}$ to $\mathcal{D} \cup D$,
    \item $\textsc{RemoveVertices}(S)$: where $S \subseteq \tilde{V}$, sets $\tilde{V}$ to $\tilde{V} \setminus S$, $\mathcal{S}$ to $\mathcal{S} \cup S$, $E_{\mathcal{S}}^+$ to $E_{\mathcal{S}}^+ \cup E_G(S, \tilde{V} \setminus S), E_{\mathcal{S}}^-$ to $E_{\mathcal{S}}^- \cup E_G(\tilde{V} \setminus S, S)$ and $E_{\mathcal{S}}$ to $E_{\mathcal{S}}^+ \cup E_{\mathcal{S}}^-$
\end{itemize}
the algorithm explicitly updates $\tilde{V} \subseteq V$ and the tuple $(E^r, \mathcal{P})$, where $E^r \subseteq E$ and $\mathcal{P}$ is a partition of $V \setminus \left(\mathcal{S} \cup \tilde{V}\right)$ (initially $E^r = \emptyset, \mathcal{P} = \emptyset$), such that both $E^r$ and $\mathcal{P}$ are non-decreasing and such that after the update 
\begin{enumerate}
    \item \label{itm:DEP-lm1} the graph $\left(G \setminus \mathcal{D}\right)\left[\tilde{V}\right]$ has a $\left(\frac{\phi \cdot \psi^4}{400}, \frac{\psi^2}{20}\right)$-out-witness $(\tilde{W}, \tilde{\Pi})$,
    \item \label{itm:DEP-lm2} $|E^r| \leq \frac{\phi}{4} \cdot \sum_{P \in \mathcal{P}} \operatorname{vol}_G(P),$
    \item \label{itm:DEP-lm3} $\sum_{P \in \mathcal{P}} \operatorname{vol}_W(P) \leq \frac{4}{3 \psi} \cdot \left|\Pi^{-1}(\mathcal{D} \cup E^-_{\mathcal{S}}) \right|, $
    \item \label{itm:DEP-lm4} $E^r = \bigcup_{P} E_{G \setminus (\mathcal{D} \cup E^-_{\mathcal{S}})}(P,V_P)$, where $V_P$ is equal to $\tilde{V}$ at the time $P$ is added to $\mathcal{P}$,
\end{enumerate}
provided $\frac{20}{\psi} \cdot  |\Pi^{-1}(\mathcal{D} \cup E_{\mathcal{S}} \cup E_{\mathcal{P}})| < e(G)$, where $\mathcal{D}$ denotes the variable at the end of all updates and $E_{\mathcal{P}}$ denotes all intercluster edges of the partition $\mathcal{P} \cup \{\tilde{V}\}$. The algorithm runs in total time $O\left(\frac{h \cdot |\Pi^{-1}(\mathcal{D} \cup E_{\mathcal{S}} \cup E_{\mathcal{P}})|}{\psi^2} + h \cdot \sum_{d \in \mathcal{D} \cup E_{\mathcal{S}} \cup E_{\mathcal{P}}} (1 + |\ff_{t_d}(d)|)\right)$.
\end{lemma}

We present $\textsc{BiDirectedExpanderPruning}$ (see Algorithm \ref{alg:BiDirectedExpanderPruning}), which implements this reduction. The $\textsc{Init}$ function initializes two out-expander pruning data structure. One for the graph $G$ with witness $(W, \Pi)$ with variables $\tilde{V}_1, \mathcal{P}_1, E^r_1$ and one for the graph $G^{rev}$ with witness $(W, \Pi)$ with variables $\tilde{V}_2, \mathcal{P}_2, E^r_2$. From the guarantees of the one directional \textsc{DirectedExpanderPruning} algorithm, we will have that after each update $G[\tilde{V}_1]$ and $G^{rev}[\tilde{V}_2]$ are out-expanders. To conclude that the $G[\tilde{V}]$ is in fact an expander in both directions, we will ensure using the function \textsc{AdjustPartition} that $\tilde{V}_1, \tilde{V}_2$ agree. If they do not agree, we will remove the vertices $\tilde{V}_1 \setminus \tilde{V}_2 $ from $\tilde{V}_1$ using the function \textsc{RemoveVertices} of the algorithm \textsc{DirectedExpanderPruning} (see \Cref{alg:DirectedExpanderPruning}). Using the function \textsc{RemoveEdges} of \textsc{BiDirectedExpanderPruning}, we can remove edges from $G[\tilde{V}]$. This is again accomplish by calling the analogous function \textsc{RemoveEdges} of \textsc{DirectedExpanderPruning} for both directions. Again we have to adjust the partition such that $\tilde{V}_1, \tilde{V}_2$ agree afterwards. The algorithm and the proof are defered to \Cref{subsec:Reduction-to-Out-Expanders}.

\begin{comment}

\mprobst{Cleaner statement Proposal}

\begin{theorem}[Expander Pruning]\label{thm:ExpanderPruning} Let $G=(V, E)$ be a $\phi$-expander with $m$ edges and $\psi$-witness $(W, \Pi)$ and $G$ be undergoing up to $\phi \psi m$ edge deletions. The algorithm processes edge deletions and outputs vertex sets $P_1, P_2, \ldots, $ such that 
\begin{enumerate}
    \item after the algorithm terminates processing the $t$-th edge deletion to $G$ where $P_1, P_2, \ldots, P_k$ are the sets outputted by the algorithm so far, we have that $(G\setminus D)[V \setminus (\cup_{i \leq t} P_t]$ is a $\frac{1}{\phi\psi}$-expander where $D$ is the set of the first $t$ edges deleted from $G$, and
    \item the sets $P_1, P_2, \ldots$ are pairwise vertex-disjoint, and
    \item for any $k$, $\bar{P_k} = V \setminus (P_1 \cup P_2 \cup \ldots \cup P_{k-1})$, we have 
$\min\{ e_{G \setminus D}( P_k , \bar{P_k}), e_{G \setminus D}(\bar{P_k}, P_k)\} \leq \frac{\phi}{2} \cdot \vol_G(P_k)$.
\end{enumerate}
The algorithm processes the first $t$ of up to $\phi \psi m$ edge deletions to $G$ in total runtime $O\left(t \log m / \phi^2 \right)$ and outputs all vertex sets $P_k$ explicitly.
\end{theorem}

\mprobst{To me it would be fine to give a direct proof where you just say in words what is happening. I.e.: Given a graph $H$, we let $H^{rev}$ be the graph $H$ with edges reversed, same for embedding $\Pi$ (move to prelims). We then compute a witness that $G$ is $\phi$-expander $(W, \Pi)$ and invoke the algorithm from \Cref{lm:PruneOrCertify} on $(G, W, \Pi)$ and on $(G^{rev}, W^{rev}, \Pi^{rev})$ respectively. We let $P^{out}$ be the set of vertices pruned from $G$. We let $P^{in}$ be the set of vertices pruned from $G^{rev}$. We let $P = P^{out} \cup P^{in}$. Whenever either of the data structures on $G$ or $G^{rev}$ outputs a set of vertices $S$ that is non-empty, we add the set to $P^{out}$ or $P^{in}$ respectively which implicitly updates the set $P$. 

After the $t$-th update to $G$, we forward the edge deletion to each data structure on $G$ and $G^{rev}$. Then, whenever a new vertex is added to $P$ by either of the data structures, we simulate a deletion of each edge incident to such vertex in both data structures. Once $P^{out} = P^{in} = P$, we terminate processing the $t$-th update to $G$. We output the set $P_t$ that consists of all vertices added to $P$ during the processing of the $t$-th update to $G$.

I think this would be much clearer than the rather intricate notation you introduced. You need the lemma below to bound recourse + update time. I would double-check whether it is really true with the update time the way that lemma 2.5 is written. Let $\bar{P}^{out}$ be the set of vertices in $P$ that were added to $P^{out}$ before they were added to $P^{in}$. Define $\bar{P}^{in}$ analogously. Then argue both sets are $\phi/2$-sparse so neither can be large but $P$ is just the union of these two sets, so volume of P is small.}



\mprobst{This lemma is misplaced. I moved it here.}
\begin{lemma} \label{lm:helper}
    Given a $\phi$-expander $G$ \mprobst{$G=(V,E)$ then take $S \subseteq V$} and a set of \mprobst{edge} deletions $D$. Then for any sparse cut in $G' = G \setminus D$, we have $\forall S \subseteq V(G'):$
    \[\min\{ e_{G'}(S, V(G) \setminus S), e_{G'}(S, V(G) \setminus S)\}  < \frac{\phi}{2} \cdot \text{vol}_G(S) \longrightarrow vol_G(S) < \frac{2\cdot |D|}{\phi}\]
\end{lemma}


\mprobst{The below statement makes things a bit complicated, I feel. Like this should be a bit more straight-forward...}
\begin{theorem}[Expander Pruning]\label{thm:ExpanderPruning} Let $G=(V, E)$ be a $\phi$-expander with $m$ edges and $\psi$-witness $(W, \Pi)$. Given a set of deletions $\mathcal{D} = \left(d_i\right)_{1 \leq i \leq D}$, algorithm $\operatorname{ExpanderPruning}$ computes two sequences $\mathcal{P} = \left(P_i\right)_i, \mathcal{Q} = \left(Q_i\right)_i$ of sets such that 

\begin{enumerate}
    \item $\forall i > 0: e_{G \setminus D}\left(P_i, V_{i, i-1} \right) \leq \frac{5 \cdot \phi}{\psi^2} \cdot \operatorname{vol}(P_i) $
    \item $\forall i > 0: e_{G \setminus D}\left(V_{i,i}, Q_i\right) \leq \frac{5 \cdot \phi}{\psi^2} \cdot \operatorname{vol}(Q_i) $
    \item $\sum_{i} \operatorname{vol}(P_i) + \operatorname{vol}(Q_i) \leq O\left(\frac{|D|}{\phi}\right)$
    \item $(G \setminus D)\left[V \setminus \bigcup_i \left(P_i \cup Q_i\right)\right]$ is a $\frac{\phi}{8}$-expander
\end{enumerate}
where $V_{k,l} = V \setminus \left( \bigcup_{j \leq k} P_j \cup \bigcup_{j \leq l} Q_j \right).$ The total run time is $O\left(|D| \log m / \phi^2 \right)$.
\end{theorem}


\begin{algorithm}[H]
\caption{Expander Pruning}\label{alg:Expander Pruning}
\begin{algorithmic}
\State Let $f, g$ be the zero flow and $\ell, h$ the trivial level set, $\tilde{V} = V(G)$ and initialize $\mathcal{P}, \mathcal{Q}$
\For{ $1 \leq i \leq D$}
    \State $\left(\tilde{V}, (f, \ell), (g, h), \left(P_i\right)_i, \left(Q_i\right)_i\right) \leftarrow \operatorname{ExpanderPruningStep}(G[\tilde{V}], (d_j)_{1 \leq j \leq i}, (f, \ell), (g, h) )$ \mprobst{Appeal to some theorem? Is this the cut-matching game?}
    \State Append $\left(P_i\right)_i$ to $\mathcal{P}$ and $\left(Q_i\right)_i$ to $\mathcal{Q}$
\EndFor
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{ExpanderPruningStep($G, D, (f, \ell), (g, h))$}\label{alg:Expander Pruning}
\begin{algorithmic}
\State Let $(f_0, \ell_0) = (f, \ell), (g_0, h_0) = (g, h)$ 
\State $i \leftarrow 0$
\Repeat 
\State $i \leftarrow i + 1$
\State $(P_i, (f_i, \ell_i)) \leftarrow \text{PruneOrCertify}(G, D, \tilde{V} = V_{i-1,i-1}, (f_{i-1}|_{\tilde{V}}, \ell_{i-1}|_{\tilde{V}}))$
\State $(Q_i, (g_i, h_i)) \leftarrow 
\text{PruneOrCertify}(G^{rev}, D^{rev}, \tilde{V} = V_{i,i-1}, (g_{i-1}|_{\tilde{V}}, h_{i-1}|_{\tilde{V}}))$
\Until{$P_i, Q_i = \emptyset$}
\State return $V_{\infty, \infty}, (f_{\infty}|_{V_{\infty,\infty}}, \ell_{\infty}|_{V_{\infty,\infty}}), (g_{\infty}|_{V_{\infty,\infty}}, h_{\infty}|_{V_{\infty,\infty}}), \left(P_i\right)_i, \left(Q_i\right)_i$
\end{algorithmic}
\end{algorithm}
    


\begin{proof}
    We remark that the first, the second, and the fourth item follow immediately from Lemma \ref{lm:PruneOrCertify}. Let us first discuss the third item.\\
    \\
    We observe that we can bound the edges between $\left(P_i\right)_i, \left(Q_i\right)_i$ as follows \mprobst{First inequality needs to be argued for, I don't quite understand...}
    \begin{align}\label{eq3}
        e \left(\bigcup_i P_i, \bigcup_i Q_i \right) &\leq \sum_{i} e\left(P_i, \bigcup_{i \leq j} Q_j\right) + e\left(\bigcup_{i+1 \leq j} P_j, Q_i\right) \\
        &\leq \sum_{i} \phi \cdot \text{vol}(P_i) + \phi \cdot \text{vol}(Q_i)
    \end{align}
    W.l.o.g. we may assume that $\sum_i \text{vol}(Q_i) \leq \sum_i \text{vol}(P_i)$. Then, equation \eqref{eq3} together with item one, implies that
    \[e\left(\bigcup_i P_i, V_{\infty,-1} \right) \leq 3 \cdot \phi \cdot \text{vol}\left(\bigcup_i P_i\right).\]
    Thus, according to Lemma \ref{lm:helper} we find that $\text{vol}\left(\bigcup_i P_i\right) \leq O \left(\frac{|D|}{\phi} \right)$. This establishes item 3 since $\sum_i \text{vol}(Q_i) \leq \sum_i \text{vol}(P_i)$. It remains to discuss the run time. From the run time of $\operatorname{PruneOrCertify}$, it follows readily that the run time of $\operatorname{ExpanderPruning}$ is bounded by 
    \[h \cdot \left( \sum_{i} \left(\Delta^+_{f_i|_{\tilde{V}}}(V_{i,i}) + \Delta^-_{f_{i}|_{\tilde{V}}}(V_{i,i})\right) + \sum_{i} \left(\Delta^+_{g_i|_{\tilde{V}}}(V_{i+1,i}) + \Delta^-_{g_{i}|_{\tilde{V}}}(V_{i+1,i})\right) \right).\]
    It thus suffices to relate $\Delta^+_{f_i|_{\tilde{V}}}, \Delta^+_{g_i|_{\tilde{V}}}$ to $\text{vol}(P_i), \text{vol}(Q_i).$
    \\
    \\
    \textbf{Claim:} 
    \begin{align*}
        \Delta^+_{f_i|_{\tilde{V}}}(V_{i,i}) & \leq \text{vol}(P_i) + \text{vol}(Q_i) \\
        \Delta^-_{f_i|_{\tilde{V}}}(V_{i,i}) & \leq \text{vol}(P_i) + \text{vol}(Q_i)
    \end{align*} 
    \begin{proof}
        We remark that for any vertex $v$ in $V_{i,i}$ we have $\ell_{i-1}(v) < h$ and thus $\Delta^+_{f_{i}}(v) = 0$. Therefore, 
        \[\Delta^+_{f_i|_{\tilde{V}}}(v) \leq \sum_{e \in E(v, P_i)} f(e) + \sum_{e \in E(v, Q_i)} f(e) + \frac{4}{\psi} \cdot |\{e \in E(W) \mid \exists u \in P_i \cup Q_i: e = (v,u)\}| .\]
        Summing over all vertices in $V_{i,i}$ we obtain
        \[\Delta^+_{f_i|_{\tilde{V}}}(V_{i,i}) \leq \sum_{e \in E(V_{i,i}, P_i)} f(e) + \sum_{e \in E(V_{i,i}, Q_i)} f(e) + \frac{4}{\psi} \operatorname{vol}_W(P_i \cup Q_i)\]
        Since $e(V_{i,i}, Q_i) \leq \frac{5 \cdot \phi}{\psi^2} \operatorname{vol}(Q_i)$ we can bound the second term by $\frac{5}{\psi^2} \operatorname{vol}(Q_i)$. Moreover, any flow flowing into $P_i$ either has to flow out again or is stuck at some vertex. But the amount of flow stuck at some vertex can be at most $O(\deg(v))$. Hence, we can bound the second term by $O(\frac{5}{\psi^2} \operatorname{vol}(P_i))$ as well. These two facts together yield the bound on $\Delta^+_{f_i|_{\tilde{V}}}(V_{i,i})$ of the claim. Following a similar line of argument, we can also establish that 
        \[\Delta^-_{f_i|_{\tilde{V}}}(v) \leq \sum_{e \in E(P_i, v)} f(e) + \sum_{e \in E(Q_i, v)} f(e)\]
        and obtain from it the bound on $\Delta^+_{f_i|_{\tilde{V}}}(V_{i,i})$ of the claim.
    \end{proof}
    It is clear that the same argument yields that 
    \begin{align}
        \Delta^+_{g_i|_{\tilde{V}}}(V_{i+1,i}) & \leq \text{vol}(P_{i+1}) + \text{vol}(Q_i) \\
        \Delta^-_{g_i|_{\tilde{V}}}(V_{i+1,i}) & \leq \text{vol}(P_{i+1}) + \text{vol}(Q_i)
    \end{align}
    and thus we may bound the run time by 
    \[O\left(h \cdot \sum_{i} (\text{vol}(P_i) + \text{vol}(Q_i)) \right) \leq O\left(|D|\log(m)/\phi^2\right) \]
\end{proof}

\end{comment}

\bibliographystyle{alpha}
\bibliography{refs}

\newpage

\appendix 
\section{Appendix}


\subsection{Previous Work}
\label{subsec:prevWork}

\paragraph{Expander Decompositions for Static Flow Problems.} In static graph settings, expander decompositions have been employed in many recent algorithms for electrical, maximum flow and min-cost flow problems. As mentioned, they were instrumental in the first Laplacian solver \cite{spielman2004nearly} that computes electrical flows, and still are used in recent Laplacian solvers, for example in the recent first almost-linear deterministic Laplacian solver for directed graphs \cite{kyng2022derandomizing}.\\
For the maximum and min-cost flow problems, expander decompositions have been crucial, as seen in \cite{kelner2014almost,van2020bipartite,van2021minimum,bernstein2022deterministic} and the recent development of an almost-linear time algorithm for max flow and min-cost flow in directed graphs \cite{chen2022maximum}. In \cite{chen2022maximum}, the static min-cost flow problem in a directed graph is transformed via advanced convex optimization methods into a dynamic problem in an undirected graph. This dynamic problem is then solved efficiently by a data structure that uses the undirected expander decomposition algorithm from \cite{saranurak2019expander} internally. By simple reductions, the result in \cite{chen2022maximum} also gave the first almost-linear time algorithms for the problems of negative Single Source Shortest Path (SSSP) and bipartite matching, but also to compute expanders in directed graphs. \\
Since the breakthrough result in \cite{chen2022maximum} (and follow-up work \cite{van2023deterministic, kyng2023dynamic, chen2023almost}), a natural new research initiative has emerged: can we solve the min-cost flow problem without relying on advanced convex optimization methods, or put differently, can it be solved with purely \emph{combinatorial} methods? This question aims to further our understanding of the min-cost flow problem by developing a radically different (possibly more accessible) perspective but is also motivated by the quest to find a simpler and more practical algorithm. This initiative has already led to significant achievements, including a near-linear time algorithm for Negative SSSP \cite{bernstein2022negative} and a purely combinatorial approach to bipartite matching \cite{chuzhoy2024faster} that improves current combinatorial approaches in dense graphs, a barrier that stood since the 80s. \\
Directed expander decomposition has emerged as a critical tool in this landscape, exemplified by the work of \cite{bernstein2022negative}, who utilized directed low-diameter decompositions akin to directed expander decompositions, and \cite{chuzhoy2024faster}, who directly applied directed expander decompositions.
The aim of our new accessible directed expander decomposition framework is to further accelerate this essential research initiative, contributing significantly to the field of graph algorithms.

\paragraph{Expander Decompositions for Graph Problems beyond Flows.} In undirected graphs, expander decompositions have also been crucial in all deterministic almost-linear time global min-cut algorithms for undirected graphs \cite{kawarabayashi2018deterministic,saranurak2021simple,li2021deterministic} in computing short-cycle decompositions \cite{chu2020graph,parter2019optimal,liu2019short}, and in finding min-cut preserving vertex sparsifiers \cite{chalermsook2021vertex,liu2020vertex}.\\
It is noteworthy that the above achievements pertain exclusively to undirected graphs. Directed graphs have yet to benefit from the application of expander decompositions.
In the directed setting only considerably less efficient algorithms are known. We hope that our directed expander decomposition framework will facilitate adapting the existing methodologies used in undirected graphs to the directed context, or will inspire novel strategies to address these algorithmic challenges.


\paragraph{Expander Decompositions in Dynamic Graphs.} 
In dynamic graphs, which are characterized by ongoing edge insertions and deletions, expanders have played a significant role in the undirected setting. They have been fundamental in achieving new worst-case update time and derandomization results in dynamic connectivity \cite{wulff2017fully,nanongkai2017dynamic,nanongkai2017dynamicMinimum,chuzhoy2020deterministic}, in single-source shortest paths \cite{chuzhoy2019new,bernstein2020deterministic,chuzhoy2021deterministic,chuzhoy2021decremental,bernstein2022deterministic}, in approximate $(s, t)$-max-flow and $(s,t)$-min-cut algorithms \cite{goranci2021expander}, and in developing sparsifiers resistant to adaptive adversaries \cite{bernstein2020fully, chen2022maximum}. Notably, they were also a key component in the first subpolynomial update time c-edge connectivity algorithm \cite{jin2022fully} and bounded-value min-cut algorithm \cite{jin2024fully}.\\
In the context of directed graphs, there remains a significant gap in our understanding. A notable challenge is the absence of near-linear time solutions for many problems, such as decremental Single-Source Shortest Paths (SSSP). Where solutions do exist, such as for decremental Strongly Connected Components (SCC), they are typically effective only against oblivious adversaries, as highlighted in \cite{bernstein2019decremental}. Furthermore, in scenarios where algorithms are devised to tackle adaptive adversaries, the trade-off is often a drastic reduction in speed, a fact exemplified in \cite{bernstein2020deterministic}. However, the use of directed expander decompositions in these algorithms suggests that enhancing these decompositions could be key to developing faster and more robust algorithms for directed dynamic graphs.
 
\subsection{Push-Pull-Relabel Algorithm}
\label{subsec:Push-Pull-Relabel-Algorithm}

\begin{algorithm}[H]
    \begin{algorithmic}
    \caption{$\textsc{ValidState}(G = (V,E), \cc, \Delta, \nabla, h)$}\label{alg:ValidState}
    \State def $\textsc{Init}$
    \Indent
    \State $\tilde{E} \leftarrow E(G), (\cc,\Delta,\nabla) \leftarrow (\cc,\Delta,\nabla), (\ff, \bell) \leftarrow (\veczero,\veczero)$
    \State $\textsc{PushRelabel}()$
    \EndIndent
    \State 
    \State def $\textsc{IncreaseSource}(\delta)$
    \Indent
    \State $\Delta \leftarrow \Delta + \delta$
    \State $\textsc{PushRelabel}()$
    \EndIndent
    \State 
    \State def $\textsc{RemoveEdges}(D)$
    \Indent
    \State $\tilde{E} \leftarrow \tilde{E} \setminus D, (\ff, \bell) \leftarrow (\ff|_{\tilde{E}},\bell|_{\tilde{V}})$
    \State $\textsc{PullRelabel}()$
    \State $\textsc{PushRelabel}()$
    \EndIndent
    \State
    \State def $\textsc{PushRelabel}()$
    \Indent
    \While{$\exists v$ where $\bell(v)<h$ and $\Gamma(v) > \nabla(v)$}
        \State Let $v$ be a vertex minimizing $\bell(v)$.
        \If{$\exists (v, u)$ such that $\cc_f(v, u)>0, \bell(v)=\bell(u)+1$}
\State $\ff(v, u) \leftarrow \ff(v, u) + \frac{1}{2}, \ff(u, v) \leftarrow -\ff(v, u)$ // Sends $\frac{1}{2}$ units of pos. excess from $v$ to $u$
        \Else
            \State $\bell(v) \leftarrow \bell(v) + 1$
        \EndIf
    \EndWhile
    \EndIndent
    \State
    \State def $\textsc{PullRelabel}()$
    \Indent
    \While{$\exists v$ where $\bell(v) > 0$ and $\Gamma(v) < \nabla(v)/2$ }
        \State Let $v$ be a vertex maximizing $\bell(v)$
        \If{$\exists (u, v)$ such that $\cc_f(u, v)>0, \bell(u)=\bell(v)+1$ }
\State $\ff(v, u) \leftarrow \ff(v, u) - \frac{1}{2}, \ff(u, v) \leftarrow - \ff(v, u)$ // Sends $\frac{1}{2}$ units of neg. excess from $v$ to $u$
        \Else
            \State $\bell(v) \leftarrow \bell(v) - 1$
        \EndIf
    \EndWhile
    \EndIndent
    \end{algorithmic}
\end{algorithm}

\subsection{Reduction to Out-Expanders}
\label{subsec:Reduction-to-Out-Expanders}

\begin{algorithm}[H]
    \begin{algorithmic}
    \caption{$\textsc{BiDirectedExpanderPruning}(G, W, \Pi)$}\label{alg:BiDirectedExpanderPruning}
    \State def $\textsc{Init}$
    \Indent
    \State $(\tilde{V}_1, \mathcal{P}_1, E^r_1) \leftarrow \textsc{DirectedExpanderPruning}(G, W, \Pi)$
    \State $(\tilde{V}_2, \mathcal{P}_2, E^r_2) \leftarrow \textsc{DirectedExpanderPruning}(G^{rev}, W, \Pi)$
    \State $\tilde{V} \leftarrow \tilde{V}_1 \cap \tilde{V}_2, \mathcal{P} \leftarrow \mathcal{P}_1 \cup \mathcal{P}_2, E^r \leftarrow E^r_1 \cup E^r_2$ // dynamically updated
    \EndIndent
    \State 
    \State def $\textsc{RemoveEdges}(D)$
    \Indent
    \State $(\tilde{V}_1, \mathcal{P}_1, E^r_1).\textsc{RemoveEdges}(D)$ 
    \State $(\tilde{V}_2, \mathcal{P}_2, E^r_2).\textsc{RemoveVertices}(\tilde{V}_2 \setminus \tilde{V}_1)$
    \State $(\tilde{V}_2, \mathcal{P}_2, E^r_2).\textsc{RemoveEdges}(D)$ 
    \State $\textsc{AdjustPartition}$
    \EndIndent
    \State
    \State def $\textsc{AdjustPartition}()$
    \Indent
    \While{$\tilde{V}_1 \neq \tilde{V}_2$}
    \State $(\tilde{V}_1, \mathcal{P}_1, E^r_1).\textsc{RemoveVertices}(\tilde{V}_1 \setminus \tilde{V}_2)$
    \State $(\tilde{V}_2, \mathcal{P}_2, E^r_2).\textsc{RemoveVertices}(\tilde{V}_2 \setminus \tilde{V}_1)$
    \EndWhile
    \EndIndent
    \end{algorithmic}
    \label{alg:bidirectedExp}
\end{algorithm}

\begin{proof}\textcolor{red}{TOPROVE 4}\end{proof}

\subsection{Maintaining Out-Expanders}
\label{subsec:outExpan}

It remains to prove \Cref{lm:DirectedExpanderDecomp}.    \Cref{alg:DirectedExpanderPruning} gives an implementation of $\textsc{DirectedExpanderPruning}$. The $\textsc{Init}$ function initializes for an out-expander $(G, W, \Pi)$ the expander pruning variables $\tilde{V}, \mathcal{P}, E^r, \mathcal{D}$ as well as a first valid state $(\ff, \bell)$ of the $\textsc{ValidState}$ algorithm (see \Cref{alg:ValidState}). This valid state $(\ff, \bell)$, we will use to find the pruning cuts in function \textsc{Prune}. Using $\textsc{RemoveEdges}$ the user can remove edges $D$ from $G[\tilde{V}]$. Removing edges might force us to prune away some part of the $G[\tilde{V}]$ and add the pruned part to the collection of pruning sets $\mathcal{P}$. To find the pruning set $P$, we adopt a similar strategy as in \cite{saranurak2019expander}. We inject additional source flow into the flow problem: for any witness edge $e = (u,v) \in E(W)$, where an edge on the embedding path $\Pi(e)$ is in $D$, we increase the sources $\Delta(u), \Delta(v)$ by $\frac{4}{\psi}$. Since we updated the flow problem by increasing the source capacities and removing edges, we need to update the valid state $(\ff, \bell)$. This new valid state $(\ff, \bell)$, then allows us to locate the pruning set in the function \textsc{AdjustPartition}. In \textsc{AdjustPartition}, we check whether there is a vertex in the remaining graph $G[\tilde{V}]$ on level $h$. If there is no such vertex, it will certify that in fact $G[\tilde{V}]$ has already a good out-witness and we don't need to prune away any subgraph. If on the other hand, there is a vertex on level $h$ we will find a pruning set $P$ using the function \textsc{Prune}. This set $P$ is then added to the collection of pruning sets $\mathcal{P}$ and the vertices in $P$ are removed from $\tilde{V}$. The cut edges $E_{G\setminus \mathcal{D}}(P,\tilde{V})$ are added to the remove edges $E^r$. Since $\tilde{V}$ has become smaller, we need to update the valid state $(\ff, \bell)$ again. We do this once more by injecting additional source at the endpoints of any witness edge $e \in E(W)$, where some edge on the path $\Pi(e)$ is in $E_{G\setminus \mathcal{D}}(\tilde{V},P)$. Thereafter we again check whether in the new valid state $(\ff, \bell)$ there is a vertex in $\tilde{V}$ on level $h$. We keep on doing this procedure until there no longer is a vertex on level $h$. We will prove that the volume of the pruning sets can be related to the size of the set of edges $D$ initially removed by the user. So far we have not explained how to find the pruning set in function \textsc{Prune}. This is accomplished by a standard level cutting procedure. We start with $P$ being all vertices on level $h$ and then check whether the vertices on the next level have volume at least $\phi \cdot \vol_G(P)$. If it is the case, we add vertices on the next level to $P$ and otherwise return $P$.

Through the function \textsc{RemoveVertices} the user can remove vertices $S$ from $\tilde{V}$. Similar to the function \textsc{RemoveEdges}, we will have to inject additional source at the endpoints of the witness edges $e \in E(W)$, where some edge of $\Pi(e)$ is in $E_{G \setminus \mathcal{D}}(\tilde{V},S)$, and update the valid state $(\ff, \bell)$ accordingly. This might again leave some vertices on level $h$ and will again force us to prune some vertices. This is again accomplished by a call to \textsc{AdjustPartition}. And similar to \textsc{RemoveEdges}, we will again prove that the volume of the pruning sets can be related to the volume of the set $S$ initially removed by the user.

\begin{comment}
\begin{algorithm}[H]
\caption{$\textsc{PruneOrCertify}(G, \ell)$}\label{alg:PruneOrCertify}
\begin{algorithmic}[1]
\State $S \leftarrow \emptyset, i \leftarrow h$ 
\Repeat 
\State $S \leftarrow S \cup\left\{v \in \tilde{V} \mid \bell(v) = i\right\}$
\State $i \leftarrow i - 1$
\Until{$\operatorname{vol}_{G}\left(\{v \in \tilde{V} \mid \bell(v) \leq i\}\right) < (1 + \phi) \cdot \operatorname{vol}_{G}(S)$} 
\State \Return the cut $S$ 
\end{algorithmic}
\end{algorithm}
\end{comment}

\begin{algorithm}[H]
    \caption{$\textsc{DirectedExpanderPruning}(G, W, \Pi)$}\label{alg:DirectedExpanderPruning}
    \begin{algorithmic}[1]
    \State def $\textsc{Init}$ 
    \Indent
    \State $\tilde{V} \leftarrow V, \mathcal{P} \leftarrow \emptyset, E^+_{\mathcal{S}} \leftarrow \emptyset, E^-_{\mathcal{S}} \leftarrow \emptyset, E^r \leftarrow \emptyset, \mathcal{D} \leftarrow \emptyset$
    \State $(\ff, \bell) \leftarrow \textsc{ValidState}(G, \frac{18}{\phi \psi^2}\cdot \vecone,\veczero,\deg_W,h)$
    \EndIndent
    \State 
    \State def $\textsc{RemoveEdges}(D)$
    \Indent
    \State $\mathcal{D} \gets \mathcal{D} \cup D$
    \State $(\ff, \bell).\textsc{RemoveEdges}(D)$ 
    \State $(\ff, \bell).\textsc{IncreaseSource}(\frac{4}{\psi} \deg_{\Pi^{-1}(D)})$ 
    \State $\textsc{AdjustPartition}()$
    \EndIndent
    \State 
    \State def $\textsc{RemoveVertices}(S)$
    \Indent
    \State $\tilde{V} \leftarrow \tilde{V} \setminus S, E^+_{\mathcal{S}} \leftarrow E^+_{\mathcal{S}} \cup E_{G\setminus \mathcal{D}}(S,\tilde{V}), E^-_{\mathcal{S}} \leftarrow E^-_{\mathcal{S}} \cup E_{G\setminus \mathcal{D}}(\tilde{V},S)$
    \State $(\ff, \bell).\textsc{RemoveEdges}\left(E_{G\setminus \mathcal{D}}(\tilde{V},S) \cup E_{G\setminus \mathcal{D}}(S,\tilde{V})\right)$ 
    \State $(\ff, \bell).\textsc{IncreaseSource}(\frac{4}{\psi} \deg_{\Pi^{-1}(E_{G\setminus \mathcal{D}}(\tilde{V},S) \cup E_{G\setminus \mathcal{D}}(S,\tilde{V}))})$ 
    \State $\textsc{AdjustPartition}()$
    \EndIndent
    \State
    \State def $\textsc{AdjustPartition}()$
    \Indent
    \While{$\exists v \in \tilde{V}$ with $\bell(v) = h$}
    \State $P \leftarrow \textsc{Prune}(G \setminus \mathcal{D},\bell)$
    \State $\mathcal{P} \leftarrow \mathcal{P} \cup \{P\}, \tilde{V} \leftarrow \tilde{V} \setminus P, E^r \leftarrow E^r \cup E_{G \setminus \mathcal{D}}(P,\tilde{V})$ \label{alg:DiExpDecomp-AdjustPartition}
    \State $(\ff, \bell).\textsc{RemoveEdges}(E_{G \setminus \mathcal{D}}(P,\tilde{V}) \cup E_{G \setminus \mathcal{D}}(\tilde{V},P))$ 
    \State $(\ff, \bell).\textsc{IncreaseSource}(\frac{4}{\psi} \deg_{\Pi^{-1}\left(E_{G \setminus \mathcal{D}}(P,\tilde{V}) \cup E_{G \setminus \mathcal{D}}(\tilde{V},P)\right)})$
    \EndWhile
    \EndIndent
    \State
    \State def $\textsc{Prune}(G, \bell)$ 
    \Indent
    \State $S \leftarrow \emptyset, i \leftarrow h$ 
    \Repeat 
    \State $S \leftarrow S \cup\left\{v \in \tilde{V} \mid \bell(v) = i\right\}$
    \State $i \leftarrow i - 1$
    \Until{$\operatorname{vol}_{G \setminus \left(\mathcal{D} \cup E^-_{\mathcal{S}}\right)}\left(\{v \in \tilde{V} \mid \bell(v) \leq i\}\right) < (1 + \frac{\phi}{72}) \cdot \operatorname{vol}_{G \setminus \left(\mathcal{D} \cup E^-_{\mathcal{S}}\right)}(S)$} 
    \State \Return the cut $S$ 
    \EndIndent
    \end{algorithmic}
\end{algorithm}


\begin{proof}\textcolor{red}{TOPROVE 5}\end{proof}


\subsection{Static Expander Decomposition}
\label{subsec:staticExpDecom}
In this section, we discuss how we can use the algorithm $\textsc{BiDirectedExpanderPruning}$ of \Cref{thm:ExpanderPruning} as a subroutine for a static expander decomposition. But before we turn to the outline of the algorithm, we recall the directed version of the cut-matching game. We point out that in the theorem statements of \cite{khandekar2009graph,louis2010cut} there is no mention of \underline{\textbf{fake}} edges as used below but these can be gleaned off the algorithmic description as first observed in \cite{chuzhoy2020deterministic}.

\begin{theorem}[\cite{khandekar2009graph,louis2010cut}]\label{thm:CutMatching}
    Given a directed graph $G=(V, E)$ of $m$ edges and a parameter $\phi$, the cut-matching game takes $O((m \log^3 m) / \phi)$ time and either returns
    \begin{enumerate}
        \item \label{item:CM-thm1} a $O(1/\log^2(m))$-witness $(W, \Pi)$ certifying that $G \cup \mathcal{F}$ is a $\phi$-expander for some set of \underline{\textbf{fake}} edges $\mathcal{F}$ where $|\Pi^{-1}(\mathcal{F})| \leq c \cdot \frac{m}{\log^4(m)}$, where $c > 0$, or
        \item \label{item:CM-thm2} a balanced sparse cut $(A, \bar{A})$ in $G$: $e_G(A, \bar{A}) \leq O\left(\phi \cdot \log^2(m) \cdot \min(\vol_G(A) , \vol_G(\bar{A}))\right)$ such that $\vol_G(A), \vol_G(\bar{A}) = \Omega(c \cdot m/\log^6 m)$.
    \end{enumerate}
\end{theorem}

The statement above slightly deviates from well-known cut-matching game formulations. It is more common that the cut-matching game either certifies that $G$ is a $\phi$-expander or provides a cut that might be unbalanced. But it is straightforward to obtain the formulation in \Cref{thm:CutMatching}. Recall that the cut-matching algorithm attempts to embed a witness using $O(\log^2(m))$ single commodity flows. A cut $(A, \bar{A})$ is provided if the algorithm fails to route one of these network flows. If one uses the push-relabel algorithm for routing these single commodity flows, it is easy to see that one obtains a pre-flow $\ff$ such that all positive excess flow is stuck on the smaller side of the cut and the total amount is at most $\min(\vol_G(A), \vol_G(\bar{A}))$. Thus, one can readily find a source-sink pair matching $F$ of size at most $\min(\vol_G(A), \vol_G(\bar{A}))$ and extend the pre-flow to an actual routing in $G \cup F$. Indeed if the cut $(A, \bar{A})$ is unbalanced, the algorithm picks such a set of fake edges $F$ and routes the remaining excess flow along these edges. It then continues with routing the next single-commodity flow in $G$. If the algorithm eventually manages to embed a witness, the witness will actually be embedded into $G \cup \mathcal{F}$, where $\mathcal{F}$ is the union of all the fake edge sets $F$ added over all rounds. 



In \Cref{alg:StaticExpanderDecomposition}, we then use $\textsc{BiDirectedExpanderPruning}$ to remove the set $\mathcal{F}$ of fake edges from $G \cup \mathcal{F}$ making only marginal adjustments to the witness embedding. In the first line of the algorithm, we check if the CutMatching game provides a cut or a witness embedding. If it provides a cut, we recurse on the two sides of the cut. If it provides a witness embedding, we remove the fake edges using the function \textsc{RemoveEdges}. This subroutine initializes an instance of \textsc{BiDirectedExpanderPruning} for the graph and computes a pruning set for the deleted edges $\mathcal{F}$. In the end, the subroutine computes expander decompositions for the pruning sets and combines those into an expander decompositon of the entire graph.

\begin{theorem}\label{thm:StaticExpanderDecomp}
    Given a directed graph $G$, we can compute a $\left(O(\log^{19} m), \lambda, O\left(\frac{1}{\log^4 m}\right)\right)$-expander decomposition $(\mathcal{X}, E_r)$ in run time $O(m \log^{20}(m)/\phi)$ provided $\lambda \leq O(1/\log^{12}(m))$.
\end{theorem}

\begin{proof}\textcolor{red}{TOPROVE 6}\end{proof}

\begin{algorithm}[H]
    \begin{algorithmic}[1]
    \caption{$\textsc{ExpanderDecomposition}(G)$}\label{alg:StaticExpanderDecomposition}
    \If{$\textsc{CutMatching}(G)$ provides a cut $(A, \bar{A})$}
    \State $(\mathcal{X}_1, E^r_1) \leftarrow \textsc{ExpanderDecomposition}(G[A])$
    \State $(\mathcal{X}_2, E^r_2) \leftarrow \textsc{ExpanderDecomposition}(G[\bar{A}])$
    \State \Return $(\mathcal{X}_1 \cup \mathcal{X}_2, E^r_1 \cup E^r_2 \cup E_G(A,\bar{A}))$
    \Else
    \State $\textsc{CutMatching}(G)$ provides $(W, \Pi)$ embedded into $G \cup \mathcal{F}$
    \State \Return $\textsc{RemoveEdges}(G, W, \Pi, \mathcal{F})$
    \EndIf
    \State 
    \State def $\textsc{RemoveEdges}(G, W, \Pi, \mathcal{D})$
    \Indent
    \State $((\tilde{V}, \tilde{W}, \tilde{\Pi}), \mathcal{P}, E^r_0) \leftarrow \textsc{BiDirectedExpanderPruning}(G, W, \Pi)$
    \State $((\tilde{V}, \tilde{W}, \tilde{\Pi}), \mathcal{P}, E^r_0).\textsc{RemoveEdges}(\mathcal{D})$
    \State $\mathcal{X} \leftarrow \{(\tilde{V}, \tilde{W}, \tilde{\Pi})\}, E^r \leftarrow E^r_0$
    \For{$P \in \mathcal{P}$}
    \State \label{alg:SED-recursion} $(\mathcal{X}_1, E^r_1) \leftarrow \textsc{ExpanderDecomposition}(P)$
    \State $\mathcal{X} \leftarrow \mathcal{X} \cup \mathcal{X}_1$
    \State $E^r \leftarrow E^r \cup E^r_1$
    \EndFor
    \State \Return $(\mathcal{X}, E^r)$
    \EndIndent
    \end{algorithmic}
\end{algorithm}


\subsection{Dynamic Expander Decomposition}
\label{subsec:dynExpanderDecomposition}

In this section, we discuss how we can use the algorithm $\textsc{BiDirectedExpanderPruning}$ and the algorithm $\textsc{ExpanderDecomposition}$ as a subroutines for a dynamic expander decomposition. The algorithm is given in \textsc{DynamicExpanderDecomposition} (see \Cref{alg:DynamicExpanderDecomposition}). We initialize the data structure with an expander decomposition $(\mathcal{X}_0, E^r_0)$. The data structure then initializes in the lines 3-5, for each component of the expander decomposition an instance of \textsc{BiDirectedExpanderPruning}. For any edge deletion $d$, the data structure envokes the function \textsc{RemoveEdges}. This algorithm, first finds the component $X$ such that $d \in E(X)$ and then deletes the edge from that expander component using the functions of \textsc{BiDirectedExpanderPruning}. This might potentially require to prune away additional subgraphs of the expander $X$. We replace $X$ in the expander decomposition $\mathcal{X}$ by the remainder of $X$ and add the cut edges of the pruning cuts to $E^r$. For any of these pruned subgraphs, we run the static expander decomposition to obtain an expander decomposition $(\mathcal{X}_1, E^r_1)$ and add the components of $\mathcal{X}_1$ to $\mathcal{X}$ and the edges of $E^r_1$ to $E^r$. 

\begin{theorem}\label{thm:DED}For every $(\beta, \phi, \psi)$-expander decomposition $(\mathcal{X}, E_r)$ of a directed graph $G$, there is a randomized data structure $\textsc{DynamicExpanderDecomposition}(G)$ (see \Cref{alg:DynamicExpanderDecomposition}). For up to $c \cdot \phi \cdot \psi \cdot e(G)$ calls, where $c$ is a fixed constant, of the form
\begin{itemize}
    \item $\textsc{RemoveEdge}(d)$: where $d \in E(V)$, adds $d$ to $\mathcal{D}$ (initially $\mathcal{D} = \emptyset$)
\end{itemize}
the algorithm explicitly updates the tuple $(\mathcal{X}, E^r)$ after each call, such that thereafter $(\mathcal{X}, E^r)$ is a $\left(4 \cdot \beta, \frac{\phi \psi^6}{32000}, \frac{\psi^4}{800}\right)$-expander-decomposition for $G \setminus \mathcal{D}$ refining the previous. The run-time is bounded by $O\left(\frac{|\mathcal{D}|}{\phi^2} \cdot \log e(G) \cdot \max\left(\log^{19}|\mathcal{D}|, \frac{1}{\psi^2}\right)\right).$
\end{theorem}

\begin{algorithm}[H]
    \begin{algorithmic}[1]
    \caption{$\textsc{DynamicExpanderDecomposition}(\mathcal{X}_0, E^r_0)$}\label{alg:DynamicExpanderDecomposition}
    \State def $\textsc{Init}$
    \Indent
    \State $(\mathcal{X}, E^r) \leftarrow (\mathcal{X}_0, E^r_0)$
    \For{$X \in \mathcal{X}$}
    \State $(V_X, \mathcal{P}_X, E^r_X) \leftarrow \textsc{BiDirectedExpanderPruning}(X, W_X, \Pi_X)$
    \EndFor
    \EndIndent
    \State 
    \State def $\textsc{RemoveEdge}(d)$
    \Indent
    \State Find $(X, W, \Pi) \in \mathcal{X}$ such that $d \in E(X)$.
    \State $((V_X, W_X, \Pi_X), \mathcal{P}_X,E^r_X).\textsc{RemoveEdges}(d)$
    \State Replace $(X, W, \Pi)$ by $(V_X, W_X, \Pi_X)$
    \For{$P$ new in $\mathcal{P}_X$} 
    \State $(\mathcal{X}_1, E^r_1) \leftarrow \textsc{ExpanderDecomposition}(P)$ \label{alg:DynExpDec-line12}
    \State $\mathcal{X} \leftarrow \mathcal{X} \cup \mathcal{X}_1$
    \State $E^r \leftarrow E^r \cup E^r_1$
    \EndFor
    \EndIndent
    \end{algorithmic}
\end{algorithm}

\begin{proof}\textcolor{red}{TOPROVE 7}\end{proof}

To obtain \Cref{Main-thm}, we combine \Cref{thm:StaticExpanderDecomp} and \Cref{thm:DED}. After $O(\phi \cdot \psi \cdot e(G))$ deletions, we restart the maintenance of the expander decomposition with \Cref{thm:StaticExpanderDecomp}.

 
\end{document}
