\documentclass[11pt]{article}
\usepackage{amssymb, amsmath}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{verbatim}
\usepackage{algorithmic}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{color}
\usepackage[dvipsnames]{xcolor}
\usepackage{mdframed}
\usepackage{marginnote}
\usepackage{amsfonts}
\usepackage{lineno}

\newcommand{\nota}[1]{ {\tiny \marginnote{#1}[0cm]}}

\newcommand\mydef{\mathrel{\overset{\makebox[0pt]{\mbox{\normalfont\tiny\sffamily def}}}{=}}}
\providecommand{\keywords}[1]
{
  \small	
  \textbf{\textit{Keywords---}} #1
}

\newcommand{\mon}[1]{\textcolor{magenta}{\textbf{Mon:} #1}}
\newcommand{\Mod}[1]{\ (\mathrm{mod}\ #1)}
\newcommand{\nega}[1]{\bar{#1}}
\newcommand{\GG}{\mathcal{G}}
\newcommand{\qd}{\qed}
\newcommand{\sos}{\text{\sc{SoS}}}
\newcommand{\supp}{suppt}
\newcommand{\y}{y^{N}}
\newcommand{\eps}{\varepsilon}
\newcommand{\n}{\hat{n}}
\newcommand{\uu}{\hat{u}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\FF}{\hat{\mathcal{F}}}
\newcommand{\Z}{\mathcal{Z}}
\newcommand{\Cc}{\mathcal{C}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\V}{\mathcal{V}}
\newcommand{\K}{\tilde{K}}
\newcommand{\LAS}{\text{\sc{Las}}}
\newcommand{\las}{\text{\sc{las}}}
\newcommand{\CLP}{\text{\sc{Clp}}}
\newcommand{\clp}{\text{\sc{clp}}}
\newcommand{\SA}{\text{\sc{Sa}}}
\newcommand{\sa}{\text{\sc{sa}}}
\newcommand{\sgn}{\text{sgn }}
\newcommand{\adj}{\text{ adj }}
\newcommand{\rank}{\text{rank }}
\newcommand{\nullity}{\text{nullity }}
\newcommand{\tr}{\text{Tr}}
\newcommand{\PEXP}[1]{L{\left [ #1 \right]}}
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\PS}{\mathcal{P}}
\newcommand{\conv}{\textnormal{conv}}
\newcommand{\Ss}{\mathcal{S}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Aut}{\text{Aut}}
\newcommand{\Ideal}[1]{{\textbf{I}}\left( #1 \right)}
\newcommand{\GIdeal}[1]{\left\langle #1 \right\rangle}
\newcommand{\ca}[1]{\mathcal{#1}}

\newcommand{\CSP}{\textsc{CSP}}
\newcommand{\IMP}{\textsc{IMP}}
\newcommand{\Pol}{\textsf{Pol}}
\newcommand{\Inv}{\textsf{Inv}}
\newcommand{\FC}{\textsc{FC}}
\newcommand{\PC}{\textsc{PC}}
\newcommand{\Nsatz}{\textsc{Nsatz}}
\newcommand{\CPC}{\textsc{CPC}}
\newcommand{\CF}{\textsc{CF}}

\newcommand{\Max}{\textsf{Max}}
\newcommand{\Min}{\textsf{Min}}
\newcommand{\Majority}{\textsf{Majority}}
\newcommand{\Minority}{\textsf{Minority }}
\newcommand{\Minorityns}{\textsf{Minority}}
\newcommand{\lex}{\textsf{lex }}
\newcommand{\lexns}{\textsf{lex}}
\newcommand{\grlex}{\textsf{grlex }}
\newcommand{\grlexns}{\textsf{grlex}}
\newcommand{\ThB}{\textsc{TH}}



\newcommand{\Variety}[1]{{\textbf{V}}\left( #1 \right)}
\newcommand{\spn}[1]{\left\langle #1 \right\rangle}
\newcommand{\spns}{\left\langle \Ss \right\rangle}
\newcommand{\Gg}[2]{S_{#1 \setminus #2}}
\newcommand{\cf}[2]{#1_{#2}}
\newcommand{\cone}{\textbf{cone}}
\newcommand{\symsos}{\text{Symmetric-SoS}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\I}{\emph{$\rm{I}$}}
\newcommand{\Zz}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\1}{\textbf{1}}
\newcommand{\qsos}{$Q\text{-}\sos$ }
\newcommand{\qsost}[1]{Q_{A}(#1)\text{-}\sos }
\newcommand{\qsosAt}[2]{Q_{#1}(#2)\text{-}\sos }
\newcommand{\multideg}{\textnormal{multideg}}
\newcommand{\LM}{\textnormal{LM}}
\newcommand{\LT}{\textnormal{LT}}
\newcommand{\LC}{\textnormal{LC}}
\newcommand{\LCM}{\textnormal{lcm}}
\newcommand{\GB}{\text{Gr\"{o}bner} }
\newcommand{\reduce}[2]{{#1}|_{#2}}
\newcommand{\redu}[1]{\overline{#1}}
\newcommand{\paren}[1]{\left ( #1 \right ) }
\newcommand{\Field}{\mathbb{Q}}
\newcommand{\Do}{\mathcal{D}}
\newcommand{\Real}{\mathbb{R}}
\newcommand{\Rational}{\mathbb{Q}}
\newcommand{\Complex}{\mathbb{C}}
\newcommand{\Int}{\mathbb{Z}}
\newcommand{\Bool}{\mathbb{B}}
\newcommand{\T}{\mathcal{T}}

\newcommand{\vb}[1]{\mathbf{#1}}

\newcommand\p{\mathcal{P}}
\newcommand\q{\mathcal{Q}}




\newcommand\bits{{|D|-1}}
\newcommand\uval{{(|D|-1)}}
\newcommand\ideg{???}
\newcommand\db{2(d+k-1)}
\newcommand\ub{2^{2k-1-\ell} \log (2\alpha)}
\newcommand\ds{2^{2k} \log (2\alpha) S}
\newcommand\Cb{2^{2k-1} \log (2\alpha)}
\newcommand\dref{d}




%
 
\usepackage{lineno}
\newcommand*\patchAmsMathEnvironmentForLineno[1]{\expandafter\let\csname old#1\expandafter\endcsname\csname #1\endcsname
  \expandafter\let\csname oldend#1\expandafter\endcsname\csname end#1\endcsname
  \renewenvironment{#1}{\linenomath\csname old#1\endcsname}{\csname oldend#1\endcsname\endlinenomath}}\newcommand*\patchBothAmsMathEnvironmentsForLineno[1]{\patchAmsMathEnvironmentForLineno{#1}\patchAmsMathEnvironmentForLineno{#1*}}\AtBeginDocument{\patchBothAmsMathEnvironmentsForLineno{equation}\patchBothAmsMathEnvironmentsForLineno{align}\patchBothAmsMathEnvironmentsForLineno{flalign}\patchBothAmsMathEnvironmentsForLineno{alignat}\patchBothAmsMathEnvironmentsForLineno{gather}\patchBothAmsMathEnvironmentsForLineno{multline}}
\usepackage[shortlabels]{enumitem}
\usepackage{url}
\usepackage[pdftex, colorlinks,
  linkcolor=blue,
  citecolor=blue,filecolor=blue,urlcolor=blue]
{hyperref}
\usepackage[capitalise]{cleveref}
\bibliographystyle{plainurl}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{example}[theorem]{Example}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{remark}[theorem]{Remark}
\newcommand{\ignore}[1]{}
\newcommand{\ale}[1]{\textcolor{red}{\textbf{Alex:} #1}}
\newcommand{\lv}[1]{\textcolor{ForestGreen}{\textbf{Luis:} #1}}
\newcommand{\SOSe}{\rm{SOS}_\varepsilon\text{-complete}}
\usepackage[normalem]{ulem}

\title{On the Degree Automatability of Sum-of-Squares Proofs} \date{}
\author{Alex Bortolotti \thanks{University of Applied Sciences and Arts of Southern Switzerland, IDSIA, Lugano, Switzerland. E-mail: \href{mailto:alex.bortolotti@supsi.ch}{\texttt{alex.bortolotti@supsi.ch}}.} \  \and Monaldo Mastrolilli \thanks{University of Applied Sciences and Arts of Southern Switzerland, IDSIA, Lugano, Switzerland. E-mail: \href{mailto:monaldo.mastrolilli@supsi.ch}{\texttt{monaldo.mastrolilli@supsi.ch}}.} \ \and Luis Felipe Vargas\thanks{University of Applied Sciences and Arts of Southern Switzerland, IDSIA, Lugano, Switzerland. E-mail: \href{mailto:luis.vargas@supsi.ch}{\texttt{luis.vargas@supsi.ch}}.}}





\begin{document}

\maketitle


\begin{abstract}
The Sum-of-Squares (\sos) hierarchy, also known as Lasserre hierarchy, has emerged as a promising tool in optimization.
However, it remains unclear whether fixed-degree $\sos$ proofs can be automated [O'Donnell (2017)].
Indeed, there are examples of polynomial systems with bounded coefficients that admit low-degree $\sos$ proofs, but these proofs necessarily involve numbers with an exponential number of bits, implying that low-degree $\sos$ proofs cannot always be found efficiently.
 
A sufficient condition derived from the Nullstellensatz proof system [Raghavendra and Weitz (2017)] identifies cases where bit complexity issues can be circumvented.
One of the main problems left open by Raghavendra and Weitz is proving any result for refutations, as their condition applies only to polynomial systems with a large set of solutions.

In this work, we broaden the class of polynomial systems for which degree-$d$ $\sos$ proofs can be automated. To achieve this, we develop a new criterion and we demonstrate how our criterion applies to polynomial systems beyond the scope of Raghavendra and Weitz's result. In particular, we establish a separation for instances arising from Constraint Satisfaction Problems ($\CSP$s).
Moreover, our result extends to refutations, establishing that polynomial-time refutation is possible for broad classes of polynomial time solvable constraint problems, highlighting a first advancement in this area.

\noindent\keywords{Sum of squares, Polynomial calculus, Polynomial ideal membership, Polymorphisms, \GB basis theory, Constraint satisfaction problems, Proof complexity.}
\end{abstract}
\newpage
{
  \hypersetup{linkcolor=black}
  \tableofcontents
}



\newpage
\section{Introduction}\label{sect:introduction}
Semidefinite programming (SDP) relaxations have been a powerful technique for approximation algorithm design ever since the celebrated result of Goemans and Williamson \cite{GoemansWilliamson1995}. With the aim to construct stronger and stronger SDP relaxations, the Sum-of-Squares ($\sos$) hierarchy has emerged as a systematic and versatile method for approximating many combinatorial optimization problems, see e.g. \cite{Lasserre2001, Parrilo03, FlemingKothariPitassi19, Laurent2009}.
However, fundamental questions remain unanswered. For instance, it is still unknown under what conditions \sos\ can be \emph{automated}, meaning whether one can find a degree-$d$ \sos\ proof in time $n^{O(d)}$, provided it exists.
O'Donnell \cite{odonnell2017} observed that the prevailing belief regarding the automatability of \sos\ using ellipsoid algorithms is not entirely accurate. Issues may arise when the only degree-$d$ proofs contain exceedingly large coefficients, thereby hindering the ellipsoid method from operating within polynomial time. 
In this paper, we establish novel conditions that ensure \sos\ automatability.

\paragraph{Polynomial optimization.}
Polynomial optimization asks for minimizing a polynomial over a given set of polynomial constraints. That is, given polynomials $r, p_1, \ldots, p_m \in \mathbb{R}[x_1, \ldots, x_n]$, the task is to find (or approximate) the infimum of the following probth:
\begin{align}\label{eqn:POP_formulation}
    \inf_{x\in S} r(x), \quad {\text{where}} \quad S=\{x\in \mathbb{R}^n \ | \ p_1(x)=\cdots=p_m(x)=0\}.
\end{align}
Typically, \( S \) is defined by a set of equality constraints, in this case \( \mathcal{P} = \{p_1, \ldots, p_m\}\), as well as a set of inequality constraints, \( \mathcal{Q} \). For all applications considered here, however, it suffices to restrict to the case where \( \mathcal{Q} = \emptyset \) and \( S \) is finite, enabling the modeling of various relevant combinatorial problems. Nonetheless, we emphasize that our results readily extend to the semialgebraic setting, where \( \mathcal{Q} \neq \emptyset \). For further details, we refer to \cref{sect:semialgebraic_sos_criterion}.

A common approach for solving (or approximating) a polynomial optimization problem is by means of sums of squares of polynomials, as we now explain.
\begin{definition}[$\sos$ Proof System]\label{def:SOS_proof}
    Let $\mathcal{P} = \{p_1=0,\ldots,p_m=0\}$ be a set of polynomial equations, and consider a polynomial $r\in \mathbb{R}[x_1, \dots, x_n]$. An $\sos$ proof of $``r\geq 0"$ (over $S$) from $\mathcal{P}$ is an identity of the form $r = \sum_{i=1}^{t_0} s_i^2 + \sum_{i=1}^m h_i p_i,$
where $s_i, h_i\in \mathbb{R}[x_1, \ldots, x_n]$. Moreover, we say that the above $\sos$ proof has \emph{degree} at most $d$ if $\deg(s_i^2) \leq d$, for all $i \in [t_0]$, and $\deg(h_i p _i) \leq d$ for all $i \in [s]$. An \emph{$\sos$ refutation of $\mathcal{P}$} is an $\sos$ proof of $``-1 \geq 0"$ from $\mathcal{P}$.
\end{definition}

The $\sos$ hierarchy is based on the following observation: if there exists an $\sos$ proof of $`` r - \theta \geq 0"$ from $\mathcal{P}$, then we have that $\min_{x \in S} r(x) \geq \theta$. Moreover, the supremum of the values $\theta$ such that there is an $\sos$ proof of $``r - \theta \geq 0"$ from $\mathcal{P}$ of degree $d$, is called $d$-th $\sos$ relaxation, also known as the $d$-th Lasserre relaxation of problem (\ref{eqn:POP_formulation}) \cite{Lasserre2001,Parrilo03}. It turns out that the $d$-th  $\sos$ relaxation can be formulated as an SDP of size $n^{O(d)}$.

\(\sos\) relaxations have gained increasing popularity and success; yet, they remain a relatively recent development. Fundamental questions about their properties and capabilities still lack definitive answers. O'Donnell~\cite{odonnell2017} posed the open problem of identifying meaningful conditions that ensure that “small” \(\sos\) proofs can be found. We will consider systems $\mathcal{P} = \{p_1 = 0,\ldots,p_m = 0\}$ of polynomials and an ``input" polynomial $r$ of degree at most $d$, with the (mild) assumption that the bit complexity needed to represent $\mathcal{P}$ and $r$ is polynomial in $n$. Moreover, we assume that $\mathcal{P}$ is explicitly Archimedean, i.e. there is $N<2^{poly(n^d)}$ such that there exists a ``small" $\sos$ proof of $``N - x_i^2 \geq 0"$ from $\mathcal{P}$ for any variable $x_i$.
We restate O'Donnell's question as follows: \emph{Consider an explicitly Archimedean polynomial system \(\mathcal{P}\); under what conditions on $\mathcal{P}$ does the following property hold?}
\begin{itemize}[label=$(\rm{P})$]
    \item Assume there exists an $\sos$ proof of $``r \geq 0"$ from $\mathcal{P}$ of degree $2d$. Then, for every $\varepsilon>0$, there also exists an $\sos$ proof of $``r +\varepsilon \geq 0"$ from $\mathcal{P}$ with degree $O(d)$ and coefficients bounded by $2^{poly(n^d,\lg \frac{1}{\varepsilon})}$.
\end{itemize}

The assumption of explicitly Archimedeanity guarantees that if there exists an approximate $\sos$ proof of $``r - \theta \geq 0"$, then there exists an (exact) $\sos$ proof of $``r - \theta + \varepsilon \geq 0"$, up to any arbitrary precision $\varepsilon$.
Moreover, explicit Archimedeanity implies that the SDP has no duality gap~\cite{JoszH16}. Therefore, it is often assumed in literature since numerical methods for solving SDPs are guaranteed to converge only when the duality gap is zero.

\paragraph{$\Nsatz$ criterion.}
Since O'Donnell~\cite{odonnell2017} raised his question in 2017, very few papers have been published that address this issue. An initial elegant solution to this question is provided by Raghavendra and Weitz~\cite{raghavendra_weitz2017}, which is based on the Nullstellensatz proof system~\cite{BeameIKPP94}, as we will now outline. For additional results from the literature related to this problem, see~\cref{sect:previous_work}.

We denote the vector space of polynomials for variables $x_1, \ldots, x_n$ up to degree $d$ as $\mathbb{R}[x_1, \dots, x_n]_d$. Moreover, we denote by $\I(S) = \{p \in \mathbb{R}[x_1,\ldots, x_n] \ | \ p(x) = 0 \  \forall x \in S\}$ the vanishing ideal generated by $S$, and by $\I_{d}(S) = \I(S) \cap \mathbb{R}[x_1, \ldots, x_n]_{d}$ the $d$-truncated ideal.  
\begin{definition}[$\Nsatz$ Proof System]\label{def:d-completeness}
    Consider a system of polynomial equations $\mathcal{P}=\{p_1=0,\ldots,p_m=0\}$. A \emph{Nullstellensatz ($\Nsatz$) proof} of $``p=0"$ from $\mathcal{P}$ is a sequence of polynomials $(h_1,\ldots,h_m)$ such that the polynomial identity $p=\sum_{i=1}^m h_ip_i$ holds. We say that the proof has degree $d$ if $\max_i\{\deg h_ip_i\}=d$.  We say that $\mathcal{P}$ is $\Nsatz$ \emph{$d$-complete} over $S$ if for every $p\in \I_{d}(S)$, the identity $``p=0"$ can be derived using a degree-$O(d)$ $\Nsatz$ proof from $\mathcal{P}$.
\end{definition}
Next, we recall the criterion proposed by Raghavendra and Weitz for the algebraic setting~\footnote{We remark that their criterion is formulated for the semialgebraic setting, i.e. when there are also inequalities.}. Moreover, for the sake of clarity of the exposition, we present their result in the case $S$ is finite. We define the algebraic variety \(S\) as the set of common zeros of \(\mathcal{P}=\{p_1=0,\ldots,p_m=0\}\). We first observe that this criterion necessitates a technical condition on the solution set \( S \), referred to as \emph{\(\delta\)-spectrality}, which we will outline below.
Let \(\mathbf{v}_d\) represent the column vector whose entries correspond to the elements of the standard monomial basis of \(\mathbb{R}[x_1, \dots, x_n]_d\). For \(\alpha \in \mathbb{R}^n\), \(\mathbf{v}_d(\alpha)\) denotes the vector of real numbers obtained by evaluating the entries of \(\mathbf{v}_d\) at \(\alpha\). 

\begin{definition}
    Let $S$ be a finite algebraic variety. We say that $S$ is $\delta$-spectrally rich up to degree $d$ if every nonzero eigenvalue of the moment matrix $\frac{1}{|S|} \sum_{\alpha \in S} \mathbf{v}_d(\alpha)\mathbf{v}_d^{\sf{T}}(\alpha)$ is at least $\delta$.
\end{definition}
This property holds for $\frac{1}{\delta} = 2^{poly(n^d)}$ in many natural instances, for example when $S \subseteq \{0,1\}^n$, or more in general, when $S \subseteq D^n$ for any finite domain $D \subseteq \mathbb{Q}$ (see \cref{sect:delta_spectrality} and \cite{raghavendra_weitz2017}).

\begin{theorem}[$\Nsatz$ criterion~\cite{raghavendra_weitz2017}]\label{th:Nsatz_crit}
    Let $\mathcal{P}$ be a system of polynomial equalities over $n$ variables with solution set $S$. Assume that 
    \begin{itemize}
        \item [(1)] $S$ is $\delta$-spectrally rich up to degree $d$.
        \item [(2)] $\mathcal{P}$ is $\Nsatz$ $d$-complete over $S$.\label{d-comp}
    \end{itemize} 
    Let $r$ be a polynomial and assume there exists an $\sos$ proof of $``r \geq 0"$ from $\mathcal{P}$ of degree $d$. Then, there also exists an $\sos$ proof of $``r \geq 0"$ from $\mathcal{P}$ with degree $O(d)$ and with absolute values of the coefficients bounded by $2^{poly(n^d ,\lg \frac{1}{\delta})}$.
\end{theorem}

This criterion is applicable to various optimization problems, including \textsc{Max-Clique}, \textsc{Matching}, and \textsc{Max-CSP}~\cite{raghavendra_weitz2017}. 
However, the \(\Nsatz\) criterion is subject to significant limitations. First, the criterion is sufficient but not necessary.
Second, it is important to observe how the $\Nsatz$ criterion (see condition \textit{(2)} in \cref{th:Nsatz_crit}) is influenced by the complexity of a well-known problem known as the \emph{Ideal Membership Problem} (\(\IMP\)). This problem involves determining whether an input polynomial \(r\) belongs to the ideal generated by \(\{p_1, \ldots, p_m\}\). We denote the \(\IMP\) where the input polynomial \(r\) has degree at most \(d=O(1)\) as \(\IMP_d\). The \(\IMP\) was first studied by Hilbert~\cite{Hilbert1893} and is a fundamental algorithmic problem with significant applications in solving polynomial systems and polynomial identity testing (see, for example, \cite{Cox}). In general, the \(\IMP\) is notoriously intractable, and the results of Mayr and Meyer demonstrate that it is EXPSPACE-complete \cite{Mayr1989, MAYR1982305}.
It remains unclear under what conditions the \(\IMP\) is tractable within the \(\Nsatz\) proof system, specifically regarding when condition \textit{(2)} in \cref{th:Nsatz_crit} is satisfied. More importantly, the limitations of the \(\Nsatz\) proof system (see e.g. \cite{FlemingKothariPitassi19}) affect the applicability of \cref{th:Nsatz_crit}. 
In simpler terms, it is intuitive to suggest that if we could replace the \(\Nsatz\) proof system with a more powerful proof system, we would be able to broaden the applicability of the criterion to new problems.


Finally, a key limitation—and one of the main open problems left by Raghavendra and Weitz \cite{raghavendra_weitz2017, Weitz:Phd}—is the inapplicability of the $\Nsatz$ criterion to \(\sos\) refutations.


For example the $\Nsatz$ criterion does not allow one to show that the following decision problem can be solved in polynomial time. 

\begin{problem}[Degree-$d$ Sum-of-Squares Refutation for $\CSP$]\label{prob:sos-csp}
Given a Constraint Satisfaction Problem (\(\CSP\)) with constraints \(\phi_1(x) = 0, \dots, \phi_m(x) = 0\) over a finite domain, decide whether:
\begin{itemize}
    \item \textbf{YES}: There exists a degree-\(d\) sum-of-squares (\(\sos\)) proof of the infeasibility of the system, i.e., a derivation of \(-1 \geq 0\) from the axioms \(\phi_1(x) = 0, \dots, \phi_m(x) = 0\) and the domain constraints.
    \item \textbf{NO}: No such degree-\(d\) \(\sos\) proof exists.
\end{itemize}
\end{problem}
Let us call this problem ``$\sos$-$\CSP$". This is perhaps the most natural formulation of ``the $\sos$ algorithm for $\CSP$s". 
It is quite striking that we still do not know whether there exists or not a polynomial-time decider for $\sos$-$\CSP$ (even for certain restricted classes of problems).

\subsection*{References to the related literature}\label{sect:previous_work}
O'Donnell \cite{odonnell2017} raised the issue of \(\sos\) bit complexity in 2017, as discussed in \cref{sect:introduction}. 
O'Donnell also presented an example of a polynomial system with bounded coefficients that allows for a degree 2 \(\sos\) proof, which necessarily has doubly-exponential coefficients.

The aforementioned result (\cref{th:Nsatz_crit}) by Raghavendra and Weitz \cite{raghavendra_weitz2017} offered an initial elegant, albeit partial, solution.
Raghavendra and Weitz expanded O'Donnell's work and presented an example of a polynomial system containing the Boolean constraints and a polynomial that admits degree 2 $\sos$ proof, but for which any $\sos$ proof of degree $O(\sqrt{n})$ must have coefficients of doubly-exponential magnitude in $n$.

Interestingly, Hakoniemi \cite{Hakoniemi21} demonstrated that both \(\sos\) and Polynomial Calculus ($\PC$)  refutations over Boolean variables encounter the same bit complexity issue. This finding also raises significant concerns regarding the frequently asserted degree automatability of \(\PC\).

Furthermore, strategies in \cite{BharathiM21,BulatovRSTOC22,BulatovARXIV21, Mastrolilli21TALG} to address the problem of \sos\ bit complexity involve replacing the original input polynomial constraints \(\mathcal{P}\) with a new set of polynomials $\mathcal{P}^{(d)}$ that satisfies the \(\Nsatz\) criterion, and generally depends on the \sos\ degree \(d\). This set $\mathcal{P}^{(d)}$ is computed externally (by an algorithm specifically designed for this purpose \footnote{In general such an algorithm cannot be simulated by $\sos$. We defer the interested reader to \cref{sect:csp_literature} for details.}), serving as the input for \(\sos\) in place of $\mathcal{P}$. For example, in the semilattice case, if $\mathcal{P}$ consists of $m$ polynomials, the set $\mathcal{P}^{(d)}$, used in \cite{BulatovRSTOC22,Mastrolilli21TALG}, is generated by a specific algorithm and has a size of \( m^{O(d)} \); that is, $\mathcal{P}^{(d)}$ depends on \( d \) and grows exponentially with the \(\sos\) degree \( d \). This preprocessing step ensures that \(\sos\) retains ``low" bit complexity, but only if $\mathcal{P}$ is substituted with $\mathcal{P}^{(d)}$. Essentially, the approach utilized in \cite{BharathiM21,BulatovRSTOC22,BulatovARXIV21, Mastrolilli21TALG} is to apply the \(\Nsatz\) criterion without enhancing or extending it, with the goal of replacing the initial input polynomial system with a new one that is computed externally and satisfies the \Nsatz\ criterion.
Our results demonstrate that all preprocessing steps employed in \cite{BharathiM21,BulatovRSTOC22,Mastrolilli21TALG} are unnecessary, as \(\sos\) achieves low bit complexity for any fixed \( d \) when \(\mathcal{P}\) is provided directly as input.

Recently, Gribling et al. \cite{Gribling23} showed that, under specific algebraic and geometric conditions, $\sos$ relaxations can be computed in polynomial time. However, as they noted, their algebraic conditions are more restrictive than $d$-completeness. Their geometric conditions apply to systems of only inequality constraints with full dimensional feasibility set.  Additionally, Palomba et al. \cite{palomba} showed that, under some mild conditions, sum-of-squares bounds for copositive programs can be computed in polynomial time. These results also yielded insights into the bit complexity of $\sos$ proofs.


The quest of characterizing conditions for ensuring tractability of the $\sos$ proof system fits into the more general context of real algebraic geometry, and in particular of the so-called \textit{effective Positivstellensatz}, i.e., the study of the complexity for representing polynomials using rational sums of squares. To this end, we mention Baldi et al. \cite{BaldiKM24}, who recently proved an exponential upper bound on the coefficients' bit complexity of sums of squares proofs in the general case of radical zero-dimensional ideals when the equality constraints form a graded basis.
Furthermore, as observed, $\sos$ feasibility can be reformulated as an SDP feasibility problem, which remains a well-known open question.
In this context, we highlight the work of Pataki and Touzov \cite{PatakiT24}, who showed that many SDP's have feasible sets whose elements have large encoding size. Moreover, they initiated the study of characterizing the conditions under which SDP feasibility sets with large encoding sizes occur.


Several papers in the literature investigate the automatability of the $\sos$ proof system in relation to degree lower bounds. Specifically, various instances have been studied where a set of polynomial equations $\mathcal{P} = \{p_1=0, \ldots, p_m=0\}$ and a polynomial $q$ satisfy the condition that `` $q \geq 0$ on $S$", but any $\sos$ proof of this fact necessarily requires a high degree (see, e.g.,~\cite{GrigorievHP_MMJ02,KLM-hard-prob-formulation,KLM-unbounded-SOS-hierarchy-integrality-gap,KLM-tight-SOS-LB-binary-POP,KLM-SOS-hierarchy-LB-symmetric-formulations,potechin:SOS-LB-from-symmetry}). Within the context of the Lasserre hierarchy, these examples correspond to polynomial optimization problems for which many rounds of the hierarchy are needed to reach optimality.

In contrast, our focus is on a different aspect of automatability: we aim to understand under what conditions a fixed-degree level of the Lasserre hierarchy can be computed in time polynomial in the input size (up to a prescribed precision). This shifts the question from degree necessity to degree tractability within a computational framework.


\subsection{Our contributions}\label{sect:contribution}


Our main contribution is to study and expand the class of polynomial systems for which finding degree-$d$ \(\sos\) proofs can be automated. To this end, we first introduce a new criterion based on the \textit{Polynomial Calculus} ($\PC$) proof system which guarantees that property (\textsc{P}) holds, referred to as the \textit{$\PC$ criterion}. This criterion holds both for $\sos$ refutations and for $\sos$ proofs over feasible systems over finite domains. Remarkably, as we will demonstrate, this criterion applies to a broad class of instances arising from Constraint Satisfaction Problems ($\CSP$s) where the $\Nsatz$ criterion does not. Specifically, we will establish tractability results for broad class of $\sos$-$\CSP$, and, moreover, prove complete degree-$d$ automatability beyond refutations for certain polynomial systems arising from $\CSP(\Gamma)$. The proof of the $\PC$ criterion combines several results, including a simulation of the $\PC$ proof system by the $\sos$  proof system together with the development of a different criterion based on the $\sos$ proof system, called the \(\sos_{\varepsilon}\) criterion.

\subsubsection*{$\PC$ criterion} \label{sect:PC-crit}
We begin by introducing \textit{polynomial systems over finite domains}, i.e., systems where each variable is restricted to assume values from a fixed set of $k$ rational numbers $ \rho_{1}, \rho_{2}, \ldots, \rho_{k} $. Given a polynomial system of equations $\mathcal{P}$ and a finite domain $D = \{\rho_1, \ldots, \rho_{k}\}$, we say that $\mathcal{P}$ is a \emph{polynomial system over finite domain $D$} if it includes the following \textit{domain polynomials}:
\begin{align}
D_{k}(x_i)&=(x_i-\rho_{1})(x_i-\rho_{2})\cdots (x_i-\rho_{k}) = 0\qquad i\in[n].
\end{align}
These polynomials ensure that each variable $x_1, \ldots, x_n$ is constrained to take values from $D$. Note that this formulation generalizes polynomial systems with Boolean variables, i.e., where the constraint \( x_i^2 - x_i = 0 \) enforces $x_i$ to be either 0 or 1.

Polynomial Calculus over $\mathbb{R}$ ($\textrm{PC}\slash \mathbb{R}$), or in short Polynomial Calculus ($\PC$), is a proof system used in computational complexity and proof complexity to study the efficiency of algebraic reasoning. It operates over polynomials and is particularly useful in analyzing the complexity of solving systems of polynomial equations. The goal is to derive the polynomial \(1\) (i.e., show inconsistency) or to demonstrate that a certain polynomial is implied by the given system. 
Originally introduced as a \textit{refutation system} in \cite{CleggEI96}, $\PC$ can be viewed as a degree-truncated version of Buchberger’s algorithm \cite{JeffersonJGD13, Cox}. Essentially, $\PC$ is a dynamic version of the $\Nsatz$ proof system, employing schematic inference rules to reason about polynomial equations. We emphasize that, for the remainder of the paper, we will consider \(\PC\) in the broader sense of polynomial derivation (so not restricted to refutation) and with polynomials over the reals.

$\PC$ consists of the following derivation rules for polynomial equations $(f = 0), (g = 0) \in  \mathcal{P}$, domain polynomial equations $(D_{k}(x_j)=0)$, variable $x_j$, and numbers $a, b \in \mathbb{R}$
\begin{equation}\label{eq:PCrules_introduction}
    \frac{}{f=0} \qquad \frac{}{D_{k}(x_j)=0} \qquad \frac{f=0 \qquad g=0}{a f + b g =0} \qquad \frac{f=0}{x_jf=0} 
\end{equation}


A \emph{$\PC$ derivation} of $``r=0"$ from $\mathcal{P}$ is a sequence $(r_1=0,\ldots,r_L=0)$ of polynomial equations iteratively derived by using \eqref{eq:PCrules_introduction} with $r=r_L$. The \emph{size} of a derivation is the sum of the sizes of the binary encoding of the polynomials in the derivation and the \emph{degree} is the maximum degree of the polynomials in the derivation. A \emph{PC refutation} is a derivation of $``1=0"$.

Next, we present one of our main contributions, namely a framework for showing that Property (\textsc{P}) holds for certain polynomial systems over finite domains.

\begin{theorem}[$\PC$ criterion]\label{th:PC_criterion_introduction}
    Let $\mathcal{P}$ be a polynomial system over a finite domain $D$ of $k$ rational values, let $S$ be its variety. Let $\mathcal{G}_{2d}$ be a $2d$-truncated \GB basis of $I(S)$ according to the $\grlexns$ order such that $\|\mathcal{G}_{2d}\|_{\infty}\leq 2^{poly(n^d)}$. Assume that, for every $g\in \mathcal{G}_{2d}$, there exist a $\PC$ derivation of $g$ from $\mathcal{P}$ of size $poly(n^d)$ and degree $O(d)$. 
    
    Let $r$ be a polynomial and assume there exists an $\sos$ proof of $``r \geq 0"$ from $\mathcal{P}$ of degree $2d$. Then, for every $\varepsilon>0$, there exists an $\sos$ proof of $``r + \varepsilon \geq 0"$ of degree $O(d)$
    such that the absolute values of the coefficients of every polynomial appearing in the proof are bounded by $2^{poly(n^d, \lg \frac{1}{\varepsilon})}$.
\end{theorem}


Moreover, suppose $\mathcal{P}$ is $\Nsatz$ $d$-complete over $S$. It follows that, for every $g \in \mathcal{G}_{2d}$, the identity $``g=0"$ admits a degree-$O(d)$ $\Nsatz$ proof from $\mathcal{P}$. Further, $\PC$ is known to be strictly stronger than $\Nsatz$ \cite{CleggEI96}, thus implying that our criterion is also more powerful than the $\Nsatz$ criterion.
The separation between the $\Nsatz$ and the $\PC$ criteria is strict and it will be further discussed in \cref{sec:separation-intro}.

The proof of \cref{th:PC_criterion_introduction} combines multiple techniques, which we will present in greater detail in \cref{sect:outline_PC_proof}. A key component of this proof is the development of a different criterion, the $\sos_\varepsilon$ criterion. As we will see, this criterion provides a more general framework that extends beyond finite domains (see \cref{ex:separation2}). Nevertheless, the strong connection between $\PC$ and Buchberger's algorithm makes the $\PC$ criterion an effective tool for many instances where the $\IMP_d$ can be efficiently solved \cite{Cox}.

\subsubsection*{Two main applications from $\CSP$s.}
In the following, we present our main two applications of \cref{th:PC_criterion_introduction}.
In both cases we focus on restricted classes of Constraint Satisfaction Problems (\(\CSP\)s), denoted as \(\CSP(\Gamma)\), where constraints are limited to relations from a specified set~\(\Gamma\). These language restrictions have proven effective for analyzing computational complexity classifications and other algorithmic properties of $\CSP$s, leading to recent breakthroughs in \cite{Bulatov17,Zhuk17,Zhuk20} (see, e.g., \cite{barto_et_al:DFU:2017:6959,2017dfu7,Chen09} and \cref{sect:CSP_IMP_background} for further details and necessary background).

\paragraph{First main application: refutation for bounded width $\CSP$s}
All known tractable Constraint Satisfaction Problems $\CSP(\Gamma)$ for a fixed constraint language $\Gamma$  are solvable using two fundamental algorithmic principles. The first relies on the \emph{few subpowers property} (see e.g. \cite{barto_et_al:DFU:2017:6959}). The second, \emph{local consistency checking}, is the most widely known and natural approach for solving $\CSP$s \cite{BartoK14,barto_et_al:DFU:2017:6959,Bulatov17}.


We consider the class of constraint languages $\Gamma$ for which $\CSP(\Gamma)$ has \emph{bounded width}, meaning that it can be solved by a local consistency checking algorithm (see e.g.~\cite{BartoK14,barto_et_al:DFU:2017:6959}). Identifying and characterizing such languages is crucial for understanding the tractability of constraint satisfaction problems \cite{BartoK14,barto_et_al:DFU:2017:6959}. Note that for languages that rely on the {few subpowers property} in general $\sos$ requires high degree for refutation \cite{barto_et_al:DFU:2017:6959,BartoK14, GRIGORIEV2001613}.

As a corollary of \cref{th:PC_criterion_introduction}, we establish the polynomial-time feasibility of the $\sos$ refutations for the whole class $\sos$-$\CSP(\Gamma)$ problems (see \cref{prob:sos-csp}) for which $\CSP(\Gamma)$ has \emph{bounded width}. \begin{corollary}\label{th:BW}
    For constraint languages $\Gamma$ over finite domains for which $\CSP(\Gamma)$ has \emph{bounded width}, the $\sos$-$\CSP(\Gamma)$ \cref{prob:sos-csp} can be solved in polynomial time for any fixed degree~$d$.
\end{corollary}
\begin{proof}\textcolor{red}{TOPROVE 0}\end{proof}

Note that both the decision and search versions of \cref{prob:sos-csp} with bounded width are solvable in polynomial time for any fixed degree~$d$, as a consequence of \cref{th:PC_criterion_introduction}.

Further, we mention that in \cite{ThapperZ18} it was obtained a similar result in the context of the Sherali-Adams proof system. However, this result applies only to a fixed limited form of $\mathcal{P}$, namely the Boolean canonical linear program. As remarked in \cref{sect:previous_work}, our focus is on deriving SoS proofs directly from $\mathcal{P}$ with variables over general finite domains without any preprocessing. To this end, in \cref{th:BW}, we demonstrate that for \emph{any} system of equations $\mathcal{P}$ over a finite domain that defines a bounded-width relation, finding SoS refutations directly derived from $\mathcal{P}$ can be automated.

\paragraph{Second main application: strong separations arising from $\CSP$s}\label{sec:separation-intro}
As second application of \cref{th:PC_criterion_introduction}, we examine constraint languages (and polynomial equations) that are closed under the semilattice and dual discriminator polymorphisms\footnote{In the context of $\CSP$s, a \emph{polymorphism} is a special kind of function that helps us understand the structure of the constraints. Specifically, it is a function that combines multiple solutions of a \CSP\ in a way that still satisfies the constraints. Polymorphisms are useful because they reveal patterns in the constraints, and studying them can help determine how easy or hard a \CSP\ is to solve. We refer to \cref{def:polymorph} for a formal definition.} (see, e.g., \cite{barto_et_al:DFU:2017:6959} and \cref{sect:PCsemilattice,sect:PCdual} for the necessary background). 
Propositional formulas from \textsc{HORN-SAT} or \textsc{2-SAT} can be easily translated into system of polynomial equations that are semillatice or dual discriminator closed, respectively.
Moreover, these two classes extend \textsc{HORN-SAT} and \textsc{2-SAT} formulas, respectively, to general finite domain cases and have held a significant role in the theory of Constraint Satisfaction Problems of the form $\CSP(\Gamma)$; see, e.g.,~\cite{barto_et_al:DFU:2017:6959,2017dfu7} and references therein.

\begin{theorem}\label{th:semilattice+dualdiscr}
    For a system $\mathcal{P}$ of polynomial equations over $n$ variables that is closed under the semilattice (or dual discriminator) polymorphism, then the $\PC$ criterion (\cref{th:PC_criterion_introduction}) applies.
\end{theorem}
Note that these classes of problems are known to be bounded width (see e.g. \cite{barto_et_al:DFU:2017:6959}). Therefore, by \cref{th:BW} the refutation \cref{prob:sos-csp} can be solved in polynomial time.
However, \cref{th:semilattice+dualdiscr} establishes a significantly stronger result.
Indeed, \cref{th:semilattice+dualdiscr} indicates that \emph{any} degree \( d \) \sos\ proof of $p\geq 0$, for any polynomial $p$, can be computed in \( n^{O(d)} \) time with arbitrary precision (not only degree-$d$ $\sos$ proofs for $-1\geq 0$, as required by refutation). 

We emphasize that Buss and Pitassi \cite{BussP98} 
show that the \(\Nsatz\) proof system necessitates a degree \(\Theta(\log n)\) proof for the induction principle \(\text{IND}_n\), a polynomial inference rule that can be formalized as a derivation in either \textsc{HORN-SAT} or \textsc{2-SAT} formulae. As a result, if \(\mathcal{P}\) is closed under the semilattice (or dual discriminator) polymorphism, it cannot be \(\Nsatz\) \(d\)-complete for any \(d = o(\log n)\).
Thus, \cref{th:PC_criterion_introduction}, \cref{th:semilattice+dualdiscr} and \cite{BussP98} establish a clear separation between the $\PC$ criterion and the \(\Nsatz\) criterion. 

Polynomial Calculus (\PC) is a rule-based, dynamic extension of Nullstellensatz (see e.g.~\cite{FlemingKothariPitassi19}). Due to its dynamic nature, it can sometimes achieve a refutation of significantly lower degree through cancellations than would be possible with the static Nullstellensatz system. A notable example is the induction principle \(\text{IND}_n\) mentioned above, which has degree 2 refutations in $\PC$. By contrast, its Nullstellensatz degree has been shown to be \(\Theta(\log n)\)~\cite{BussP98}.

    We demonstrate that $\PC$, in addition to solving refutation for the very special case of \(\text{IND}_n\) with low degree, also addresses the much more general Ideal Membership Problem $\IMP_d$ in $n^{O(d)}$ time for two families of problems that significantly generalize \textsc{HORN-SAT} and \textsc{2-SAT} in multiple respects and apply to all finite rational domains. This also demonstrates that \(\PC\) is complete and free from bit complexity issues for these problems (Hakoniemi recently raised concerns regarding the bit complexity in \(\PC\) \cite{Hakoniemi21}, see also \cref{sect:open problem}).  
    


    {This result is not only intrinsically interesting but also closely aligned with the main goal of this article. Indeed, the $\PC$ criterion demonstrates that solvability via Polynomial Calculus and the bit complexity of Sum-of-Squares are deeply interconnected.
    }
    Finally, we emphasize that it is not implied by the recent result of Bulatov and Rafiey \cite{BulatovRSTOC22}; more details are given in \cref{sect:applications}.

The proof of this broad generalization is technically complex and lengthy, necessitating a dedicated space with the necessary preliminaries. Therefore, we defer the full discussion—including a detailed review, proof, the underlying intuition and the literature review—to \cref{sect:applications}.


    




This paper aims to deepen our understanding of the bit complexity issue and to explore the conditions under which it arises. For instance, we demonstrate that all preprocessing steps aimed at replacing \(\mathcal{P}\) with a new set \(\mathcal{P'}\) to satisfy the \(\Nsatz\) criterion, as used in \cite{BulatovRSTOC22,Mastrolilli21TALG, BharathiM22, BharathiM21} to circumvent the bit complexity issues of \(\sos\) for semilattice and dual discriminator polymorphisms, are unnecessary. Specifically, \(\sos\), when applied directly to \(\mathcal{P}\) as input, achieves low bit complexity for any fixed~\(d\) (refer to \cref{sect:csp_literature} for a more detailed discussion). This result appears to support and extend the hypothesis that CNF formulas do not exhibit a bit complexity issue, an open question posed by Hakoniemi~\cite{Hakoniemi21} (see also \cref{sect:open problem}).

\subsubsection*{$\sos$ (approximately) simulates $\PC$}\label{sect:PC_criterion_introduction}


As a main contribution, we address the existing knowledge gap regarding the relationship between $\sos$ and $\PC$ in the general finite domain setting.
Our main result shows that $\sos$ can simulate $\PC$ derivations in this setting with an arbitrarily small error. Essentially, if $\PC$ can derive the equation $``p=0"$, then, for any arbitrary $\varepsilon>0$, $\sos$ can prove the statements $``p+\varepsilon\geq 0"$ and $``-p+\varepsilon \geq 0"$ with only a polynomial increase in size.
While this result serves as a main technique for proving the $\PC$ criterion, as outlined in \cref{sect:outline_PC_proof}, it is also valuable on its own, as we present below.
Our result builds upon and generalizes the simulation result of Berkholz~\cite{berkholz18} for Boolean variables to the broader context of general finite domains.

Berkholz~\cite{berkholz18} related different approaches for proving the unsatisfiability of a system of real polynomial equations. Over Boolean variables, he showed that SoS simulates $\PC$ refutations: any \(\PC\) refutation of degree \(d\) can be converted into an \(\sos\) refutation of degree \(2d\), with only a polynomial increase in size.

In the non-Boolean setting, there are systems of equations that are easier to refute for $\PC$ than for SoS \cite{GrigorievV01}. Grigoriev and Vorobjov \cite{GrigorievV01} show that the simulation of $\PC$ by SoS does not hold in the non-Boolean case, namely when the Boolean axioms $x_j^2-x_j=0$ are omitted. For example, the so-called telescopic system of equations, $\{ yx_1=1, x_1^2=x_2, \ldots, x_{n-1}^2=x_n, x_n=0\}$, has a $\PC$ refutation of degree $n$, but it requires exponential refutation degree in SoS \cite{GrigorievV01}. It is worth noting that a similar (although much weaker than the one present in \cref{th:sos_sim_PC_introduction}) generalization of Berkholz's result was considered in \cite{Sokolov20}, when the variables take the values $\pm 1$, and in \cite{PartFTT21}, for a variation of $\PC$ endowed with a ``radical rule" and a ``sum-of-squares rule".

Whether $\sos$ could simulate $\PC$ in the general finite domain setting, where variables can take values from any finite set, has remained an open question, despite known limitations in specific non-Boolean cases. 

In this work, we answer this open question and complement the results in~\cite{GrigorievV01,berkholz18} by establishing the following theorem. In summary, we first derive the following lemma.

\begin{lemma}\label{th:sos_sim_PC_introduction}
    Let $\mathcal{P}$ be a system of polynomial equations over a finite domain $D$ with $|D| = k$. Assume that $``r=0"$ has a $\PC$ derivation of degree $d$ and size $S$ from $\mathcal{P}$. Then $`` -r^2\geq 0"$ has an $\sos$ proof of degree $2(d+k-1)$ with coefficients of size $poly(k,S)$.
\end{lemma}

The overall structure of the proof partially mirrors that in \cite{berkholz18}, but with notable differences. In particular, new ideas and techniques are introduced in the simulation of the multiplication rule of \(\PC\).

Furthermore, note that the result holds for the particular case of refutations, i.e. when $r=1$. Indeed, if there exists a $\PC$ refutation of $\mathcal{P}$, i.e., a derivation of $1=0$, then \cref{th:sos_sim_PC_introduction} implies that there exists an $\sos$ refutation $``-1 \geq 0"$ with only polynomial increasing.

Then, employing \cref{th:sos_sim_PC_introduction}, we prove the following result.

\begin{theorem}\label{th:sospc_introduction}
    $\sos$ \emph{approximates} $\PC$ with degree linear in the domain size $k$ over general finite domains. That is, if there exists a \(\PC\) derivation of \( ``r=0" \) with degree \( d \) and size \( S \), then for every \( \varepsilon > 0 \), we have \(\sos\) proofs of \( ``r+\varepsilon \geq 0" \) and \( ``-r+\varepsilon \geq 0" \) with degree \( O(d+k) \) and coefficients bounded by \( 2^{\text{poly}(k, S, \lg \frac{1}{\varepsilon})} \).
\end{theorem}


\subsubsection*{Outline of the techniques for proving the $\PC$ criterion}\label{sect:outline_PC_proof}

Below we outline the main techniques that will be used in the proof of the PC criterion. 

\begin{enumerate}
    \item \textbf{$\sos_\varepsilon$ criterion} (\cref{sect:sos_criterion_subsection}) We begin by introducing a general criterion, called the $\sos_\varepsilon$ criterion, which ensures that Property (\textsc P) is satisfied and, consequently, that $\sos$ can be automated. This criterion is a natural generalization of the $\Nsatz$ criterion~\cite{raghavendra_weitz2017} (see \cref{th:Nsatz_crit}), and serves as a foundational tool for presenting our main contributions. The key distinction lies in the notion of approximate completeness: the $\sos_\varepsilon$ criterion requires $\sos_\varepsilon$ completeness, a relaxed condition than the one required by \cref{th:Nsatz_crit}, as discussed in \cref{sect:sos-criterion}.
Informally, a system $\mathcal{P}$ is $\sos_\varepsilon$ complete if for every $q \in \I_d(S)$ and every $\varepsilon > 0$, there exist an $\sos$ proof of the inequality $``q + \varepsilon \geq 0"$ using bounded coefficients (see Section~\ref{sect:SOS_completeness} for the precise definition).
    \item \textbf{$\sos$ approximability of polynomial systems}(\cref{sect:SOS_completeness}) As previously mentioned, the main difference between the $\Nsatz$ and $\sos_\varepsilon$ criteria lies in their respective notions of completeness. Therefore, a main challenge in applying the $\sos_\varepsilon$ criterion is proving that a given system $\mathcal{P}$ is $\sos_\varepsilon$ complete. To this end, in \cref{sect:SOS_completeness} we present the notion of $\sos$-approximation ($\lesssim$) between polynomial systems defining the same zero set, which turns out to be a powerful tool for showing $\sos_\varepsilon$ completeness, and applying the $\sos_\varepsilon$ criterion.
The key advantage of $\sos$-approximation is that it allows the inheritance of $\sos_\varepsilon$ completeness between systems: under mild conditions, if $\mathcal{P}$ is $\sos_\varepsilon$ complete and $\mathcal{P} \lesssim \mathcal{Q}$, then $\mathcal{Q}$ is also $\sos_\varepsilon$ complete.
    \item {\textbf{SoS approximately simulates $\PC$}} (\cref{sect:proof_sos_sim_PC}) The final tool we use to establish the PC criterion is the simulation of the $\PC$ derivation system by $\sos$. As previously emphasized, this simulation, presented formally in Lemma~\ref{th:sos_sim_PC_introduction} and Theorem~\ref{th:sospc_introduction}, is one of the main contributions of this work and can be appreciated independently. However, it also plays a crucial role in proving another major result: the PC criterion (Theorem~\ref{th:PC_criterion_introduction}).
The proof strategy proceeds as follows. Under the theorem’s hypotheses, the truncated Gröbner basis $\mathcal{G}$ is easily shown to be $\Nsatz$-complete and hence $\sos_\varepsilon$ complete. Using our simulation results, we then establish the following chain of $\sos$-approximations:
   $$\mathcal{G}\lesssim \mathcal{G}^2 \lesssim \mathcal{P}.$$
Finally, using the properties of $\sos$-approximability, we conclude that $\mathcal{P}$ is also $\sos_\varepsilon$ complete. 
\end{enumerate}

In the following sections, we explore these three concepts in more detail. Then, in \cref{sect:pc_crit}, we combine these techniques to prove the $\PC$ criterion (\cref{th:PC_criterion_introduction}).

\subsection{Structure of the article}
In Section \ref{sect:sos-criterion}, we give a full exposition of the $\sos_\varepsilon$ criterion. Subsequently, we develop several tools to facilitate its application. In Section \ref{sect:PC_criterion}, we focus on the case of polynomial systems over finite domains, where we establish a connection to the Polynomial Calculus ($\PC$) proof system and derive a weaker version of the $\sos_\varepsilon$, called the $\PC$ criterion. The latter will be used for the separation in the radical ideal case. \cref{sect:applications,sect:semilattice-proof,sect:dual-proof} are devoted to construct a class of examples arising from Constraint Satisfaction Problems, demonstrating a separation between our new criterion and the $\Nsatz$ criterion. Section \ref{sect:applications} begins with an overview of relevant background and related results, followed by a description of our proof strategy and main results. In Sections \ref{sect:semilattice-proof} and \ref{sect:dual-proof}, we present the detailed proofs. 
Finally, in Section \ref{sect:open problem}, we finish with concluding remarks and discuss potential research directions.

\section{Preliminaries}\label{sect:prelim}
Consider a set of variables $\{x_1,\ldots,x_n\}$ and denote the vector space of polynomials in $x$ up to a fixed degree $d = O(1)$ as $\mathbb{R}[x_1, \dots, x_n]_d$. We denote as $\mathbf{v}_d$ being the column vector whose entries are the elements of the usual monomial basis of $\mathbb{R}[x_1, \dots, x_n]_d$ and, if $\alpha \in \mathbb{R}^n$, $\mathbf{v}_d(\alpha)$ is the vector of reals whose entries are the entries of $\mathbf{v}_d$ evaluated at $\alpha$. It follows that for any polynomial $u(x) \in \mathbb{R}[x_1, \dots, x_n]_d$, it holds that $u(x) = u^{T} \mathbf{v}_d$ for some $u \in \mathbb{R}^n$. 
We will consider systems $\mathcal{P} = \{p_1 = 0,\ldots,p_m = 0\}$ of polynomial equations and an "input" polynomial $r$ of degree at most~$d$, with the (mild) assumption that the bit complexity needed to represent $\mathcal{P}$ and $r$ is polynomial in $n$. The string $l$ representing polynomials $r, p_1, \dots, p_m$ will be the input for our certification problems and this last assumption allows us to reduce any complexity reasoning to $n$ instead of the length of $l$. We will sometimes refer to $\mathcal{P}$ as a set of \emph{constraints} or \emph{axioms}.

Next, we need to define the measures of norm and bit complexity for different objects. For the first measure, consider a polynomial $p = \sum_\alpha c_\alpha x^\alpha$, we define $\| p \|_{\infty} = \max_\alpha |c_{\alpha}|$. Similarly, for a set of polynomial we have $\| \mathcal{P} \|_{\infty} = \max_{p \in \mathcal{P}} \| p \|_{\infty}$. Throughout this paper, we will assume that the set $S$ of common zeros of $\mathcal P$ is \textit{finite} and that  $\| S \| := \max_{\alpha \in S} \| \alpha \| < 2^{poly(n^d)}$. These assumptions are very general and are met in many different contexts. For the second measure, consider a polynomial $p$ (or a polynomial system $\mathcal{P}$). We define the \emph{bit complexity} of $p$ (or $\mathcal{P}$) as the minimum length of a bit-string representing $p$ (or $\mathcal{P}$) when the rational numbers are represented with their reduced fractions written in binary (see e.g.~\cite{Hakoniemi21}). As noted above, the bit complexity of $\mathcal{P}$ is assumed polynomial in $n$.

\subsection*{Explicit Archimedeanity}

We recall the notion of explicit Archimedeanity of polynomial systems. This property plays a crucial role in the context of computations of $\sos$ proofs \cite{JoszH16,Laurent2009}. The Archimedean property in algebraic optimization requires all variables to be bounded within some compact set. The \emph{explicitly Archimedean} condition strengthens this by demanding that boundedness of variables is efficiently certifiable via $\sos$ proofs. We give the following formal definition.

\begin{definition}[Explicitly Archimedean System]
    A system of polynomials $\mathcal{P}$ is said to be \emph{explicitly Archimedean} if one of the following equivalent conditions holds.
    \begin{itemize}
        \item \label{def:exp_arch} For every degree $k$ polynomial $p\in \mathbb{R}[x_1, \dots, x_n]$, there exists $0<N_p \leq 2^{poly(n^{\max\{k,d\}}, \lg \|p\|_{\infty})}$ such that there exists a $\sos$ proof of $``N_p-p\geq 0"$ from $\mathcal{P}$ of degree $O(k)$ and with coefficients bounded by $2^{poly(n^{\max\{k,d\}}, \lg \|p\|_{\infty})}$.
        \item \label{prop:bounded_variables_archimedeanity} For every $i \in [n]$ there exists $0 < N_{x_i} \leq 2^{poly(n^d)}$ such that there exist $\sos$ proofs $``N_{x_i} - x_i \geq 0"$ and $``N_{x_i} + x_i \geq 0"$ from $\mathcal{P}$ of degree $O(d)$ and with coefficients bounded by $2^{poly(n^d)}$.
        \item For every $i \in [n]$ there exists $0 < N_{x_i^2} \leq 2^{poly(n^d)}$ such that there exist $\sos$ proofs $``N_{x_i^2} - x_i^2 \geq 0"$ from $\mathcal{P}$ of degree $O(d)$ and with coefficients bounded by $2^{poly(n^d)}$.
    \end{itemize}
\end{definition}

The assumption of explicit Archimedeanity is met in numerous natural cases. This is the case for Boolean systems, i.e. systems that contain the Boolean constraints $x_i^2 - x_i = 0$ for every variable, where it suffices to set $N_{x_i} = 1$ for $i \in [n]$. Furthermore, every system with variables constrained over a finite domain $D$ is explicitly Archimedean, as shown in \cref{lemma-new-t}.

\subsection*{Ideals and varieties}
Let us recall here the notions of (polynomial) ideals, (algebraic) varieties and some of their properties (see e.g. \cite{Cox}).
Consider a set of polynomials $\mathcal{P} = \{p_1,\ldots,p_m\} \subseteq \mathbb{R}[x_1, \dots, x_n]$. 
\begin{definition}
    The \textit{algebraic variety generated by $\mathcal{P}$} is defined as
    \begin{align*}
        S:= \Variety{\mathcal{P}} = \{x \in \mathbb{R}^n \, | \, p_i(x) = 0, \, \forall i \in [m] \}.
    \end{align*}
\end{definition}
We also define the following two sets.
\begin{definition}
        \begin{align*}
        \langle \mathcal{P} \rangle &:= \{q \in \mathbb{R}[x_1, \dots, x_n] \ | \ q = \sum_i h_i p_i, \ h_i \in \mathbb{R}[x_1, \dots, x_n]\}, \\
        \I(S) &:= \{ q \in \mathbb{R}[x_1, \dots, x_n] \ | \ q(\alpha) = 0, \ \forall \alpha \in S\},
    \end{align*}
    as the \emph{ideal generated by $\mathcal{P}$}, the former, and the \emph{(vanishing) ideal generated by set $S$}, the latter. We refer to a \emph{$d$-truncated ideal} when we consider $I_d := I \cap \mathbb{R}[x_1, \dots, x_n]_d$, where $I \subseteq \mathbb{R}[x_1, \dots, x_n]$ is a polynomial ideal.
\end{definition}

\begin{definition}\label{def:radical}
    We say that an ideal $\I$ is \emph{radical} if $p^m \in \I$ for some $m \in \mathbb{N}$ implies $p \in \I$.
\end{definition}

\subsection*{\GB bases}


We give here a very brief introduction on the notion of $\GB$ basis. For a complete exposition, we refer the reader to \cite{Cox}.

We first establish an order on the polynomial ring $\mathbb{R}[x_1, \ldots, x_n]$. Given a monomial $x^{\alpha} = x_1^{\alpha_1} \dots x_n^{\alpha_n}$, this can be unambiguously associated to the $n$-tuple $\alpha = (\alpha_1, \ldots, \alpha_n) \in \mathbb{N}^n$.

\begin{definition}\label{def:lex and grlex} Let $\alpha =(\alpha_1,\ldots,\alpha_n),\beta=(\beta_1,\ldots,\beta_n)\in \mathbb{N}^n$ and $|\alpha| = \sum_{i=1}^n\alpha_i$, $|\beta| = ~\sum_{i=1}^n\beta_i$.
  \begin{enumerate}[(i)]
      \item Lexicographic order (\lexns): We say $\alpha>_\lex \beta$ if, in the vector difference $\alpha -\beta \in \Zz^n$, the left most nonzero entry is positive. 
      \item Graded lexicographic order (\grlexns): We say $\alpha>_\grlex \beta$ if $|\alpha| >|\beta|$, or $|\alpha| =|\beta|$ and $\alpha>_\lex \beta$.
  \end{enumerate}
\end{definition}

Throughout this paper we will always assume that $\mathbb{R}[x_1,\ldots,x_n]$ is ordered according to the \textit{graded lexicographic order} \grlexns.

One potential approach to solving the $\IMP$ is through polynomial division. The idea is that, given a polynomial $r$ and a set of polynomials $\mathcal{P}$, if the remainder of the division of $r$ by $\mathcal{P}$ is zero, then $r$ belongs to the ideal $\langle \mathcal{P} \rangle$. However, it is well-known that polynomial division is generally not well-defined. Specifically, the remainder resulting from the division of $r$ by $\mathcal{P}$ can vary depending on the order in which the polynomials in $\mathcal{P}$ are used for division.

To fix this issue, a special set of generators was introduced in \cite{BuchbergerThesis}.
\begin{definition}[\GB Basis]
    Let $\mathcal{G} = \{g_1, \ldots, g_s\}$ be a set of polynomials. Consider an ideal $\I \subseteq \mathbb{R}[x_1, \ldots, x_n]$ such that $\I = \langle g_1, \ldots, g_s \rangle$, and consider $r \in \mathbb{R}[x_1, \ldots, x_n]$. We say that $\mathcal{G}$ is a \emph{\GB basis of $\I$} if the following property holds
    \begin{align*}
        r \in \I \iff r|_{\mathcal{G}} = 0,
    \end{align*}
where $r|_{\mathcal{G}}$ is the remainder of the polynomial division of $r$ by $\mathcal{G}$.
\end{definition}
Moreover, we will be mainly interested in solving problems of the form $\IMP_d$, i.e. when $r$ has degree at most $d$. Because $\mathbb{R}[x_1,\ldots,x_n]$ is ordered according to the \grlex order, the only polynomials in $\mathcal{G}$ that can divide $r$ are those with degree $d$ or lower. Consequently, we give the following definition.

\begin{definition}\label{def:dTruncated GB}
  Let $\mathcal{G}$ be a \GB basis of an ideal in $\I \in \mathbb{R}[x_1,\dots,x_n]$, the \emph{d-truncated \GB basis} $\mathcal{G}_d$ of $\I$ is defined as
\begin{equation}\label{eq:Gd}
      \mathcal{G}_d := \mathcal{G} \cap \mathbb{R}[x_1,\dots,x_n]_d.
  \end{equation}
\end{definition}

By the definition of \GB basis, we immediately conclude that $\IMP_d$ can be solved when the $d$-truncated \GB basis is available. Specifically, we have
\begin{align*}
    r \in \I_d \iff r|_{\mathcal{G}_d} = 0.
\end{align*}
Furthermore, if $\mathcal{G}_d$ can be calculated in polynomial time, then the $\IMP_d$ can be solved in polynomial time (see also \cref{sect:PC_bit}).

\subsection*{Polynomial Calculus over general finite domains}

In this paper we consider $\PC$ over a general finite domain $D$, which is an immediate generalization of the classical $\PC$ over the Boolean domain \cite{CleggEI96}, i.e. when the Boolean constraints $x_j^2 - x_j = 0$ belong to the set of constraints. Let $D = \{\rho_1, \rho_2, \ldots, \rho_k\}$ be a finite domain. For every variable $x_j$ where $j \in [n]$, to enforce $x_j$ to assume values in $D$, we include the following univariate \emph{domain polynomials} in $\mathcal{P}$
\begin{align*}
    D_{k}(x_j)&=(x_j-\rho_{1})(x_j-\rho_{2})\cdots (x_j-\rho_{k}) \qquad j \in [n].
\end{align*}
$\PC$ over a general finite domain is a proof system that consists of the following derivation rules for polynomial equations $(f = 0), (g = 0) \in  \mathcal{P}$, domain polynomial equations $(D_{k}(x_j)=0)$, variable $x_j$, and numbers $a, b \in \mathbb{R}$
\begin{equation}\label{eq:PCrules}
    \frac{}{f=0} \qquad \frac{}{D_{k}(x_j)=0} \qquad \frac{f=0 \qquad g=0}{a f + b g =0} \qquad \frac{f=0}{x_jf=0} 
\end{equation}


\begin{definition}\label{def:pc_derivation}
    A \emph{$\PC$ derivation} (or \emph{$\PC$ proof}) of $``r=0"$ from $\mathcal{P}$ is a sequence $(r_1=0,\ldots,r_L=0)$ of polynomial equations iteratively derived by using \eqref{eq:PCrules} with $r=r_L$. The \emph{size} of a derivation is the sum of the sizes of the binary encoding of the polynomials in the derivation and the \emph{degree} is the maximum degree of the polynomials in the derivation. A \emph{PC refutation} is a derivation of $``1=0"$.
\end{definition}

\section[SoS epsilon criterion]{$\sos_\varepsilon$ criterion}\label{sect:sos-criterion}
As outlined in \cref{sect:introduction}, we will examine \emph{sufficient} conditions on a polynomial system \(\mathcal{P}\) for ensuring that the following property holds.
\begin{itemize}[label=$(\rm{P})$]
    \item \label{prob:1} Assume there exists an $\sos$ proof of $``r \geq 0"$ from $\mathcal{P}$ of degree $2d$. Then, for every $\varepsilon>0$, there also exists an $\sos$ proof of $``r +\varepsilon \geq 0"$ from $\mathcal{P}$ with degree $O(d)$ and coefficients bounded by $2^{poly(n^d,\lg \frac{1}{\varepsilon})}$.
\end{itemize}


In this section we formulate the \emph{$\sos_{\varepsilon}$ criterion}, a set of sufficient conditions that guarantee that property (\textsc{P}) holds (see \cref{sect:sos_criterion_subsection}, in particular \cref{th:SoS_Criterion}). The $\sos_{\varepsilon}$ criterion has two requirements: $\delta$-spectrality and $\SOSe$ness. We then proceed to give general settings and techniques to verify that the requirements are satisfied (see \cref{sect:delta_spectrality} and \cref{sect:SOS_completeness}). Finally, we discuss the separation between the \Nsatz\ criterion and the \sos\ criterion (see \cref{sect:separation_Nsatz_SOS,sect:pc_crit,sect:applications}).























\subsection[SoS epsilon criterion]{$\sos_{\varepsilon}$ criterion}\label{sect:sos_criterion_subsection}
Recall we are assuming that $S$ is finite and that $\| S \| < 2^{poly(n)}$. The \emph{moment} matrix is defined as follows.
\begin{align}
M = M_{S,d} := \mathbb{E}_{\alpha \in S} [\mathbf{v}_d (\alpha) \mathbf{v}_d^{\sf{T}}(\alpha)] = \frac{1}{|S|}\sum_{\alpha\in S}\mathbf{v}_d (\alpha) \mathbf{v}_d^{\sf{T}}(\alpha),
\end{align}
where the expectation is over the uniform distribution over $S$. Note that $M$ is positive semidefinite, i.e. it is a real symmetric matrix with nonnegative eigenvalues. Let $\lambda_1$, $\lambda_2$, $\dots, \lambda_{\binom{n+d}{d}} $ be the eigenvalues of $M_{s,d}$ with corresponding eigenvectors $u_1, \dots, u_{\binom{n+d}{d}} $ forming an orthonormal basis for $\mathbb{R}^{\binom{n+d}{d}}$. Let $U$ be the matrix where the columns are the eigenvectors $u_1,\ldots,u_{\binom{n+d}{d}}$. 
Now, we define 
\begin{align}\label{Pi}
\Pi^+ := \sum_{i \text{ s.t. } \lambda_i >0} u_i u_i^{\sf{T}}, \qquad \Pi^0 := \sum_{i \text{ s.t. } \lambda_i =0} u_i u_i^{\sf{T}}. 
\end{align}
    Then, we have 
    \begin{equation*}
        I = U^{\sf{T}} U \qquad \text{and} \qquad I = \Pi^+ + \Pi^0.
    \end{equation*}
We have the following lemma.
\begin{lemma}\label{th:eigen-to-ideal}
Let $u$ be an eigenvector for the zero eigenvalue $\lambda=0$ of $M$. Then, we have $u^{\sf{T}}\mathbf{v}_d\in \I_d(S)$.
\end{lemma} 
\begin{proof}\textcolor{red}{TOPROVE 1}\end{proof}
  \ignore{  where the first equality follows from the definition of orthogonality. To see the second, consider a vector $v$. Since $u_1, \ldots, u_n$ form an orthonormal basis, then there exist $\alpha_1,\ldots, \alpha_n \in \mathbb{R}^n$ such that
    \begin{equation*}
        v = \alpha_1 u_1 + \ldots + \alpha_n u_n.
    \end{equation*}
    Thus, 
    \begin{align*}
        (\Pi^+ + \Pi^0)v &= \sum_i u_i u_i^{\sf{T}} v \\
        &= u_i u_i^{\sf{T}} (\alpha_1 u_1 + \ldots + \alpha_n u_n) = \sum_i \alpha_i u_i = v.
    \end{align*}

We will focus just on discrete sets. We observe that the eigenvectors for the eigenvalue $\lambda=0$ define polynomials that vanish on the algebraic variety. (\textcolor{red}{Do we really need the second part?)}
\begin{lemma}\label{th:eigen-to-ideal}
    Let $u_i(x) := \langle u_i, \mathbf{v}_d \rangle$, then
    \begin{itemize}
        \item For all $i$ s.t. $\lambda_i = 0$, we have $u_i(x) \in I(S)$;
        \item For all $i$ s.t. $\lambda_i > 0$, we have $u_i(x) \notin I(S)$.
    \end{itemize}
\end{lemma}

\begin{proof}\textcolor{red}{TOPROVE 2}\end{proof}

\begin{corol}
    If $\langle \mathcal{P} \rangle$ is radical, then also
    \begin{itemize}
        \item For all $i$ s.t. $\lambda_i = 0$, we have $u_i(x) \in \langle \mathcal{P} \rangle$.
        \item For all $i$ s.t. $\lambda_i > 0$, we have $u_i(x) \notin \langle \mathcal{P} \rangle$.
    \end{itemize}
\end{corol}
}

\begin{definition}[$\delta$-spectrality and $\sos_\varepsilon$-completeness]\label{def:delta+soscomplete}
    Let $\mathcal{P}=\{p_1=0, \dots p_m=0\}$ be polynomial system with variety $S = \Variety{\mathcal{P}}$, and let $\delta \in \mathbb{R}_{>0}$. 
    \begin{enumerate}
        \item We say that \emph{$S$ is $\delta$-spectrally rich up to degree $d$} if every nonzero eigenvalue of $M$ is at least~$\delta$.
        \item We say that \emph{$\mathcal{P}$ is $\sos_\varepsilon$-$d$-complete over $S$} (or simply $\sos_\varepsilon$-complete) if, for every polynomial in the $2d$-truncated vanishing ideal $q \in \I_{2d}(S)$ and every $\varepsilon > 0$, there exists an $\sos$ proof of $``q + \varepsilon \geq 0"$ of degree $O(d)$ from $\mathcal{P}$ with absolute value of the coefficients bounded by $2^{poly(n^d, \, \lg \| q \|_{\infty}, \lg \frac{1}{\varepsilon})}$.
    \end{enumerate}
\end{definition}

Let $r$ be a polynomial. Suppose that $``r \geq 0"$ admits an $\sos$ proof $\Pi$ from $\mathcal{P}$. Although $\Pi$ may, in principle, have coefficients with magnitude of the order $2^{2^n}$ (see \cite{odonnell2017,raghavendra_weitz2017}), we show in the next result that $r$ can be decomposed as a sum-of-squares component plus an ``ideal part" component, both having bounded coefficients. In general, the ideal part does not necessarily take the form $\sum h_i p_i$ as in \cref{def:SOS_proof}. Nevertheless, this result allows us to reduce the discussion to focus on the ideal part of the decomposition. The following lemma, essentially from Raghavendra and Weitz~\cite{raghavendra_weitz2017}, is presented here separately as we use it to extend their result.

\begin{lemma}\label{th:SOS_decomposition}
    Consider the a polynomial system $\mathcal{P} = \{p_1 = 0, \ldots, p_m = 0\}$ with finite variety $S = \Variety{\mathcal{P}}$ such that $\| S \| \leq 2^{poly(n^d)}$. Assume that $S$ is $\delta$-spectrally rich up to degree $d$. \\
    Let $r$ be a polynomial nonnegative on $S$ with coefficients bounded by $2^{poly(n^d)}$. If there exists an $\sos$ proof of $``r \geq 0"$ from $\mathcal{P}$ with degree at most $2d$
    \begin{equation}\label{original-SOS}
        r = \sum_{i=1}^{t_0} q_i^2 + \sum_{i=1}^m h_i p_i,
    \end{equation}
    for some $s_i, h_i \in \mathbb{R}[x_1, \ldots, x_n]$. Then, we have
    \begin{equation}\label{eqn:SoS_decomposition}
        r = \sum_{i=1}^{t_1} s_i^2 + p,
    \end{equation}
    for some polynomials $s_i$ of degree at most $d$, some $p\in \I_{2d}(S)$ and with all the coefficients on the right-hand side of \eqref{eqn:SoS_decomposition} bounded by $2^{poly(n^d, \lg \frac{1}{\delta})}$.
\end{lemma}

\begin{proof}\textcolor{red}{TOPROVE 3}\end{proof}

Note that if $\mathcal{P}$ is $\Nsatz$ $d$-complete, then the identity $p=\sum h_i p_i$ for the ``ideal part" can be computed efficiently by the $\Nsatz$ proof system, i.e. with degree at most $O(d)$ and coefficients bounded by $2^{poly(n^d, \lg \frac{1}{\delta})}$. This is the idea behind the $\Nsatz$ criterion. However, this is sufficient but not a necessary condition (see \cite{raghavendra_weitz2017} for a further discussion on the limitations of the $\Nsatz$ criterion).

We next present a new criterion called \textit{$\sos_{\varepsilon}$ criterion}. In essence, the $\sos_{\varepsilon}$ criterion requires that any degree $2d$ polynomial from the ideal part can be $\sos$ proven efficiently to be nonnegative (up to an additive error $\varepsilon$).  This replaces the requirement that there exists $\Nsatz$ proofs of the the ideal part in the $\Nsatz$ criterion. Since $\sos$ is stronger than $\Nsatz$ as a proof system, it follows that the $\sos_{\varepsilon}$ criterion extends and generalizes the $\Nsatz$ criterion. In the following, we will provide natural examples of separation between the two criteria (see \cref{sect:separation_Nsatz_SOS}).

\begin{theorem}[$\sos_{\varepsilon}$ criterion]\label{th:SoS_Criterion}
    Consider a polynomial system $\mathcal{P}=\{p_1 = 0, \dots, p_m = 0\}$ with finite variety $S = \Variety{\mathcal{P}}$ such that $\| S \| \leq 2^{poly(n^d)}$.
    Assume that (see \cref{def:delta+soscomplete})
    \begin{itemize}
        \item [1)] $S$ is $\delta$-spectrally rich up to degree $d$, and
        \item [2)] $\mathcal{P}$ is $\sos_\varepsilon$-complete over $S$.
    \end{itemize}
    Let $r$ be a polynomial. If $``r \geq 0"$ has a degree $2d$ $\sos$ proof
    \begin{equation*}
        r = \sum_{i=1}^{t_0} \sigma_i^2 + \sum_{i=1}^m h_i p_i,
    \end{equation*}
    then, for every $\varepsilon>0$, there exists an $\sos$ proof of $``r+\varepsilon \geq 0"$ of degree $O(d)$
    \begin{equation}\label{eqn:SOS_criterion}
        r +\varepsilon = \sum_{i=1}^{t} \tilde{\sigma}_i^2 + \sum_{i=1}^m \tilde{h}_i p_i,
    \end{equation}
    such that the coefficients of every polynomial appearing in the proof are bounded by $2^{poly(n^d, \lg \frac{1}{\delta}, \lg \frac{1}{\varepsilon})}$.
\end{theorem}

\begin{proof}\textcolor{red}{TOPROVE 4}\end{proof}

\begin{corollary}
    Suppose $\mathcal{P}$ satisfies the assumptions of the $\sos_\varepsilon$ criterion with $\frac{1}{\delta}=2^{poly(n^d)}$. Assume, moreover, that $\mathcal{P}$ is explicitly Archimedean. If $``r\geq 0"$ has an $\sos$ proof of degree $2d$ from $\mathcal{P}$, then $``r + \varepsilon \geq 0"$ has an $\sos$ proof of degree $O(d)$ from $\mathcal{P}$ that can be computed in time $poly(n^d, \lg \frac{1}{\varepsilon})$, up to any additive error $\varepsilon$.
\end{corollary}



\subsection[Delta-spectrality]{$\delta$-spectrality}\label{sect:delta_spectrality}


The $\delta$-spectrality (\cref{def:delta+soscomplete}) hypothesis in \cref{th:SoS_Criterion} is, to some extent, a mild hypothesis. It is satisfied by many interesting instances where the variety $S$ is discrete. For example, it is satisfied by combinatorial problems having varieties contained in the Boolean hypercube $\{0,1\}^n$. To see this, we first state a lemma for integer-valued matrices.

\begin{lemma}[\cite{raghavendra_weitz2017}]\label{th:spectrality_integer_matrix}
    Let $M \in \mathbb{S}^{N \times N}$ be an integer matrix with $|M_{ij}| \leq B$ for all $i,j \in [N]$. The smallest non-zero eigenvalue of $M$ is at least $(BN)^{-N}$. 
\end{lemma}

By observing that $|S| \cdot M_{S,d}$ is a $O(n^d) \times O(n^d)$ integer-valued matrix, we immediately get $\delta$-spectrality over integer-valued varieties.

\begin{corollary}[\cite{raghavendra_weitz2017}]
    Let $\mathcal{P}$ be a polynomial system such that $S \subseteq \mathbb{Z}^n$ such that $\| S \| < 2^{poly(n^d)}$. Then $S$ is $\delta$-spectrally rich with $\frac{1}{\delta} = 2^{poly(n^d)}$.
\end{corollary}

Another wide class of polynomial problems for which $\delta$-spectrality is easily satisfied are the polynomial systems $\mathcal{P}$ with \textit{variables constrained over a finite domain $D$}. Assuming $D =\{\rho_1, \dots, \rho_k\} \subseteq \mathbb{Q}$ with constant $k=O(1)$, these systems are described as containing the domain polynomials $(x_i - \rho_1)(x_i - \rho_2) \cdot \dots \cdot (x_i - \rho_k)$ for each variables $x_i$.

\begin{corollary}\label{cor:rich-finite}
    Let $\mathcal{P}$ be a polynomial system with variables constrained over a finite domain $D \subseteq \mathbb{Q}$, i.e. $S \subseteq D^n$. Then $S$ is $\delta$-spectrally rich (up to degree $d$) for some $\frac{1}{\delta} = 2^{poly(n^d)}$ 
\end{corollary}

\begin{proof}\textcolor{red}{TOPROVE 5}\end{proof}

\subsection[SoS epsilon completeness]{$\sos_\varepsilon$-completeness}\label{sect:SOS_completeness}
In this section we develop tools for showing that a polynomial system is $\SOSe$.
We will consider multiple polynomial systems $\mathcal{Q}$ preserving geometric and bit complexity properties of $\mathcal{P}$, namely
\begin{enumerate}[label=A\arabic*.]
    \item \label{assumption_1} \textit{Same zero set:} $S = \Variety{\mathcal{P}} = \Variety{\mathcal{Q}}$.
    \item \label{assumption_2} \textit{Same degree order:} $\deg(q) = O(d)$, $ \forall q \in \mathcal{Q}$, where $d$ is the maximum degree of the polynomials in~$\mathcal{P}$.
    \item \label{assumption_3} \textit{Polynomial bit complexity:} the bit complexity for representing $\mathcal{Q}$ is polynomial in $n$. Note that this implies that the cardinality of $\mathcal{Q}$ is polynomially bounded, i.e. $|\mathcal{Q}| = poly(n)$, and that all coefficients of the polynomials in $\mathcal{Q}$ are bounded by $2^{poly(n^d)}$.
\end{enumerate}
\paragraph{$\sos$-approximability.}
We define the relation of \emph{$\sos$-approximability} between polynomial systems with the same zero set. This relation arises by considering $\sos$ proofs of approximate objective polynomials $p + \varepsilon$. Therefore, it cannot be simulated by the $\Nsatz$ proof system. We will see that $\sos$-approximability is a powerful tool for showing that a polynomial system $\mathcal{P}$ is $\SOSe$.
\begin{definition}[$\sos$ approximation]\label{def:sos_approx}
     Let $\mathcal{P}=\{p_1 = 0,p_2=0, \dots, p_m=0\}$ and $\mathcal{P}'=\{p_1'=0, p_2'=0, \dots, p_l'=0\}$ be two polynomial systems such that $\Variety{\mathcal{P}} = \Variety{\mathcal{P}'}$. We say that \emph{$\mathcal{P}'$ $\sos$-approximates $\mathcal{P}$}, and it is denoted by $\mathcal{P} \lesssim_{SoS} \mathcal{P}'$, if for every $p \in \mathcal{P}$ and every $\varepsilon >0$ there exist $\sos$ proofs
    \begin{align}
      \begin{split}
    ``p + \varepsilon \geq 0&"  \text{ from }\mathcal{P}' \text{ and}\\
    ``-p + \varepsilon \geq 0&" \text{ from } \mathcal{P}'     
      \end{split}
    \end{align} 
    with degree $O(d)$ and with coefficients bounded by $2^{poly(n^d, \lg \frac{1}{\varepsilon})}$.
\end{definition}

Next, we introduce a property that will prove valuable throughout the rest of this section. Roughly speaking, we will show that, under the assumption of explicit Archimedeanity, if $\sos$ can (approximately) prove $``p=0"$ in a precise sense, then it can (approximately) prove the product $``gp \geq 0"$ for any polynomial $g$.

\begin{lemma}\label{lemma-pg-e}
    Let $\mathcal{P}$ be an explicitly Archimedean polynomial system. Let $p \in \mathbb{R}[x_1,\ldots,x_n]$ be a polynomial of degree (at most) $2d$ with coefficient norm bounded by $2^{poly(n^d)}$.
    Assume that, for every $\varepsilon>0$, we have $\sos$ proofs of degree $2d$ from $\mathcal{P}$ of
    \begin{align}
      \begin{split}
          ``p + \varepsilon &\geq 0", \text{ and of} \\
          ``-p + \varepsilon &\geq 0",      
      \end{split}
    \end{align} 
    with coefficients bounded by $2^{poly(n^d, \lg \frac{1}{\varepsilon})}$. Then, for every $\varepsilon>0$ and every $g \in \mathbb{R}[x_1 \dots, x_n]$ with $\deg(g) = O(d)$ and $\| g \|_{\infty} < 2^{poly(n^d)}$, there exists an $\sos$ proof from $\mathcal{P}$ of  
    $$`` pg + \varepsilon \geq 0",$$
    of degree $O(d)$ with coefficients bounded by $2^{poly(n^d, \lg \frac{1}{\varepsilon})}$.
\end{lemma}

\begin{proof}\textcolor{red}{TOPROVE 6}\end{proof}

With the notions of $\sos$-approximability and \cref{lemma-pg-e} at hand, we begin by demonstrating an interesting property of the relation $\lesssim_{\sos}$.

\begin{lemma}[Transitivity]\label{th:transitivity_of_approximations}
    Let $\mathcal{P}_1, \mathcal{P}_2$ and $\mathcal{P}_3$ be three systems of polynomials with zero set $S$. Assume that $\mathcal{P}_3$ is explicitly Archimedean. If $\mathcal{P}_1 \lesssim_{SoS} \mathcal{P}_2$ and $\mathcal{P}_2 \lesssim_{SoS} \mathcal{P}_3$, then $\mathcal{P}_1 \lesssim_{SoS} \mathcal{P}_3$.
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 7}\end{proof}

Next we present a few relevant examples for which it is possible to show $\sos$-approximability. The first example focuses on the powers of polynomial systems. Namely, let $\mathcal{P} = \{p_1 = 0, \ldots, p_m = 0\}$ be a polynomial system of equations. We define the \emph{$\alpha$-power of $\mathcal{P}$} as the polynomial system $\mathcal{P}^{\alpha} = \{p_1^{\alpha_1} = 0, p_2^{\alpha_2} = 0, \ldots, p_m^{\alpha_m} =0\}$, where $\alpha$ is a multi-index $\alpha = (\alpha_1,\alpha_2, \ldots, \alpha_m) \in \mathbb{N}^m$. The next result shows that $\alpha$-powers of a polynomial system approximate the set itself.

\begin{proposition}\label{prop:alpha_powers}
    Let $\alpha\in \mathbb{N}^n$, with $|\alpha|=O(d)$. Then, $\mathcal P\lesssim_{SoS}\mathcal{P}^\alpha$.
\end{proposition}

\begin{proof}\textcolor{red}{TOPROVE 8}\end{proof}









In the second example, we show that when the polynomials in a system of polynomials are multiplied by positively shifted sums-of-squares, approximation is possible. More precisely, let $\mathcal{P}=\{p_1 = 0, \dots, p_m = 0\}$ be a polynomial system. Let $g\in \mathbb{R}[x_1, \dots, x_n]$ be a polynomial of the form
\begin{align}\label{sos+p}
    g = \sum_{i=1}^t q_i^2 + c,
\end{align}
for some constant $c > 0$. We consider the polynomial system $\mathcal{P}'=\{gp_1=0, \dots, p_m=0\}$. Clearly, $\mathcal{P}$ and $\mathcal{P}'$ have the same variety. We also make the assumptions \ref{assumption_2} and \ref{assumption_3} for set $\mathcal{P}'$. We have the following result.
\begin{proposition}
    Let $\mathcal{P}$ and $\mathcal{P}'$ as defined above. Then, we have $\mathcal{P} \lesssim_{SoS} \mathcal{P}'$.
\end{proposition}
\begin{proof}\textcolor{red}{TOPROVE 9}\end{proof}

\paragraph{Showing $\SOSe$ness.}

The main consequence of the concept of $\sos$-approximability is that it allows for the inheritance of $\SOSe$ness among different polynomial systems.

\begin{theorem}\label{th:richness_inheritance}
    Let $\mathcal{P}_1$ and $\mathcal{P}_2$ be polynomials systems with zero set $S$. Assume that $\mathcal P_1$ is $\SOSe$ and that $\mathcal{P}_2$ is explicitly Archimedean. If  $\mathcal{P}_1\lesssim_{SoS} \mathcal{P}_2$, then $\mathcal{P}_2$ is $\SOSe$. 
\end{theorem}
\begin{proof}\textcolor{red}{TOPROVE 10}\end{proof}

\begin{corollary}\label{cor:completeness_inheritance}
    Let $\mathcal{P}_1, \dots, \mathcal{P}_k$ be polynomial systems for some integer $k = O(1)$. Assume that $\mathcal{P}_1 \lesssim_{SoS} \dots \lesssim_{SoS} \mathcal{P}_k$. If $\mathcal{P}_1$ is $\sos_{\varepsilon}$-complete and $\mathcal{P}_k$ is explicitly Archimedean, then $\mathcal{P}_k$ is $\sos_{\varepsilon}$-complete.
\end{corollary}



It follows that the problem of showing that an explicitly Archimedean system $\mathcal{P}$ is $\SOSe$ can be reduced to identifying $\sos_\varepsilon$-complete polynomial systems $\mathcal{Q}$ such that $\mathcal{Q} \lesssim_{SoS} \mathcal{P}$. Interestingly, this can be achieved in various instances.


A broad class of such reductions arises from Gröbner basis theory. We recall that \GB bases completely characterize polynomial ideals. Specifically, for polynomial rings ordered by the \emph{\grlexns} order, every polynomial in the $2d$-truncated ideal $q \in \I_{2d}$ has remainder 0 when reduced by the set $\mathcal{G}_{2d}$ of elements of degree at most $2d$ of a \GB basis $\mathcal{G}$ (see e.g.~\cite{Cox}). Therefore, we have the following result.

\begin{lemma}\label{th:Grobner_basis_SOS_completeness}
    Let $\mathcal{P}$ be a polynomial system with $S = \Variety{\mathcal{P}}$. Let $\mathcal{G}_{2d}$ be a $2d$-truncated \GB basis of $I(S)$ according to the $\grlexns$ order. Assume that $\| \mathcal{G}_{2d} \|_{\infty} \leq 2^{poly(n^d)}$. Then $\mathcal{G}_{2d}$ is $\sos_{\varepsilon}$-complete.
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 11}\end{proof}

Finally, we obtain a method for checking whether a system $\mathcal{P}$ is $\SOSe$.



\begin{corollary}\label{cor:powers-complete}
    Let $\mathcal{P}$ be an explicitly Archimedean polynomial system and let $\mathcal{G}_{2d}$ be a $2d$-truncated \GB basis of $\I(\Variety{\mathcal{P}})$ according to the $\grlexns$ order. Assume that $\| \mathcal{G}_{2d} \|_{\infty} \leq 2^{poly(n^d)}$. If there exists a multi-index $\alpha$ with $|\alpha| = O(d)$ such that $\mathcal{G}^\alpha \lesssim_{\sos} \mathcal{P}$, then $\mathcal{P}$ is $\SOSe$.
\end{corollary}

\begin{proof}\textcolor{red}{TOPROVE 12}\end{proof}

Furthermore, the relation $\lesssim_{SoS}$ induces an order structure over the set of explicitly Archimedean polynomials systems with the same variety.

\begin{proposition}
    Consider the set
    \begin{equation*}
        \mathfrak{P}_{S} = \{ \mathcal{P} \, | \, \text{$\mathcal{P}$ is explicitly Archimedean with $\Variety{\mathcal{P}} = S$}\}.
    \end{equation*}
    Then $\lesssim_{SoS}$ is a \emph{preorder} (i.e. a reflexive and transitive relation) of the set $\mathfrak{P}_S$.
\end{proposition}

\subsection[Separation between Nsatz and SoS]{Separation between $\Nsatz$ and $\sos$ criteria}\label{sect:separation_Nsatz_SOS}


We now highlight some differences distinguishing the two notions of completeness. We distinguish between two fundamental cases: non-radical and radical ideals (see \cref{def:radical}).

\textit{Non-radical ideals}. When the ideal generated by the input polynomials is not radical, the $\Nsatz$ criterion is inherently weak and does not apply, as the $d$-completeness property cannot be satisfied. In contrast, below we show that our criterion is more robust and it may be effective even for non-radical ideals. 
In the following, we show a concrete example of an application of the $\sos_{\varepsilon}$ criterion for polynomial systems with non-radical ideals.

\begin{example}\label{ex:separation2}
    Let $\mathcal{P} = \{ x_1^2 + x_2^2 + \ldots + x_n^2 =0\} $. We show first that $\mathcal{P}$ is explicitly Archimedean. It suffices to show that $\mathcal{P}$ has bounded variables by \cref{prop:bounded_variables_archimedeanity}. Indeed, let $i \in [n]$ and consider a variable $x_i$. We have that 
    \begin{align*}
        \frac{1}{4} - x_i &= \left(\frac{1}{2} - x_i\right)^2 + x_2^2 + \dots + x_n^2 - (x_1^2 + x_2^2 + \dots + x_n^2), \\
        \frac{1}{4} + x_i &= \left(\frac{1}{2} + x_i\right)^2 + x_2^2 + \dots + x_n^2 - (x_1^2 + x_2^2 + \dots + x_n^2).
    \end{align*}
    Hence, $\mathcal{P}$ is explicitly Archimedean.
    
     Observe now that $\Variety{\mathcal{P}} = \{(0,0 \ldots, 0)\}$. Therefore, the reduced \GB Basis for $I(\Variety{\mathcal{P}})$ is given by $\mathcal{G} = \{ x_1, x_2, \ldots, x_n \}$. Next we observe that $I(\Variety{\mathcal{P}})$ is not radical. Indeed, that there are no $\Nsatz$ proofs of polynomials $x_i$ (for every $i \in [n]$) from $\mathcal{P}$ since the polynomial $h(x_1^2 + \dots + x_n^2)$ is the zero polynomial or it has degree at least 2, for every $h\in \mathbb{R}[x_1, \dots, x_n]$. Hence the $\Nsatz$ criterion cannot be applied to $\mathcal{P}$. However, it is still possible to find $\sos$ proofs of $``-x_i^2 \geq 0"$ and $``x_i^2 \geq 0"$ from $\mathcal{P}$. Thus, by definition, $\mathcal{G}^2 = \{x_1^2, \dots, x_n^2\} \lesssim_{SoS} \mathcal{P}$. Also, by \cref{prop:alpha_powers}, we have  $\mathcal{G} \lesssim_{SoS} \mathcal{G}^2$ and by \cref{th:Grobner_basis_SOS_completeness} we have that $\mathcal{G}$ is $\SOSe$. Thus by \cref{cor:completeness_inheritance} we have that $\mathcal{P}$ is $\SOSe$.

    Lastly, we note that the moment matrix is
    \begin{align*}
        (M_{\Variety{\mathcal{P}},d})_{ij} = \begin{cases}
            1 & \text{for } (i,j) = (1,1), \\
            0 & \text{otherwise}, \\
        \end{cases}
    \end{align*}
    thus $\Variety{\mathcal{P}}$ is $1$-spectrally rich. Therefore, the $\sos_{\varepsilon}$ criterion of \cref{th:SoS_Criterion} applies, i.e. for every polynomial $r$ with a degree $2d$ $\sos$ proof from $\mathcal{P}$, there exists also a proof of $``r + \varepsilon \geq 0"$ of degree $O(d)$ and coefficients bounded by $2^ {poly(n^d,\lg \frac{1}{\varepsilon})}$ for any additive error $\varepsilon > 0$.
\end{example}

\textit{Radical ideals}. The previous separation example show advantages of the $\sos_{\varepsilon}$ criterion over the $\Nsatz$ criterion. But what happens in the case of radical ideals? 

For problems with a finite domain, the ideal is radical, and it is well known that the $\Nsatz$ proof system is complete for sufficiently large degrees. 
However, in general, a linear lower bound on the degree $O(n)$ is unavoidable, in the sense that there are instances of systems $\mathcal{P}$ and polynomials $r$ such that for proving that $``r=0"$ from $\mathcal{P}$ by the $\Nsatz$ proof system there is a lower bound $\Omega(n)$ on the degree \cite{Buss96}. Thus, if the degree is bounded by a constant $d$, both the $\Nsatz$ and the $\sos$ proof systems are again incomplete, even though we are in a radical setting. We address whether a separation can be established between the \(\sos_{\varepsilon}\) criterion and the \(\Nsatz\) criterion in this context. Specifically, we ask whether there exists a polynomial system \(\mathcal{P}\) and a polynomial \(r\) such that any \(\Nsatz\) proof of \(``r = 0"\) from \(\mathcal{P}\) necessarily has a degree that depends non-constantly on \(n\), while, for every additive error \(\varepsilon > 0\), \(\sos\) proofs of \(``r + \varepsilon \geq 0"\) and \(``-r + \varepsilon \geq 0"\) from \(\mathcal{P}\) can be achieved with degree \(O(d)\) and coefficients bounded by \(2^{poly(n^d)}\). We affirmatively answer this question.

To do so, in \cref{sect:applications} we will examine two natural families of problems, which have played a crucial role in the theory of $\CSP(\Gamma)$. In these cases, the ideal is radical because the variables take values from a finite domain. For these families, we show a strict separation between the two criteria.

\emph{Role of $\varepsilon$ in the criteria.} We highlight that our criterion asks for an {\em approximated} proof of the nonnegativity of the elements in the truncated ideal $I_{2d}(S)$. This seemingly subtle difference has a significant impact on the application of the criterion.
Indeed, \cref{ex:separation2} also shows that even if for some $q\in \I_{2d}(S)$ there is no $\sos$ proof for $``q\geq 0"$, there may be one for $``q+\varepsilon\geq 0"$ satisfying the criterion conditions. This shows that not only replacing the proof system with stronger one ($\Nsatz$ with $\sos$) plays a role, but also extending it to an approximate form. 
We further note that allowing this approximation in the condition has an impact in the result of the criterion. Whereas the $\Nsatz$ criterion shows the existence of an $\sos$ proof of $``r\geq 0"$ with bounded coefficients, the  $\sos_{\varepsilon}$ criterion guarantees the existence of a proof of $``r+\varepsilon\geq 0"$ with bounded coefficients. However, following the discussion in the introduction, this second property is enough to guarantee the polynomial-time computability (up to arbitrary precision) and essentially does not compromise the quality of the computed solutions. 

\subsection{The semialgebraic case}\label{sect:semialgebraic_sos_criterion}

We have seen the $\sos_{\varepsilon}$ criterion in the algebraic case with finite $S$. As noted, this setting is very general and covers a wide range of combinatorial problems. Moreover, all the separations we present in this paper are in this case.
Nonetheless, it is not hard to generalize the $\sos_{\varepsilon}$ criterion to the case where $S$ is \textit{infinite} and there are inequality constraints.
Indeed, Raghavendra and Weitz \cite{raghavendra_weitz2017} originally formulated the $\Nsatz$ criterion in this more general setting. For completeness of exposition, we proceed to formulate the $\sos_{\varepsilon}$ criterion in its full generality. The proof in the semialgebraic case, is similar, mutatis-mutandis, to the proof of the $\sos_{\varepsilon}$ criterion (see \cref{sect:sos_criterion_subsection}).

We begin by defining the $\sos$ proof system in this setting.

\begin{definition}
    Let $\mathcal{P} = \{p_1=0,\ldots,p_m=0\}$ be a set of polynomial equality constraints and $\mathcal{Q} = \{q_1 \geq 0, \ldots, q_\ell \geq 0\}$ be a set of polynomial inequality constraints. Consider a polynomial $r\in \mathbb{R}[x_1, \dots, x_n]$. An $\sos$ proof of $``r\geq 0"$ (over $S$) from $(\mathcal{P}, \mathcal{Q})$ is an identity of the form 
    \begin{align*}
        r = \sum_{i=1}^{t_0} s_i^2 + \sum_{i=1}^\ell \left( \sum_{j=1}^{t_i} \lambda_j^2 \right) q_i + \sum_{i=1}^m h_i p_i,
    \end{align*}
where $s_i, \lambda_j, h_i\in \mathbb{R}[x_1, \ldots, x_n]$. Moreover, we say that the above $\sos$ proof 
    has \emph{degree} at most $d$ if $\max \{\deg(s_i^2), \deg(\lambda_j^2 q_i), \deg(h_ip_i)\} \leq d$.
\end{definition}

Next, we "adjust" various definitions to the semialgebraic case.

\begin{definition}
    Let $\mathcal{P} = \{p_1=0,\ldots,p_m=0\}$ be a set of polynomial equality constraints and $\mathcal{Q} = \{q_1 \geq 0, \ldots, q_\ell \geq 0\}$ be a set of polynomial inequality constraints. We define as
    \begin{align*}
        S = \{x \in \mathbb{R}^n \ | \ p_1(x) = \ldots = p_m(x) =0, \ q_1(x), \ldots, q_\ell(x) \geq 0\}
    \end{align*}
    as the \emph{feasibility set} (or \emph{zero set}) of $(\mathcal{P}, \mathcal{Q})$. Moreover, we recall that the moment matrix is defined as $M = M_{S,d} = \mathbb{E}_{\alpha \in S}[\mathbf{v}_d(\alpha) \mathbf{v}_d^{\sf{T}}(\alpha)]$, where the expectation is taken over the uniform distribution over $S$.
\end{definition}

Lastly, we introduce a new notion to relates to the set of inequality constraints $\mathcal{Q}$

\begin{definition}
    We say that $S$ is $\mu$-robust for $\mathcal{Q}$ if for all $q \in \mathcal{Q}$ and all $\alpha \in S$, it holds that $q(\alpha) > \mu$. 
\end{definition}

We are ready to state the $\sos_{\varepsilon}$ in the semialgebraic case.

\begin{theorem}[$\sos_{\varepsilon}$ criterion]\label{th:SoS_Criterion_semialgebraic}
    Let $\mathcal{P} = \{p_1=0,\ldots,p_m=0\}$ be a set of polynomial equality constraints and $\mathcal{Q} = \{q_1 \geq 0, \ldots, q_\ell \geq 0\}$ be a set of polynomial inequality constraints, with feasibility set $S$ such that $\| S \| \leq 2^{poly(n^d)}$.
    Assume that
    \begin{itemize}
        \item [1)] $S$ is $\delta$-spectrally rich up to degree $d$, 
        \item [2)] $\mathcal{P}$ is $\sos_\varepsilon$-complete over $S$,
        \item [3)] $S$ is $\mu$-robust for $\mathcal{Q}$.
    \end{itemize}
    Let $r$ be a polynomial. If $``r \geq 0"$ has a degree $2d$ $\sos$ proof from $(\mathcal{P}, \mathcal{Q})$
then, for every $\varepsilon>0$, there exists an $\sos$ proof of $``r+\varepsilon \geq 0"$ of degree $O(d)$ from $(\mathcal{P}, \mathcal{Q})$
such that the coefficients of every polynomial appearing in the proof are bounded by $2^{poly(n^d, \lg \frac{1}{\delta}, \lg \frac{1}{\mu} \lg \frac{1}{\varepsilon})}$.
\end{theorem}





\section{\sos\ and \PC\ for polynomials over finite domains}\label{sect:PC_criterion}

This section provides a complete exposition of the main technical results concerning the automatability of degree-$d$ $\sos$ proofs. It presents two primary results: the $\PC$ criterion, a sufficient condition for automatability based on the $\PC$ proof system, and the approximate simulation of $\PC$ by $\sos$ over finite domains. The simulation result is used in the proof of the $\PC$ criterion and may be of independent interest.

We begin by formally defining polynomial systems over finite domains. These are systems of polynomials where variables are restricted to take values over finite sets. Following this, we present \cref{th:sospc}, which states that $\sos$ approximately simulates $\PC$ in this finite domain setting. This result builds upon on \cref{th:sos_sim_PC_1}; its relation to prior work and its role in proving the main criterion are discussed. Finally, the section concludes with the presentation of the $\PC$ criterion (\cref{th:PC_criterion}). 

\subsection{Finite domains systems}
Consider a system of real polynomial equations

\begin{equation}\label{eq:Psystem}
\F=\{f_1=0,\ldots,f_m=0\}    
\end{equation}
over variables $x_1,\ldots,x_n$.
We consider the general case of polynomial equations over a finite domain $D$ of even size $2k$, with $k\in \N$, namely every variable can take a value from among $2k$ given rational values $\rho_{1},\rho_{2},\ldots,\rho_{2k}$. If the domain has an odd number of (distinct) elements, repeat an element so the resulting domain has an even number of (not distinct) elements.
We define the univariate rational \emph{domain polynomials} $D_{2k}(x_j)$ of degree $2k$ for each variable $x_j$ as follows: 
\begin{align}
D_{2k}(x_j)&=(x_j-\rho_{1})(x_j-\rho_{2})\cdots (x_j-\rho_{2k}) \qquad j\in[n], \textrm{ or equivalently,}    \label{eq:domain_f_roots}\\
D_{2k}(x_j)&=x_j^{2k}+\alpha_{2k-1}x_j^{2k-1}+\dots + \alpha_1 x_j + \alpha_0 \qquad j\in[n], \label{eq:domain_f}   
\end{align}
where the correspondence between $\{\alpha_0,\ldots,\alpha_{2k-1}\}$ and $\{\rho_1,\ldots,\rho_{2k}\}$ is given by the well-known Vieta's formulas.
To enforce finite domain variables, the axioms
\begin{equation}\label{eq:domain}
D_{2k}(x_j)=0 \qquad j\in[n],    
\end{equation}
are included in the proof systems. 
Hence every variable $x_j$ can take $2k$ possible values which are the roots of \cref{eq:domain}. We denote by $D=\{\rho_1, \rho_2, \dots, \rho_{2k}\}$ the set of domain values, i.e. $D_{2k}(v)=0$ if and only if $v\in D$, and we set
\begin{equation}\label{eq:D}
    \Do=\{D_{2k}(x_j)=0\mid j\in[n]\}.
\end{equation}
For example, to enforce Boolean variables, the axioms $x^2_j - x_j=0$ are always included in the proof systems and in this case $D=\{0,1\}$. 

In summary, we will consider polynomial systems of equations of the following form.

\begin{definition}
    Let $D$ be a finite domain. A \emph{polynomial system over a finite domain $D$} is defined as a set $\mathcal{P}$ of the form
    \begin{equation}\label{eq:axiomsF}
        \mathcal{P} = \F \cup \Do =\{f_1=0,\ldots,f_m=0\} \cup \{D_{2k}(x_j)=0\mid j\in[n]\}.
    \end{equation}
\end{definition}

Recall that we are considering rational values for $\rho_{1},\rho_{2},\ldots,\rho_{2k}$ in \eqref{eq:domain_f_roots}. It follows that $\alpha_{2k-1}, \ldots,$ $\alpha_0$ are also rational. Let $\beta$ be the the minimum number of bits needed to encode each of the numbers $\alpha_{2k-1}, \ldots,$ $\alpha_0,$  and the values $\rho_1, \rho_2, \dots, \rho_{2k}$ when the rational coefficients are represented with their reduced fractions written in binary.
The \emph{polynomial domain size} is the bit length of the binary encoding of $D_{2k}(x)$, namely $O(k\beta)$. 



Now, we recall the following result claiming that every globally nonnegative univariate polynomial has an $\sos$ decomposition with well structured coefficients.

\begin{lemma}\label{lemma-rational-sq}\cite[Section 4, Thm 23]{magron-schwei}
    Let $p\in \mathbb{R}[x]$ be a univariate polynomial of degree $2d$ with rational coefficients, such that each of them can be encoded with $\tau$ bits. Assume that $p(x)\geq 0$ for all $x\in \mathbb{R}$. Then, we have 
    $$p=\sum_{i=1}^{2d+3}a_iq_i^2,$$
    for some nonnegative rational constants $a_i$ and some polynomials $q_i$ of degree $d$ with rational coefficients. All coefficients in this representation can be encoded with ${O}(d^3 +d^2\tau)$ bits.
\end{lemma}
The following result demonstrates that, for any polynomial system \(\mathcal{P}\) over a finite domain \(D\), polynomial-size \(\sos\) proofs can be constructed to establish that the variables are bounded.
\begin{lemma}\label{lemma-new-t}
    There exists a positive rational number $t>\max_{i\in [2k]}\{2,|\rho_i|\}$ that can be encoded with ${O}(k\beta)$ bits such that there exist $\sos$ proofs of degree $2k$
    \begin{align}
        t-x = \sum_{i=1}^{2k+3}a_iq_i^2 - D_{2k}(x), \\
        t+x = \sum_{i=1}^{2k+3}\tilde{a_i}\tilde{q}_i^2 - D_{2k}(x),
    \end{align}
 for some rational constants $a_i$ and some polynomials $q_i$ with rational coefficients. All coefficients in this representations can be encoded with $poly(k,\beta)$ bits.
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 13}\end{proof}

The results of \cref{lemma-new-t} and \cref{prop:bounded_variables_archimedeanity} allow us to conclude that any polynomial system over a finite domain is explicitly Archimedean.
\begin{proposition}\label{prop:finite-archi}
    Let $\mathcal{P}$ be a polynomial system over a finite domain $D$. Then, $\mathcal{P}$ is explicitly Archimedean.
\end{proposition} 




\subsection{Approximate simulation of \PC\ by \sos}\label{sect:proof_sos_sim_PC}


Berkholz~\cite{berkholz18} related different approaches for proving the unsatisfiability of a system of real polynomial equations. Over Boolean variables, he showed that SoS simulates $\PC$ refutation: any \(\PC\) refutation of degree \(d\) can be converted into an \(\sos\) refutation of degree \(2d\), with only a polynomial increase in size.
In the non-Boolean setting, there are systems of equations that are easier to refute for $\PC$ than for SoS \cite{GrigorievV01}. Grigoriev and Vorobjov \cite{GrigorievV01} show that the simulation of $\PC$ by SoS does not hold in the non-Boolean case, namely when the Boolean axioms $x_j^2-x_j=0$ are omitted. For example, the so-called telescopic system of equations, $\{ yx_1=1, x_1^2=x_2, \ldots, x_{n-1}^2=x_n, x_n=0\}$, has a $\PC$ refutation of degree $n$, but it requires exponential refutation degree in SoS \cite{GrigorievV01}.
However, it is not known if SoS can simulate $\PC$ in the (non-Boolean) general domain setting, namely when variables can take values from a general finite set of values. 
In this section, we address the existing knowledge gap by extending Berkholz's result to general domains. This complements the results in~\cite{GrigorievV01,berkholz18}.
Recall that we are considering a polynomial systems of the form 
\begin{equation}
    \F=\{f_1=0,\ldots,f_m=0\} \cup \Do=\{D_{2k}(x_j)=0\mid j\in[n]\}
\end{equation}
over variables $x_1,\ldots,x_n$. We prove the following \cref{th:sos_sim_PC_1}, which is a generalization of (\cite[Lemma 1]{berkholz18}). The overall structure of the proof partially follows from the one in \cite{berkholz18} but with some significant differences that will be emphasized below in the proof (see Case~4).








\begin{lemma}\label{th:sos_sim_PC_1}
    Let $(r_1, r_2, \dots r_L)$ be a \PC\ derivation from $\mathcal{F}\cup \mathcal{D}$ of degree $d$ and size $S$. Then, for every $H\leq L$ there exists an $\sos$ proof of $-(r_H)^2$ of degree $2(d+k-1)$ of the following form
    \begin{equation}\label{eq:sosstep}
         \sum_{i=1}^m (-a_i f_i) f_i + \sum_{j=1}^{n} q_j D_{2k}(x_j) +\sum_{j=1}^{m_1} c_{j}(p_{j})^2=-(r_H)^2,
    \end{equation}
    such that:
    \begin{itemize}
        \item $m_1$ is constant bounded by $O(k, H)$,
        \item $a_i, c_j$ are nonnegative constants, and $q_j$ (for $j\in [n])$, $p_j$ (for $j\in [m_1]$) are polynomials,
        
        \item all coefficients in the proof can be encoded with $poly(k, \beta, S)$ bits.
    \end{itemize}
\end{lemma}

\begin{proof}\textcolor{red}{TOPROVE 14}\end{proof}

\begin{remark}[Finite domains of odd size]
    The result of Lemma~\ref{th:sos_sim_PC_1} extends to domains with an odd number of elements. Specifically, if the domain D has size $|D| = |{\rho_1, \rho_2, \ldots, \rho_{2k - 1}}| = 2k - 1$, the same conclusion follows. To show this, we employ the same proof strategy as used in Cases 1, 2, and 3. However, in Case 4, instead of the domain polynomials defined as
    \begin{align*}
        D_{2k-1}(x_i) = (x_i - \rho_1)\cdots(x_i - \rho_{2k-1}),
    \end{align*}
    one can consider a modified set of polynomials, denoted by $\tilde{D}$, where each polynomial is defined as
    \begin{align*}
        \tilde{D}_{2k-1}(x_i) = (x_i - \rho_1)^2(x_i - \rho_2)\cdots(x_i - \rho_{2k-1}).
    \end{align*}
    Here, one root is repeated to ensure an even degree for the polynomials in $\tilde{D}$. With this adjustment, the same arguments apply, yielding an SoS proof from $\mathcal{F} \cup \mathcal{D} \cup \tilde{\mathcal{D}}$, and hence from $\mathcal{F} \cup \mathcal{D}$, of degree $2(d + k - 1)$.
\end{remark}

\begin{remark}
   In the previous result, we highlighted the dependence of the coefficients present in the $\sos$ proof on the parameter $\beta$. Recall that $\beta$ corresponds to the number of bits needed to encode the coefficients of the polynomials $D_{2k}(x)$ and its roots $\rho_1, \dots, \rho_{2k}$. This parameter can be eliminated and implicitly linked to the size of the $\PC$ proof $S$. Specifically, it suffices to assume that the $\PC$ proof begins by deriving all the polynomials $D_{2k}(x_j)$ for $j \in [n]$.
\end{remark}

While \cref{th:sos_sim_PC_1} immediately establishes a simulation of $\PC$ by $\sos$ as \emph{refutation} systems, it remains unclear whether $\sos$ can also simulate $\PC$ as a \emph{derivation} system. Specifically, the existence of an $\sos$ proof of $``-r^2 \geq 0"$ does not immediately guarantee the existence of an $\sos$ proof of $``\pm r \geq 0"$. Further, it is not hard to find polynomial systems for which the latter does not hold. Consider the simple polynomial system $\{ x^2\}$ from which it is trivial to derive $``-x^2 \geq 0"$. However, there are no $\sos$ proofs of $``\pm x \geq 0"$ from such premise.

Interestingly, by the use of $\sos$ approximability techniques developed in \cref{sect:SOS_completeness}, we are able to work around and resolve this issue. Provided that, given a statement derived by $\PC$ $``r = 0"$, an (arbitrarily) small approximation $\varepsilon$ of the statement is allowed, the simulation holds. That is, there exist $\sos$ proofs of $`` r + \varepsilon \geq 0"$ and of $``- r + \varepsilon \geq 0"$.

\begin{theorem}\label{th:sospc}
    $\sos$ \emph{approximates} $\PC$ with degree linear in the domain size $k$ over general finite domains. That is, if there exists a \(\PC\) derivation of \( ``r=0" \) with degree \( d \) and size \( S \), then for every \( \varepsilon > 0 \), we have \(\sos\) proofs of \( ``r+\varepsilon \geq 0" \) and \( ``-r+\varepsilon \geq 0" \) with degree \( O(d+k) \) and coefficients bounded by \( 2^{\text{poly}(k, S, \lg \frac{1}{\varepsilon})} \).
\end{theorem}

\begin{proof}\textcolor{red}{TOPROVE 15}\end{proof}

\subsection[PC criterion]{$\PC$ criterion}\label{sect:pc_crit}

In this section we show that, within the context of finite domains, \cref{th:sos_sim_PC_1} can be combined with the $\sos_{\varepsilon}$ criterion to formulate a new criterion, called \emph{\PC\ criterion}, based on the \PC\ proof system. 
While, in general, \PC\ is weaker than \sos\ as a proof system, it naturally connects to the theory of \GB basis, in particular to Buchberger's algorithm for their computation (see \cite{BuchbergerThesis}).
As we will see in \cref{sect:applications}, this connection enables the application of the \PC\ criterion to certain families of problems arising from $\CSP$s, for which the \Nsatz\ criterion is not satisfied.

\begin{theorem}[PC criterion]\label{th:PC_criterion}
    Let $\mathcal{P} = \{p_1 = 0, \dots, p_m = 0\}$ polynomial system over a finite domain $D$ of $2k$ rational values, let $S=\Variety{\mathcal{P}}$ be its variety and let $r\in\mathbb{R}[x_1, \dots, x_n]$ be a polynomial nonnegative over $S$. Assume there exists an $\sos$ proof of $``r\geq 0"$ from $\mathcal{P}$ of degree $2d$
  \begin{equation*}
        r = \sum_{i=1}^{t_0} \sigma_i^2 + \sum_{i=1}^m h_i p_i.
    \end{equation*}
   Let $\mathcal{G}_{2d}$ be a $2d$-truncated \GB basis of $I(S)$ according to the $\grlexns$ order such that $\|\mathcal{G}_{2d}\|_{\infty}\leq 2^{poly(n^d)}$. Assume that, for every $g\in \mathcal{G}_{2d}$, there exist a $\PC$ derivation of $g$ from $\mathcal{P}$ of size $poly(n^d)$ and degree $O(d)$. Then, for every $\varepsilon>0$, the polynomial $``r+\varepsilon \geq 0"$ has a degree-$O(d)$ $\sos$ proof
    \begin{equation*}
        r +\varepsilon = \sum_{i=1}^{t} \tilde{\sigma}_i^2 + \sum_{i=1}^m \tilde{h}_i p_i,
    \end{equation*}
    where the coefficients of every polynomial appearing in the proof are bounded by $2^{poly(n^d, \lg \frac{1}{\varepsilon})}$.   
\end{theorem}
\begin{proof}\textcolor{red}{TOPROVE 16}\end{proof}

\section{Strong Separation for certain Constraint Satisfaction Problems}\label{sect:applications}
In what follows, we establish \cref{th:semilattice+dualdiscr} by demonstrating and utilizing the ability of \(\sos\) to approximate a dynamic proof system, such as \PC\ (see \cref{th:sospc}).
 In light of \cref{th:PC_criterion}, it is sufficient to show that $\PC$ can solve in polynomial time $\IMP_d(\Gamma)$ when $\Gamma$ is a finite constraint language closed under a semilattice polymorphism (see \cref{th:semilattice}), and in the case it is closed under a dual-discriminator polymorphism (see \cref{th:dual_discriminator}). 
The degree lower bound for \Nsatz\ given in \cite{BussP98}, along with the results of this section, and \cref{th:PC_criterion} gives the claimed separation among the $\sos_{\varepsilon}$ and $\Nsatz$ criteria. 

The structure of the following sections is outlined as follows. The literature review, along with essential background and notation, is presented in \cref{sect:csp_literature} and \cref{sect:CSP_IMP_background}, respectively. The proofs of \cref{th:semilattice} and \cref{th:dual_discriminator} are provided in \cref{sect:semilattice-proof} and \cref{sect:dual-proof}, respectively.
\subsection{Related results} \label{sect:csp_literature}
In \cite{Mastrolilli21TALG, BharathiM21}, Mastrolilli and Bharathi initiated a systematic study of the IMP$_d$ tractability for combinatorial ideals arising from Constraint Satisfaction Problems $\CSP(\Gamma)$ in which the type of constraints is restricted to relations from a set $\Gamma$ over the Boolean domain.
Note that $\CSP(\Gamma)$ is just the special case of not-$\IMP_0(\Gamma)$ with $r=1$.
The main results of \cite{Mastrolilli21TALG, BharathiM21} identified the borderline of tractability of $\IMP_d(\Gamma)$ for languages $\Gamma$ over the Boolean domain. By using \GB bases techniques, they expanded Schaefer's dichotomy theorem \cite{Schaefer78} which classifies all CSPs of the form $\CSP(\Gamma)$ over the Boolean domain to be either in P or NP-complete. Recently, Bulatov and Rafiey \cite{BulatovRSTOC22, BulatovRSTACS22} continued this line of research by extending \cite{Mastrolilli21TALG, BharathiM21} beyond Boolean domains in several ways. 

With the aim of expanding the class of $\IMP_d(\Gamma)$s tractable by $\PC$, we observe that some of the algorithms that are considered in \cite{BulatovRSTOC22, BulatovRSTACS22, Mastrolilli21TALG, BharathiM21} for solving the $\IMP_d(\Gamma)$ are known to not being simulable by $\PC$ and by $\sos$.  For example, when $\Gamma$ is closed under the minority polymorphism, in \cite{BharathiM21} it is shown that the membership proof for $\IMP_d(\Gamma)$ can be computed in $n^{O(d)}$ time for any $d\in \mathbb{N}$.
Note that \textsc{3Lin(2)} is a special case of this class of problems. However,  linear (thereby, sharp) lower bounds on degrees for $\sos$ refutations are known \cite{GRIGORIEV2001613} for \textsc{3Lin(2)}.
It follows that bounded degree $\sos$ and $\PC$ over the reals cannot simulate the algorithm in \cite{BharathiM21}. 
The approach in \cite{BharathiM21} has been generalized by \cite{BulatovRSTOC22} by showing that constructing a $d$-truncated \GB Basis for an ideal $\I$ is reducible to solving $\chi\IMP_d$ for the ideal $\I$ (see \cite{BulatovRSTOC22} for details). With this reduction at hand, they designed a general algorithmic approach,
inspired by the famous FGLM algorithm \cite{FAUGERE1993329} and the conversion algorithm in \cite{BharathiM21}, to construct $d$-truncated \GB Basis for many combinatorial ideals, in particular, combinatorial ideals arising from languages invariant under a semilattice, or the dual-discriminator, or languages expressible as linear equations over $GF(p)$. In light of the impossibility result for the particular case of \textsc{3Lin(2)} discussed earlier, the general approach presented by \cite{BulatovRSTOC22}, which also works for \textsc{3Lin(2)}, cannot in general be simulated by $\PC$.

In \cref{sect:applications}, we complement the aforementioned impossibility result with some positive results. 
More precisely, we show that $\PC$ is powerful enough to solve $\IMP_d(\Gamma)$ when $\Gamma$ is closed under a semilattice polymorphism or the dual discriminator. 
As a result of the aforementioned considerations, our approach differs fundamentally from the general methodology employed in \cite{BulatovRSTOC22} (see also the discussion in \cref{rm:semilattice}).


Furthermore, strategies in \cite{BharathiM21,BulatovRSTOC22,BulatovARXIV21, Mastrolilli21TALG} to address the problem of \sos\ bit complexity involve replacing the original input polynomial constraints \(\mathcal{P}\) (see \cref{def:SOS_proof}) with a new set of polynomials $\mathcal{P}^{(d)}$ that satisfies the \(\Nsatz\) criterion, and generally depends on the \sos\ degree \(d\). This set $\mathcal{P}^{(d)}$ is computed externally (by an algorithm specifically designed for this purpose), serving as the input for \(\sos\) in place of $\mathcal{P}$. For example, in the semilattice case, if $\mathcal{P}$ consists of $m$ polynomials, the set $\mathcal{P}^{(d)}$, used in \cite{BulatovRSTOC22,Mastrolilli21TALG}, is generated by a specific algorithm and has a size of \( m^{O(d)} \); that is, $\mathcal{P}^{(d)}$ depends on \( d \) and grows exponentially with the \(\sos\) degree \( d \). This preprocessing step ensures that \(\sos\) retains ``low`' bit complexity, but only if $\mathcal{P}$ is substituted with $\mathcal{P}^{(d)}$. Essentially, the approach utilized in \cite{BharathiM21,BulatovRSTOC22,BulatovARXIV21, Mastrolilli21TALG} is to apply the \(\Nsatz\) criterion without enhancing or extending it, with the goal of replacing the initial input polynomial system with a new one that is computed externally and satisfies the \Nsatz\ criterion.
Our results demonstrate that all preprocessing steps employed in \cite{BharathiM21,BulatovRSTOC22,Mastrolilli21TALG} are unnecessary, as \(\sos\) achieves low bit complexity for any fixed \( d \) when \(\mathcal{P}\) is provided directly as input.



\subsection[Background and notation for CSP's]{Background and notation for \(\CSP(\Gamma)\)}\label{sect:CSP_IMP_background}
In this section we give the basic definitions and results that we will need later.
We refer to~\cite{barto_et_al:DFU:2017:6959,2017dfu7,Chen09, Mastrolilli21TALG, BulatovRSTOC22} for more details.

Let $D$ denote a finite set called the  \textbf{\emph{domain}}.
By a $k$-ary \textbf{\emph{relation}} $R$ on a domain $D$ we mean a subset of the $k$-th cartesian power $D^k$; $k$ is said to be the \textbf{\emph{arity}} of the relation. We often use relations and (affine) varieties interchangeably since both are subsets of $D^k$ (we will not refer to varieties from universal algebra in this paper). A \textbf{\emph{constraint language}} $\Gamma$ over $D$ is a set of relations over $D$. A constraint language is \textbf{\emph{finite}} if it contains finitely many relations, and is \textbf{\emph{Boolean}} if it is over the two-element domain $\{0,1\}$. 

A \emph{\textbf{constraint}} over a constraint language $\Gamma$ is an expression of the form $R(x_{i_1},\ldots, x_{i_k})$ where $R$ is a relation of arity $k$ contained in $\Gamma$, and $x_{i_1},\ldots, x_{i_k}$ are variables that belong to the variable set $X$. A constraint is satisfied by a mapping $\phi$ defined on the variables if $(\phi(x_{i_1}),\ldots, \phi(x_{i_k}))\in R$.

\begin{definition}\label{def:csp}
 The \emph{(nonuniform) \textsc{Constraint Satisfaction Problem} ($\CSP$)} associated with language $\Gamma$ over $D$ is the problem $\CSP(\Gamma)$ in which: an instance is a triple $\Cc=(X,D,C)$ where $X=\{x_1,\ldots,x_n\}$ is a set of $n$ variables and $C$  is a set of constraints over $\Gamma$ with variables from $X$. The goal is to decide whether or not there exists a solution, i.e. a mapping $\phi: X\rightarrow D$ satisfying all of the constraints. We will use $Sol(\Cc)\subseteq D^n$ to denote the set of solutions of $\Cc$.
\end{definition}
Moreover, we follow the algebraic approach to Schaefer's dichotomy result \cite{Schaefer78} formulated by Jeavons \cite{JEAVONS1998185} where each class of CSPs that are polynomial time solvable is associated with a polymorphism.
Recall that a polymorphism of a constraint language $\Gamma$ over a set $D$ is a multi-ary operation on $D$ that can be viewed as a multidimensional symmetry of relations from $\Gamma$ (see e.g.~\cite{barto_et_al:DFU:2017:6959}).
\begin{definition}\label{def:polymorph}
An operation $f:D^m \rightarrow D$ is a \textbf{polymorphism} of a relation $R\subseteq D^k$ if for any choice of $m$ tuples $(t_{11},\dots,t_{1k}),\dots,(t_{m1},\dots,t_{mk})$ from $R$ (allowing repetitions), it holds that the tuple obtained from these $m$ tuples by applying $f$ coordinate-wise, $(f(t_{11},\dots,t_{m1}),\dots,f(t_{1k},\dots,t_{mk}))$, is in $R$. We also say that $f$ \textbf{preserves} $R$, or that $R$ is \textbf{invariant} or \textbf{closed} with respect to $f$. A polymorphism of a constraint language $\Gamma$ is an operation that is a polymorphism of every $R\in \Gamma$. By $\Pol(\Gamma)$ we denote the set of all polymorphisms of $\Gamma$. 
\end{definition}




\subsubsection[The ideal membership problem of a constraint language IMP(Gamma)]{The ideal membership problem of a constraint language $IMP(\Gamma)$}\label{sec:IMPdef}


The polynomial \textsc{Ideal Membership Problem} (\IMP) is the following computational task.
Let $\Field[x_1, \ldots, x_n]$ be the ring of polynomials over the field $\Field$ and indeterminates $\{x_1,\ldots, x_n\}$ ordered according to the \grlex order (see \cref{sect:prelim}).
Given $f_0,f_1,\ldots,f_r\in \Field[x_1, \ldots, x_n]$ we want to decide if $f_0\in \I= \GIdeal{f_1,\ldots, f_r}$, where $\I$ is the ideal generated by $F=\{f_1,\ldots , f_r\}$.
If the ideal $\I$ corresponds to a $\CSP$ instance we can be specific on its structure. 
Here, we explain how to construct an ideal corresponding to a given CSP($\Gamma$) instance $\Cc$ by following \cite{Mastrolilli21TALG}. Constraints are in essence varieties (see e.g.~\cite{vandongenPhd,JeffersonJGD13}). 
\begin{definition}\label{def:combinatorial_ideal}
For any given $\CSP(\Gamma)$ instance $\Cc=(X,D,C)$, the \textbf{\emph{combinatorial ideal}} 
\begin{align}\label{eq:comb_Id}
    \I_\Cc=\langle f_{R_1}(X_{R_1}),\ldots,f_{R_\ell}(X_{R_\ell}),f_D(x_1),\ldots,f_D(x_n)\rangle
\end{align} 
is defined as the vanishing ideal of the set $Sol(\Cc)$ and it is constructed as follows.
\begin{itemize}
    \item For every $x_i\in X$ the ideal $I_\Cc$ contains a domain polynomial $f_D(x_i)$ whose zeroes are precisely the elements of the domain $D$.
    \item For every constraint $R_j(X_{R_j})\in C$, where $X_{R_j}$ is a tuple of variables from $X$, the ideal $\I_\Cc$ contains a polynomial $f_{R_j}(X_{R_j})$ such that for $X_{R_j}\in D^{|X_{R_j}|}$ it holds $f_{R_j}(X_{R_j})=0$ if and only if $R_j(X_{R_j})$ is true.
\end{itemize}   
\end{definition}
  See \cite{Mastrolilli21TALG} for more details and properties. 
\begin{definition}\label{def:IMP}
 The {\emph{\textsc{Ideal Membership Problem}}} associated with language $\Gamma$ is the problem $\IMP(\Gamma)$ in which
 the input consists of a polynomial $f\in \Field[x_1, \ldots, x_n]$ and a $\CSP(\Gamma)$ instance $\Cc=(X,D,C)$ where $D\subset \Field$. The goal is to decide whether $f$ lies in the combinatorial ideal~$I_\Cc$. We use $\IMP_d(\Gamma)$ to denote $\IMP(\Gamma)$ when the input polynomial $f$ has degree at most $d$.
\end{definition}

Ideal membership testing can be performed by means of \GB bases. Indeed, if we can compute the $d$-truncated \GB basis $\mathcal{G}_d$ of $\I_\Cc$ in $n^{poly(n^d)}$ time, then we can solve $\IMP_d(\Gamma)$ in polynomial time (see \cref{sect:prelim}).


As in the case of the CSP, polymorphisms of $\Gamma$ are what determines the complexity of $\IMP_d(\Gamma)$ (see \cite{Mastrolilli21TALG,BharathiM21, BulatovRSTOC22}). 
 


\subsection{Polynomial Calculus and semilattice polymorphism}\label{sect:PCsemilattice}


We consider the complexity of $\IMP_d(\Gamma)$ for constraint languages $\Gamma$ closed under a \emph{semilattice} operation $\psi$ (either meet or join). 
There are two kinds of semilattice operations (see e.g.~\cite{Davey_Priestley_2002}). A \emph{join}-semilattice, also known as an \emph{upper}-semilattice, refers to a partially ordered set that possesses a \emph{join} (or least upper bound) for every nonempty finite subset. Conversely, a \emph{meet}-semilattice, or \emph{lower}-semilattice, is a partially ordered set characterized by having a \emph{meet} (or greatest lower bound) for any nonempty finite subset. 
Algebraically, semilattices can be defined {as pairs $\mathcal{D} = (D,\phi)$, where $D$ is a domain and $\phi$ is the semilattice operation \textit{join} or \textit{meet}. Note that both operations are associative, commutative and idempotent binary operations.} 

In the following, we show that standard $\PC$ is $d$-complete and efficient for constraint languages that are closed under a semilattice polymorphism. Our result greatly simplifies known approaches \cite{BulatovRSTOC22, Mastrolilli21TALG} and unifies them into one simple
PC-based algorithm. Further details explaining the substantial differences with what is already known are given and discussed in \cref{rm:semilattice}. 
Our main technical result is as follows.
\begin{theorem}\label{th:semilattice}
Let $\Gamma$ be a finite constraint language over a domain $D$. Consider an instance $\Cc$ of $\CSP(\Gamma)$. If $\Gamma$ is closed under a semilattice polymorphism, then $O(d)$-degree \PC\  can compute in $n^{O(d)}$ time the reduced $d$-truncated \GB basis $\mathcal{G}_d$ (in \grlex order) of the combinatorial ideal $I_\Cc$, for any degree $d \in \mathbb{N}$ and where $n$ is the number of variables.
\end{theorem}
\begin{proof}\textcolor{red}{TOPROVE 17}\end{proof}
\cref{th:semilattice} in conjunction with \cref{th:PC_criterion} implies \cref{th:semilattice+dualdiscr} for semilattice structures.


\subsection{Polynomial Calculus and dual discriminator polymorphism}\label{sect:PCdual}
We consider the complexity of $\IMP_d(\Gamma)$ for constraint languages where the dual discriminator operation is a polymorphism of $\Gamma$. 
The dual discriminator is a well-known majority operation \cite{Jeavons:1997:CPC,barto_et_al:DFU:2017:6959} and is often used as a starting point in many $\CSP$ related classifications \cite{barto_et_al:DFU:2017:6959}. For a finite domain $D$, a ternary operation $f$ is called a majority operation if  $f(a,a,b)=f(a,b,a)=f(b,a,a)=a$ for all $a,b\in D$. The \emph{dual discriminator} $\nabla$ on a domain $D$, is a majority operation such that $\nabla(a,b,c)=a$ for pairwise distinct $a,b,c\in D$.

In \cite{BulatovRSTOC22} it is shown that $\IMP_d(\Gamma)$ is solvable in polynomial time for any fixed $d$. The work in \cite{BharathiM21} complements the result in \cite{BulatovRSTOC22} by proving that the \textit{full} (as opposed to \textit{truncated}) \GB basis in graded lexicographic order can be computed in polynomial time and with bounded degree, thus proving polynomial time efficiency for solving the general $\IMP(\Gamma)$ (see also \cref{sect:PC_bit}).

In the following, we again show the power of the $\PC$ by demonstrating that the ad hoc algorithm presented in \cite{BharathiM21} is simulable by $\PC$. 
This greatly simplifies previous algorithms \cite{BulatovRSTOC22, BharathiM21, BharathiM22} and provides another family of problems for which the $\sos_{\varepsilon}$ criterion is provably stronger than the $\Nsatz$ criterion.
Our main technical result is as follows.
\begin{theorem}\label{th:dual_discriminator}
    Let $\Gamma$ be a finite constraint language over a domain $D$. Consider an instance $\Cc$ of $\CSP(\Gamma)$. If $\Gamma$ is closed under a dual discriminator polymorphism, then \PC\ can compute in $n^{O(1)}$ time the reduced \GB basis $\mathcal{G}$ (in \grlex order) of the combinatorial ideal $I_\Cc$, where $n$ is the number of variables and $|D|=O(1)$.
\end{theorem}
\begin{proof}\textcolor{red}{TOPROVE 18}\end{proof}
\cref{th:dual_discriminator}, along with \cref{th:PC_criterion}, implies \cref{th:semilattice+dualdiscr} for dual discriminator structures. 

\section{Proof of \cref{th:semilattice} }\label{sect:semilattice-proof}
We consider the complexity of $\IMP_d(\Gamma)$ for constraint languages $\Gamma$ where $\Pol(\Gamma)$ (see \cref{def:polymorph}) includes a \emph{semilattice} operation $\psi$ (either meet or join). 
There are two kinds of semilattice operations (see e.g.~\cite{Davey_Priestley_2002}). A \emph{join}-semilattice, also known as an \emph{upper}-semilattice, refers to a partially ordered set that possesses a \emph{join} (or least upper bound) for every nonempty finite subset. Conversely, a \emph{meet}-semilattice, or \emph{lower}-semilattice, is a partially ordered set characterized by having a \emph{meet} (or greatest lower bound) for any nonempty finite subset. Algebraically, semilattices can be defined {as pairs $\mathcal{D} = (D,\phi)$, where $D$ is a domain and $\phi$ is the semilattice operation \textit{join} or \textit{meet}. Note that both operations are associative, commutative and idempotent binary operations.} 
In mathematics, the symbol for the join (meet) operation in a semilattice is often denoted by the symbol $\vee$ ($\wedge$).
Any such operation induces a partial order ($\preceq$) (and its corresponding inverse order) in which the result of the operation for any two elements represents the least upper bound (or greatest lower bound) of those elements in relation to the established partial order.



The input to $\IMP_d(\Gamma)$ consists of any given set of polynomials that defines the combinatorial ideal $\I_\Cc$ (see \cref{def:combinatorial_ideal}) corresponding to a semilattice closed language $\Gamma$: 
\begin{align}\label{eqn:polynomial_constraints_CSPs}
    f_{R_1}(X_{R_1}),\ldots,f_{R_\ell}(X_{R_\ell}),f_D(x_1),\ldots,f_D(x_n).
\end{align} We want to show that $\PC$ is capable of computing the $d$-truncated \GB basis (in \grlex order) in polynomial time for any fixed $d$.

\paragraph{\cref{th:semilattice} proof outline.}\label{sect:semilattice_structure}
Schematically, \cref{th:semilattice} is proven by the following arguments:
\begin{enumerate}[(i)]
    \item First we prove \cref{th:semilattice} for the Boolean case, where the domain $D = \{0,1\}$.
    That is, we show that bounded-degree $\PC$ computes the $d$-truncated \GB basis for the Boolean domain. The known \cite{Mastrolilli21TALG} algorithm to efficiently compute the $d$-truncated \GB basis consists of ``guessing'' the truncated \GB basis in polynomial time. Here, the main technical difficulty is that this guessing ``trick'' is not immediately simulable in an efficient way by \PC. We show that the latter is possible. The algorithm in \cite{Mastrolilli21TALG} essentially reduces the \IMP\ for a given polynomial $f$ in the $2d$-truncated \GB basis to the (contrapositive) problem of checking whether ``non-vanishing assignments" of variables for $f$ belong to the variety. In this work, we are able to $\PC$-derive $f$ by polynomially formulating ``non-vanishing assignments" into an infeasible system of Horn-type polynomials. We then combine algebraic and logical reasoning, leading us to efficient \PC\ refutations of the new system by means of simulation of refutation proofs. By accurately using the \PC\ ability for refutation, we can then retrieve a \PC\ derivation of $f$. This technique may be of independent interest.
    \item We reduce the general case (with arbitrary finite domain $D$) to the Boolean case. The reduction is achieved by encoding the domain $D$ using strings over $\{0,1\}$. The encoding is given by a novel bijective map that preserves the semilattice structure. The strength of our bijection is that it ensures a one-to-one correspondence between the solution spaces of the original $\CSP$ over $D$ and the reduced Boolean problem, which allows us to reduce the (search version of) $\IMP_d(\Gamma)$ to the (search version of) $\IMP_{O(d)}(\Gamma^{01})$, where $\Gamma^{01}$ is a Boolean constraint language derived from $\Gamma$. Crucially, the preservation of the semilattice structure ensures that $\IMP_{O(d)}(\Gamma^{01})$ remains solvable in polynomial time by $\PC$.
 
\end{enumerate}

More details on the second point are given below.

\begin{enumerate}
    \item Show that any instance $\Cc = (X,D,C)$ of $\CSP(\Gamma)$ is reducible to an instance $C^{01}$ of $\CSP(\Gamma^{01})$, where $\Gamma^{01}$ is a finite constraint language over $\{0,1\}$ and so that there exists a $\phi \in \Pol(\Gamma^{01})$ that is a semilattice ($\Min$ or $\Max$ polymorphisms) (see \cref{sect:mapping2bool}). The idea is that we can "encode" $\Cc$ in binary and that the encoding function is invertible (see \cref{sect:binencoding}).
    \item Show $\IMP_d(\Gamma)$ is reducible to $\IMP_{\uval d}(\Gamma^{01})$, where $\Gamma^{01}$ is a constraint language over the Boolean domain $\{0,1\}$ and there exists a semilattice $\phi \in \Pol(\Gamma^{01})$ ($\Min$ or $\Max$ polymorphism) (see \cref{sect:2Bool}). In addition, the reduction ensures that the varieties in the two different domains are in one-to-one correspondence.
    \item By \cref{th:2semilattice}, we can solve $\IMP_{\uval d}(\Gamma^{01})$ by bounded-degree $\PC$.
    \item Our reduction guarantees that we can recover a bounded-degree $\PC$ proof in the finite domain from the bounded-degree $\PC$ proof over the Boolean domain (see \cref{sect:mappingBack}). More precisely, we show how $\PC$ proofs of degree $\uval d$ in the Boolean domain translate into the $\PC$ proofs of degree $O(d)$ in the finite domain, thus proving \cref{th:semilattice}.
\end{enumerate}

\begin{remark}\label{rm:semilattice}
We emphasize that a reduction to the Boolean domain case has also been used to prove that the decision version of $\IMP_d(\Gamma)$ is tractable for such constraint languages $\Gamma$ (see \cite[Th. 5.10]{BulatovRSTOC22} for more details). However the mapping used in \cite{BulatovRSTOC22} is by the means of pp-interpretability (see \cite{DonaPapert1964}), and it is not guaranteed that one can recover proofs for the finite domain under this reduction. In particular, the very first obstacle is given by the fact the mapping $\pi$ in the definition of pp-interpretability \cite[Def.~3.12]{BulatovRSTOC22} is not guaranteed to be a bijection. In fact, this difficulty of transforming the Boolean case proof to the finite general domain case led to the development of a specific method \cite[Th.~6.5]{BulatovRSTOC22} for the search version of the problem. Moreover, as previously noted at the beginning of \cref{sect:applications}, it is far from evident that it can be simulated by $\PC$. In the following, we show that the standard bounded-degree $\PC$ approach is sufficient. This simplifies known approaches and unifies them into one simple $\PC$-based approach.
\end{remark}

\subsection[Min/Max polymorphisms]{$\Min$/$\Max$ polymorphisms}






Two important classes of polymorphisms that played a fundamental role in the celebrated dichotomy theorem by Schaefer~\cite{Schaefer78} are the $\Min/\Max$ polymorphisms. In fact, $\Min$ ($\Max$) is a polymorphism of the (dual) problem \textsc{Horn-SAT} \cite{JEAVONS_TRACTABLE_CONSTRAINTS}. A Boolean language $\Gamma$ is invariant under semilattice operations given by (component-wise) the $\Max$ operation (logical \emph{OR}) or the $\Min$ operation (logical \emph{AND}). The semilattice polymorphism is a well-known generalization of $\Min/\Max$ polymorphisms for the general finite domain.
In this section we show that $\PC$ is $d$-complete and efficient for polynomial systems that are closed with respect to the $\Min$ polymorphism (a similar proof holds for $\Max$). 

















In the remainder of this section we focus on system of polynomials $C_1,\ldots, C_m$ that are $\Min$ closed, namely each polynomial constraint $C_i$, along with domain polynomials, has solutions that are closed with respect to the $\Min$ polymorphism. These polynomials are defined in \cref{def:combinatorial_ideal}.



\subsubsection[Min polymorphism]{$\Min$ polymorphism}


We will make use of the following definition from \cite{Mastrolilli21TALG}.
\begin{definition}\label{def:2terms}
  For a given set $X=\{x_1,\ldots,x_n\}$ of variables and for any set $S\subseteq [n]$ possibly empty, $\alpha\in \{0, \pm 1\}$, let a \textbf{\emph{term}} be defined as \footnote{The empty product has the value 1.}
  \begin{align*}
    \tau^+(S)&\mydef \alpha\prod_{i\in S}x_i, \quad \textsc{*positive term*} \\
    \tau^-(S)&\mydef\alpha\prod_{i\in S}(x_i-1). \quad \textsc{*negative term*}
  \end{align*}
For $S_1,S_2\subseteq [n]$ and $i\in [n]$, let a \textbf{\emph{2-terms polynomial}} be a polynomial that is the sum of two terms or it is $\pm(x_i^2-x_i)$.
We say that a set $G$ of polynomials is \textbf{\emph{2-terms structured}} if each polynomial from $G$ is a 2-terms polynomial.

  We further distinguish between the following special 2-terms polynomials:
  \begin{align*}
    \T^+ & \mydef \{\tau^+(S_1)+\tau^+(S_2)\mid S_1,S_2\subseteq[n]\} \cup\{\pm(x_i^2-x_i)\mid i\in [n]\},  \quad \textsc{*positive 2-terms*}\\
    \T^- & \mydef \{\tau^-(S_1)+\tau^-(S_2)\mid S_1,S_2\subseteq[n]\} \cup\{\pm(x_i^2-x_i)\mid i\in [n]\}. \quad \textsc{*negative 2-terms*}
  \end{align*}
  \end{definition}


\begin{remark}
$\Gamma$ is a finite language. It follows that each given polynomial constraint $C_i$ (as defined in \cref{def:combinatorial_ideal}) has a constant number of feasible solutions.
Therefore \PC\ can efficiently derive any polynomial vanishing over the solutions of $C_i$, and in particular it can derive any vanishing $2$-term polynomial.
\end{remark}


\begin{lemma}\label{th:Min}
If $\Min\in\Pol(\Gamma)$ then $\PC$ can compute the truncated reduced \GB basis $\mathcal{G}_d$ in $n^{O(d)}$ time (where $n$ is the number of variables), for any degree $d\in \mathbb{N}$.
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 19}\end{proof}
\begin{lemma}\label{th:MiNVA_sos}
If $f=p-q$ belongs to $\mathcal{G}_d$ then the following polynomials 
\begin{equation}\label{MINVA1}
    {p_j = p(x_j-1) \quad \forall j \in Q, \quad q_i = q(x_i-1) \quad \forall i \in P}
\end{equation}
belong to the combinatorial ideal $\I_\Cc$ and there is a $O(d)$-PC proof of this fact.
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 20}\end{proof}


\begin{lemma}\label{th:f_sos}
If $f=p-q$ belongs to $\mathcal{G}_d$, then $f=0$ admits a degree-$O(d)$ $\PC$ proof.
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 21}\end{proof}
By symmetric arguments we obtain the following.
\begin{lemma}\label{th:Max}
If $\Max\in\Pol(\Gamma)$ then $\PC$ can calculate the reduced truncated basis \GB $\mathcal{G}_d$ in $n^{O(d)}$ time (where $n$ is the number of variables), for any degree $d\in \mathbb{N}$.
\end{lemma}
\begin{corollary}\label{th:2semilattice}
    Let $\Gamma$ be a finite constraint language over $\{0, 1\}$ that is closed under  a 2-element semilattice operation polymorphism. Then $\PC$ can compute the reduced truncated \GB basis $\mathcal{G}_d$ in $n^{O(d)}$ time (where $n$ is the number of variables), for any degree $d\in \mathbb{N}$.
\end{corollary}



\subsection{Generalizing to finite domain semilattice}
In the following, we generalize \cref{th:2semilattice} to constraint languages over finite domains that are closed under a semilattice polymorphism and obtain the proof of \cref{th:semilattice}. We begin by recalling the definition of semilattice operations. We then present the main arguments used to prove \cref{th:semilattice}, followed by their details.

\subsubsection{Binary encoding}\label{sect:binencoding}
{Let} $\mathcal{D} = (D,\psi)$ {be} a semilattice{, with} $\psi$ {being} a semilattice polymorphism (see \cref{def:polymorph}) of the constraint language $\Gamma$.
Then, it is known that $\mathcal{D}$ can be encoded in binary form in such a way that it is a subalgebra of $\mathcal{B}^k$ {for some $k \in \mathbb{N}$}, where $\mathcal{B} = (\{0, 1\}, \phi)$ is a 2-element semilattice \cite{DonaPapert1964}.
In the following we show how to encode the elements of $D$ in binary in a proper form such that (i) the just mentioned property \cite{DonaPapert1964} is satisfied, and (ii) it will allow us to recover proofs {over the finite domain $D$} from the Boolean domain, a property that is not guaranteed by the approach considered in \cite{BulatovRSTOC22}.
The encoding $\mu$ is very ``natural'' and it is described in the proof of the following lemma.\begin{lemma}\label{th:bin_encoding}
    Let $\mathcal{D} = (D,\psi)$ be a finite semilattice where $\psi$ is a meet-semilattice (join-semilattice) operation. Then there is a mapping $\mu:D\rightarrow \{0,1\}^{\uval}$ such that $\Min$ ($\Max$) is a polymorphism of {the Boolean relation} $D^{01}=\{\mu(d_1),\ldots,\mu(d_{|D|})\}$ and $\mu:D\rightarrow D^{01}$ is bijective.
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 22}\end{proof}





\subsubsection[Reducing CSP(Gamma) over a finite domain to the Boolean domain]{Reducing $\CSP(\Gamma)$ over a finite domain to the Boolean domain}\label{sect:mapping2bool}
By \cref{th:bin_encoding} we obtain the following.

\begin{lemma}\label{th:reduction_csp}
Let $\Gamma$ be a constraint language over $D$ that is closed with respect to a meet (join) semilattice operation. Let $\Gamma^{01}$ be the constraint language over $\{0,1\}$ that is obtained from $\Gamma$ by replacing the values from $D$ appearing in the relations from $\Gamma$ with their corresponding binary encoding, as given by the mapping $\mu$ in \cref{th:bin_encoding}. Then 
\begin{itemize}
    \item $\Min$ ($\Max$) is a polymorphism of $\Gamma^{01}$.
    \item Any given instance $\Cc=(X,D,C)$ of $\CSP(\Gamma)$ is polynomial time reducible to an instance $\Cc^{01}=(Y,\{0,1\},C^{01})$ of $\CSP(\Gamma^{01})$. Moreover, the solution sets $Sol(\Cc)$ and $Sol(\Cc^{01})$ are in one-to-one correspondence.  
\end{itemize} 
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 23}\end{proof}
\subsubsection[Reducing IMPd(Gamma) over a finite domain to the Boolean domain]{Reducing $\IMP_{d}(\Gamma)$ over a finite domain to the Boolean domain} \label{sect:2Bool}
In the reduction considered in \cref{th:reduction_csp}  every variable $x_i\in X$ is mapped to $\uval$ new binary variables $y_{i1},\ldots, y_{i\uval}$.
In the following we reduce $\IMP_{d}(\Gamma)$ to $\IMP_{\uval d}(\Gamma^{01})$. This reduction, along with its corresponding ``inversion'' (see \cref{sect:mappingBack}), will be used to prove \cref{th:semilattice}, as summarized in \cref{sect:semilattice_structure}.

\paragraph{The interpolating polynomial $\p$ in the Boolean domain.} 
By a straightforward generalization of Lagrange interpolating polynomials (see e.g. \cite{phillips2003interpolation}, \cite{Gasca2000-hx}), given $|D|$ distinct values  $\mu(d_1),\ldots,\mu(d_{|D|})\in \{0,1\}^{\uval}$ (see \cref{th:bin_encoding}) and corresponding values $d_1,\ldots, d_{|D|}$, there exists a polynomial $\p$ of degree at most $|D|-1$ that interpolates the data, i.e. $\p(\mu(d_i))=d_i$ for each $i=1,\ldots,|D|$.
\paragraph{A reduction to the Boolean domain.}
As in the proof of \cref{th:reduction_csp}, we want to map every variable $x_i\in X$ to a tuple of $\uval$ new binary variables $y_{i1},\ldots, y_{i\uval}$. Let $Y_i=y_{i1},\ldots, y_{i\uval}$ and $Y=\{Y_1,\ldots, Y_n\}$. \\
To guarantee that each tuple $Y_i$ assumes only values that correspond to valid encondings of elements in $D$, we consider the following ``low'' degree polynomial:
\begin{align*}
    \T(y_{1},\ldots, y_{\uval})=\prod_{v_1,\ldots,v_\uval\in D^{01}}(1-\prod_{j=1}^{\uval}(1-v_j+y_j))).
\end{align*}
Every $\T(Y_i)$ has degree $|D|\uval$. \\
For any given $\CSP(\Gamma)$-instance $\Cc=(X,D,C)$, the corresponding combinatorial ideal  (see \cref{def:combinatorial_ideal})  
\begin{align}
    \F&=\{f_{R_1}(x_{1_{R_1}}\ldots,x_{k_{R_1}}),\ldots,f_{R_\ell}(x_{1_{R_\ell}}\ldots,x_{k_{R_\ell}}),f_D(x_1),\ldots,f_D(x_n)\} \label{eq:F}\\
    \I_\Cc&=\langle \F\rangle
\end{align}
is mapped to
\begin{align}
 \F^{01}&=\{f_{R_1}(\p(Y_{1_{R_1}}),\ldots,\p(Y_{k_{R_1}})),\ldots,f_{R_\ell}(\p(Y_{1_{R_\ell}})\ldots,\p(Y_{k_{R_\ell}})),\nonumber\\ 
&\qquad \T(Y_1), \ldots,\T(Y_n),y_1^2-y_1,\ldots,y_{n\uval}^2-y_{n\uval}\} \label{eq:F01}\\ 
\I_\Cc^{01}&=\langle \F^{01}\rangle.
\end{align}
Note that 
\begin{itemize}
    \item The polynomial constraints $\{\T(Y_i)=0\mid \forall i\in [n]\}$ (along with $y_i^2-y_i=0$) forces each tuple $Y_i$ to take only the values from $D^{01}$.
    \item The polynomial constraint  $f_{R_j}\left(\p(Y_{1_{R_j}}),\ldots,\p(Y_{k_{R_j}})\right)=0$, for all $j\in [\ell]$, forces the tuples $Y_{i_{R_j}}$ to take only the values whose corresponding value (according to $\mu$, see \cref{th:bin_encoding}) in finite domain satisfy $f_{R_1}(x_{1_{R_1}}\ldots,x_{k_{R_1}})$.
    \item Let $u(x_1, \dots, x_n)$ and consider $u^{01}(\p(Y_1), \dots, \p(Y_n))$. Then
    \begin{align*}
        u(x) = 0 \iff u^{01}(Y) = 0 \iff (\p(Y_1), \dots, \p(Y_n)) \in \Variety{\I_\Cc}.
    \end{align*}
    Thus $\Variety{\I_\Cc}$ and $\Variety{\I_{\Cc^{01}}}$ are in one-to-one correspondence and $u \in \I_\Cc$ if and only if $u^{01} \in \I_{\Cc}^{01}$.
    \item If $\deg(u) = d$, then $\deg(u^{01}) \leq \uval d$.
\end{itemize}
Note that the set of satisfying assignments $Sol(\Cc)$ corresponds to the variety $\Variety{\I_\Cc}$ of $\I_\Cc$, i.e. $Sol(\Cc)=\Variety{\I_\Cc}$. 
\begin{corollary}\label{th:imp_red}
 $\IMP_d(\Gamma)$ is polynomial time reducible to $\IMP_{\uval d}(\Gamma^{01})$, where $\Gamma^{01}$ if a finite constraint language over $\{0, 1\}$ that is closed under  a 2-element semilattice operation polymorphism, and such that $\Variety{\I_\Cc}$ and $\Variety{\I_{\Cc^{01}}}$ are in one-to-one correspondence. 
\end{corollary}

\subsubsection[Mapping the Boolean PC proof back to finite domain]{Mapping the Boolean $\PC$ proof back to finite domain}\label{sect:mappingBack}
Let $|D|=O(1)$. By \cref{th:Min}, we can solve $\IMP_{\uval d}(\Gamma^{01})$ by bounded-degree $\PC$ in $n^{O(d)}$ time. In the following we show the existence of a polynomial time bounded-degree $\PC$ proof for $\IMP_{\uval d}(\Gamma^{01})$ implies a polynomial time bounded-degree $\PC$ proof for $\IMP_{d}(\Gamma)$, and hence the proof of \cref{th:semilattice} follows.


To begin, we introduce the following terminology.
\begin{definition}
    Let $\I\subseteq \Field[x_1, \ldots, x_n]$ be an ideal, and let $f,g\in \Field[x_1, \ldots, x_n]$. We say that $f$ and $g$ are \textbf{\emph{congruent modulo $\I$}}, written $f\cong g \mod{\I}$, if $f-g\in \I$.
\end{definition}

\paragraph{The interpolating polynomial $\q_j$ in finite domain.}
For any given value $d_i\in D$ and $j\in [\uval]$, we need a polynomial function $\q_j(d_i)$ that returns the $j$-th bit of $\mu(d_i)=b_{i1},\ldots,b_{i\uval}$, i.e. $\q_j(d_i)=b_{ij}$.
By Lagrange interpolating polynomials (see e.g. \cite{phillips2003interpolation}, \cite{Gasca2000-hx}), given $|D|$ distinct values  $d_1,\ldots,d_{|D|}\in D$ and corresponding values $b_{1j},\ldots,b_{|D|j}$, there exists a polynomial $\q_j$ of degree $|D|-1$ that interpolates the data, i.e. $\q_j(d_i)=b_{ij}$ for each $j=1,\ldots,\uval$.

\begin{lemma}\label{th:x}
    \begin{enumerate}
        \item $x \cong \p(\q_1(x),\ldots,\q_\uval(x)) \mod{\langle f_D(x)\rangle}$. \footnote{Recall $\langle f_D(x)\rangle$ is the ideal generated by the domain polynomial $f_D(x)$ of $x$.}
        \item $\T(\q_1(x), \q_2(x), \dots, \q_{\uval}(x)) \cong 0 \mod{\langle f_D(x)\rangle}.$
        \item $\q_{j}(x)^2 - \q_{j}(x) \cong 0 \mod{\langle f_D(x)\rangle}$
    \end{enumerate}
\end{lemma}
\begin{proof}\textcolor{red}{TOPROVE 24}\end{proof}

\begin{proof}\textcolor{red}{TOPROVE 25}\end{proof}

































\begin{comment}
\begin{proof}[Old]
Assume that $P,Q\not = \emptyset$ otherwise we are done by \cref{th:MiNVA_sos}.
Consider $p_1$ and $q_1$ which are nonzero polynomials by the previous assumption. We now use \cref{def:monomial_deg}.
If $\multideg(p_1) =\alpha$ and $\multideg(q_1)= \beta$, then let $\gamma=(\gamma_1,\ldots,\gamma_n)$, where $\gamma_i = \max(\alpha_i,\beta_i)$ for each $i$. We call $x^\gamma$ the least common multiple of $\LM(f)$ and $\LM(g)$, written $x^\gamma = \LCM(\LM(f),\LM(g))$.
Recall, see e.g. \cite{Cox}, that the so called $S$-polynomial of $p_1$ and $q_1$ is the combination $S(p_1,q_1) = \frac{x^\gamma}{\LT(p_1)}\cdot p_1 - \frac{x^\gamma}{\LT(q_1)}\cdot q_1$. The S-polynomial deliberately cancels the leading terms of both polynomials.

Let $B$ denote the set of Boolean domain polynomials, i.e. $B=\{x_i^2-x_i\mid i\in [n]\}$.
Consider $S(p_1,q_1)|_B$ (see \cref{def:reduction}). Note that $S(p_1,q_1)|_B$ is a multilinear polynomial that is obtained from $S(p_1,q_1)$ by algebraically adding polynomials belonging to the ideal generated by $B$. So by the assumption, $S(p_1,q_1)|_B\in \I_\Cc$ and admits a $O(d)$-SoS proof.




Let us denote the elements from $Q\setminus P$ by $y_1,\ldots,y_a$, where $a=|Q\setminus P|$. Similarly, let us denote the elements from $P\setminus Q$ by $z_1,\ldots,z_b$, where $b=|P\setminus Q|$. For ease of notation let $y_{a+1}=1$ and $z_{b+1}=1$. Now, consider the following polynomial $g$:

\begin{align}
 g= S(p_1,q_1)|_B +   \sum_{i=2}^a (p-p\cdot y_i)\prod_{\ell=i+1}^{a+1} y_\ell - \sum_{j=2}^b (q-q\cdot z_j)\prod_{k=j+1}^{b+1} z_k
\end{align}
First note that by the assumption $g\in \I_\Cc$ and admits a $O(d)$-SoS proof. Second we show that $g=p-q$ and the claim follows.
Indeed, (telescopic sum)...
\end{proof}
\begin{proof}[Proof old]Consider 
\begin{align*}
    -\frac{1}{|S_2\setminus S_1|}\sum_j p_j + \frac{1}{|S_1\setminus S_2|}\sum_i q_i &= -\frac{1}{|S_2\setminus S_1|}\sum_j p(x_j-1) + \frac{1}{|S_1\setminus S_2|}\sum_i q(x_i-1)\\
    &= -\frac{1}{|S_2\setminus S_1|}\sum_j px_j + p + \frac{1}{|S_1\setminus S_2|}\sum_i qx_i - q.
\end{align*}
Let $m_{p_j}$ be the monomial $\prod_k x_k$ where $k\in S_2\setminus S_1\setminus\{j\}$. In other words let $$m_{p_j}=\frac{q}{hcf(p,q)x_j},  m_{q_i}=\frac{p}{hcf(p,q)x_i} \textrm{ and } m = \prod_{k\in S_1\cup S_2} x_k.$$ Similarly let $$$$ Consider 
\begin{align*}
    -\frac{1}{|S_2\setminus S_1|}\sum_j p_jm_{p_j} &+ \frac{1}{|S_1\setminus S_2|}\sum_i q_im_{q_i}\\ 
    &= -\frac{1}{|S_2\setminus S_1|}\sum_j p(x_j-1)m_{p_j} + \frac{1}{|S_1\setminus S_2|}\sum_i q(x_i-1)m_{q_i}\\
    &= -m 
\end{align*}
\end{proof}


Suppose the domain polynomial is $x^2+\alpha x+\beta$, where $\alpha,\beta\in\mathbb{Q}$. \anote{Does it work for any kind of root? We assume only that the coefficients are rational: it should work when roots are $-i,+i$ so domain polynomial is $x^2+1$. This implies $\alpha=0,\beta=1$, go to case 2.} We follow along with the proof in Section 3 of \cite{berkholz18}. The base step is very similar, so we don't go into the details. For the induction step, we assume that we have a proof for $r_{L'}$ for some $L'<L$ as follows:
\begin{equation}\label{eq:rL_2el}
    \sum_{i=1}^m (-a_i'f_i)f_i + \sum_{l=1}^{L'}b_l'q_l(x_{j_l}^2+\alpha x_{j_l} +\beta)+\sum_{l=1}^{L'}c_l'p_l^2 = -(r_{L'})^2.
\end{equation}
We now find a proof for $-(r_{\widehat{L}}^2)$ when $r_{\widehat{L}}=x_{j'}r_{L'}$.

\paragraph{Case 1:} $\alpha\neq 0$.\\
We define $b_{\widehat{L}}=1$, $q_{\widehat{L}}=-2r_{L'}^2$, $c_{\widehat{L}}=\alpha^2$ and $p_{\widehat{L}}=\frac{1}{\alpha}r_{L'}x_{j'}+r_{L'}$. We see that 
\begin{align*}
    b_{\widehat{L}}q_{\widehat{L}}(x_{j'}^2+\alpha x_{j'} &+\beta) + c_{\widehat{L}}p_{\widehat{L}}^2\\
    &= -2r_{L'}^2x_{j'}^2-2\alpha r_{L'}^2x_{j'} -2r_{L'}^2\beta + r_{L'}^2x_{j'}^2 + \alpha^2 r_{L'}^2 + 2\alpha r_{L'}^2 x_{j'}\\
    &= (\alpha^2-2\beta)r_{L'}^2 -r_{L'}^2x_{j'}^2\\
    &= (\alpha^2-2\beta)r_{L'}^2 -r_{\widehat{L}}^2.
\end{align*}
Multiplying \cref{eq:rL_2el} by $\alpha^2-2\beta$ and adding it to the equation above, we have a proof for $-(r_{\widehat{L}}^2)$. Formally, we set $a_i := (\alpha^2-2\beta)a_i'$ for all $i\in [m]$, $b_l := (\alpha^2-2\beta)b_l'$ and $c_l := (\alpha^2-2\beta)c_l'$ for all $l\leq L'$ to obtain 
\begin{equation}\label{eq:rLhat_2el}
    \sum_{i=1}^m (-a_if_i)f_i + \sum_{l=1}^{\widehat{L}}b_lq_l(x_{j_l}^2+\alpha x_{j_l} +\beta)+\sum_{l=1}^{\widehat{L}}c_lp_l^2 = -(r_{\widehat{L}})^2.
\end{equation}

\paragraph{Case 2:} $\alpha=0$ and $\beta\neq 0$.\\
We define $b_{\widehat{L}}=1$, $q_{\widehat{L}}=-r_{L'}^2$, $c_{\widehat{L}}=p_{\widehat{L}}=0$. Then
\begin{align*}
    b_{\widehat{L}}q_{\widehat{L}}(x_{j'}^2+\alpha x_{j'} &+\beta) + c_{\widehat{L}}p_{\widehat{L}}^2
    = -r_{L'}^2x_{j'}^2 -r_{L'}^2\beta.
\end{align*}
Multiplying \cref{eq:rL_2el} by $-\beta$ and adding it to the equation above, we have a proof for $-(r_{\widehat{L}}^2)$. The remaining case when $r_{\widehat{L}}=ar_{L'}+br_{L''}$ is the same as that in \cite{berkholz18}.

Suppose the domain polynomial is of the form $x_i^3 + \alpha x_i^2 + \beta x_i + \gamma$, where the coefficients are all in $\mathbb{Q}$. As before, the base step is similar, and we assume for the induction step that we have a proof for $r_{L'}$ for some $L'<L$  is as follows:
\begin{equation*}\sum_{i=1}^m (-a_i'f_i)f_i + \sum_{l=1}^{L'}b_l'q_l(x_{j_l}^{3}+\alpha x_{j_l}^{2} +\beta x_{j_l}+\gamma)+\sum_{l=1}^{L'} \left( c_{1_l}'p_{1_l}^2 + c_{2_l}'p_{2_l}^2 \right) = -(r_{L'})^2.
\end{equation*}
In the 2-element domain, it was enough to have just one square polynomial $p_l^2$ for every step $l$ of the $\PC$. Here we need two square polynomials $p_{1_l}^2$ and $p_{1_l}^2$ per step. Since the domain polynomial has odd degree, we assume that every $q$ contains $x$, so that every monomial containing only $x$ (except for $x^2$) is cancelled out by the SoS part. More precisely, let $q_l=x_{j_l}q_l^*$, and the proof is now
\begin{equation}\label{eq:rL_3el}
    \sum_{i=1}^m (-a_i'f_i)f_i + \sum_{l=1}^{L'}b_l'q_l^*(x_{j_l}^{4}+\alpha x_{j_l}^{3} +\beta x_{j_l}^2+\gamma x_{j_l})+\sum_{l=1}^{L'} \left( c_{1_l}'p_{1_l}^2 + c_{2_l}'p_{2_l}^2 \right) = -(r_{L'})^2.
\end{equation}
We find a proof for $r_{\widehat{L}}=x_{j'}r_{L'}$ based on three cases of $k = \alpha^2/4-\beta$.

\paragraph{Case 1:} $k = 0$.\\
We define
\begin{align*}
    &\textrm{constants } b_{\widehat{L}}=1, c_{1_{\widehat{L}}} = 1, c_{2_{\widehat{L}}} = 1,\\
    &\textrm{polynomials } p_{1_{\widehat{L}}}=r_{L'}x_{j'}^2+\frac{\alpha}{2}r_{L'}x_{j'} - r_{L'}, p_{2_{\widehat{L}}}=r_{L'}x_{j'} + \left( \frac{\alpha+\gamma}{2}\right)r_{L'}, q^*_{\widehat{L}} = -r_{L'}^2.
\end{align*}
We see that
\begin{align*}
&b_{\widehat{L}}q^*_{\widehat{L}}(x_{j'}^{4}+\alpha x_{j'}^{3} +\beta x_{j'}^2+\gamma x_{j'})+c_{1_{\widehat{L}}}p_{1_{\widehat{L}}}^2+c_{2_{\widehat{L}}}p_{2_{\widehat{L}}}^2\\
    &=-r_{L'}^2(x_{j'}^{4}+\alpha x_{j'}^{3} +\beta x_{j'}^2+\gamma x_{j'}) + \left(r_{L'}x_{j'}^2+\frac{\alpha}{2}r_{L'}x_{j'} - r_{L'}\right)^2 \\
    &\quad + \left(r_{L'}x_{j'} + \left( \frac{\alpha+\gamma}{2}\right)r_{L'}\right)^2\\
    &=-r_{L'}^2x_{j'}^{4}-\alpha r_{L'}^2 x_{j'}^{3} -\beta r_{L'}^2 x_{j'}^2-\gamma r_{L'}^2 x_{j'} + r_{L'}^2 x_{j'}^4 +\frac{\alpha^2}{4}r_{L'}^2 x_{j'}^2+r_{L'}^2 +\alpha r_{L'}^2 x_{j'}^{3}\\ 
    &\quad  -r_{L'}^2 x_{j'}^2 -\alpha r_{L'}^2 x_{j'}+r_{L'}^2r_{L'}^2 x_{j'}+ x_{j'}^2+(\alpha+\gamma)+\left(\frac{\alpha+\gamma}{2}\right)^2r_{L'}^2\\
    &= -r_{L'}^2 x_{j'}^2 + r_{L'}^2\left(1+\left(\frac{\alpha+\gamma}{2}\right)^2\right) \\
    &= -(r_{\widehat{L}})^2 + r_{L'}^2\left(1+\left(\frac{\alpha+\gamma}{2}\right)^2\right).
\end{align*}
We add \cref{eq:rL_3el} multiplied by $1+\left(\frac{\alpha+\gamma}{2}\right)^2$ to the above equation to get the desired proof.
\paragraph{Case 2:} $k>0$.\\
We choose an integer $d\geq 1$ such that $d^2k-1>0$. We define
\begin{align*}
    &\textrm{constants } b_{\widehat{L}}=1, c_{1_{\widehat{L}}} = 1, c_{2_{\widehat{L}}} = d^2k-1,\\
    &\textrm{polynomials } p_{1_{\widehat{L}}}=dr_{L'}x_{j'}^2+\frac{\alpha d}{2}r_{L'}x_{j'} - dkr_{L'}, p_{2_{\widehat{L}}}=r_{L'}x_{j'} + \left( \frac{(\alpha+\gamma)d^2k}{2(d^2k-1)}\right)r_{L'},\\
    &\quad\quad\quad\quad\quad\quad q^*_{\widehat{L}} = -d^2r_{L'}^2.
\end{align*}
We see that
\begin{align*}
&b_{\widehat{L}}q^*_{\widehat{L}}(x_{j'}^{4}+\alpha x_{j'}^{3} +\beta x_{j'}^2+\gamma x_{j'})+c_{1_{\widehat{L}}}p_{1_{\widehat{L}}}^2+c_{2_{\widehat{L}}}p_{2_{\widehat{L}}}^2\\
    &=-d^2r_{L'}^2(x_{j'}^{4}+\alpha x_{j'}^{3} +\beta x_{j'}^2+\gamma x_{j'}) + \left(dr_{L'}x_{j'}^2+\frac{\alpha d}{2}r_{L'}x_{j'} - dkr_{L'}\right)^2 \\
    &\quad + (d^2k-1)\left(r_{L'}x_{j'} + \left( \frac{(\alpha+\gamma)d^2k}{2(d^2k-1)}\right)r_{L'}\right)^2\\
&= -d^2r_{L'}^2x_{j'}^{4}-\alpha d^2r_{L'}^2 x_{j'}^{3} -\beta d^2r_{L'}^2 x_{j'}^2-\gamma d^2r_{L'}^2 x_{j'} + d^2r_{L'}^2x_{j'}^{4}+\frac{\alpha^2d^2}{4}r_{L'}^2 x_{j'}^2\\
    &\quad + d^2k^2r_{L'}^2 + \alpha d^2 r_{L'}^2 x_{j'}^3 -2d^2kr_{L'}^2 x_{j'}^2 -\alpha d^2kr_{L'}^2 x_{j'} + d^2kr_{L'}^2 x_{j'}^2 - r_{L'}^2 x_{j'}^2 \\
    &\quad + (\alpha+\gamma)d^2kr_{L'}^2 x_{j'} + \frac{(\alpha+\gamma)^2d^4k^2}{4(d^2k-1)}r_{L'}^2\\
&= -r_{L'}^2 x_{j'}^2 + \left(d^2k^2 + \frac{(\alpha+\gamma)^2d^4k^2}{4(d^2k-1)}\right)r_{L'}^2. 
\end{align*}
We add \cref{eq:rL_3el} multiplied by $d^2k^2 + \frac{(\alpha+\gamma)^2d^4k^2}{4(d^2k-1)}$ to the above equation to obtain the desired proof.

\paragraph{Case 3:} $k<0$.\\
We choose an integer $d\geq 2$ such that $-((d^2-1)k+1)>0$. We define
\begin{align*}
    &\textrm{constants } b_{\widehat{L}}=1, c_{1_{\widehat{L}}} = 1, c_{2_{\widehat{L}}} = -((d^2-1)k+1),\\
    &\textrm{polynomials } p_{1_{\widehat{L}}}=(d-1)r_{L'}x_{j'}^2+\frac{\alpha (d-1)}{2}r_{L'}x_{j'} + kr_{L'},\\ &\quad\quad\quad\quad\quad\quad p_{2_{\widehat{L}}}=r_{L'}x_{j'} + \left( \frac{-\gamma(d-1)^2+\alpha k(d-1)}{2((d^2-1)k+1)}\right)r_{L'},\\
    &\quad\quad\quad\quad\quad\quad q^*_{\widehat{L}} = -(d-1)^2r_{L'}^2.
\end{align*}
We see that
\begin{align*}
&b_{\widehat{L}}q^*_{\widehat{L}}(x_{j'}^{4}+\alpha x_{j'}^{3} +\beta x_{j'}^2+\gamma x_{j'})+c_{1_{\widehat{L}}}p_{1_{\widehat{L}}}^2+c_{2_{\widehat{L}}}p_{2_{\widehat{L}}}^2\\
    &=-(d-1)^2r_{L'}^2(x_{j'}^{4}+\alpha x_{j'}^{3} +\beta x_{j'}^2+\gamma x_{j'}) + \left((d-1)r_{L'}x_{j'}^2+\frac{\alpha (d-1)}{2}r_{L'}x_{j'} + kr_{L'}\right)^2 \\
    &\quad - ((d^2-1)k+1)\left(r_{L'}x_{j'} + \left( \frac{-\gamma(d-1)^2+\alpha k(d-1)}{2((d^2-1)k+1)}\right)r_{L'}\right)^2\\
&= -(d-1)^2r_{L'}^2x_{j'}^{4}-\alpha (d-1)^2r_{L'}^2 x_{j'}^{3} -\beta (d-1)^2r_{L'}^2 x_{j'}^2-\gamma (d-1)^2r_{L'}^2 x_{j'}\\  
    &\quad +(d-1)^2r_{L'}^2x_{j'}^{4} + \frac{\alpha^2(d-1)^2}{4}r_{L'}^2 x_{j'}^2+ k^2r_{L'}^2 + \alpha (d-1)^2r_{L'}^2 x_{j'}^{3} +2k(d-1)r_{L'}^2 x_{j'}^2\\
    &\quad +\alpha k(d-1)r_{L'}^2 x_{j'} -(d^2-1)kr_{L'}^2 x_{j'}^2 -r_{L'}^2 x_{j'}^2 +\gamma(d-1)^2 r_{L'}^2 x_{j'} - \alpha k(d-1)r_{L'}^2 x_{j'} \\
    &\quad - \left( \frac{(-\gamma(d-1)^2+\alpha k(d-1))^2}{2((d^2-1)k+1)}\right)r_{L'}^2\\
& = \left(-\beta(d-1)^2 + \frac{\alpha^2(d-1)^2}{4} +2k(d-1)-(d^2-1)k-1\right)r_{L'}^2 x_{j'}^2 + k^2 r_{L'}^2 \\
    &\quad - \left( \frac{(-\gamma(d-1)^2+\alpha k(d-1))^2}{2((d^2-1)k+1)}\right)r_{L'}^2\\
& = -r_{L'}^2 x_{j'}^2 +\left(k^2- \frac{(-\gamma(d-1)^2+\alpha k(d-1))^2}{2((d^2-1)k+1)}\right)r_{L'}^2.
\end{align*}
We add \cref{eq:rL_3el} multiplied by $k^2- \frac{(-\gamma(d-1)^2+\alpha k(d-1))^2}{2((d^2-1)k+1)}$ to the above equation to obtain the desired proof.

\paragraph{Example:} When the domain is $\{0,1,2\}$, the domain polynomial is $(x_i-0)(x_i-1)(x_i-2)=x_i^3-3x_i^2+2x_i$. Thus $\alpha = -3$, $\beta=2$ and $\gamma = 0$ and we are in Case 2 since $k = \alpha^2/4-\beta = 9/4-2>0$.
We choose an integer $d:=3$ so that $d^2k-1>0$. We define (see Case 2 for more details)
\begin{align*}
    &\textrm{constants } b_{\widehat{L}}=1, c_{1_{\widehat{L}}} = 1, c_{2_{\widehat{L}}} = 5/4,\\
    &\textrm{polynomials } p_{1_{\widehat{L}}}=3r_{L'}x_{j'}^2-\frac{9}{2}r_{L'}x_{j'} - \frac{3}{4}r_{L'}, p_{2_{\widehat{L}}}=r_{L'}x_{j'}-\frac{27}{10}r_{L'},\\
    &\quad\quad\quad\quad\quad\quad q^*_{\widehat{L}} = -9r_{L'}^2.
\end{align*}
It follows that 
\begin{align*}
&b_{\widehat{L}}q^*_{\widehat{L}}(x_{j'}^{4}+\alpha x_{j'}^{3} +\beta x_{j'}^2+\gamma x_{j'})+c_{1_{\widehat{L}}}p_{1_{\widehat{L}}}^2+c_{2_{\widehat{L}}}p_{2_{\widehat{L}}}^2
    = -r_{L'}^2 x_{j'}^2 + \frac{387}{40} r_{L'}^2. 
\end{align*}
We add \cref{eq:rL_3el} multiplied by $ \frac{387}{40}$ to the above equation to eliminate the last term and obtain proof of $-(r_{\widehat{L}})^2$.

The proof is nearly the same as the one above: the domain polynomial is now $x_i^4 + \alpha x_i^3 + \beta x_i^2 + \gamma x_i + \delta$. The proof looks similar to \cref{eq:rL_3el}, except that $q_l^*$ is $q_l$. We see that the only additional term is $\delta b_l'q_l$. Adding \cref{eq:rL_3el} multiplied by $-\delta b_l'q_l/r_{L'}^2$ cancels this term out (note that $q_l$ is a multiple of $r_{L'}^2$).
\newpage
\newpage
\end{comment}

\section{Proof of \cref{th:dual_discriminator}}\label{sect:dual-proof}
In this section, we focus on $\IMP_d(\Gamma)$, where $\Gamma$ is a language closed under the \emph{dual discriminator} polymorphism and show the proof of~\cref{th:dual_discriminator}. 
The dual discriminator is a well-known majority operation \cite{Jeavons:1997:CPC,barto_et_al:DFU:2017:6959} and is often used as a starting point in many CSP-related classifications \cite{barto_et_al:DFU:2017:6959}. For a finite domain $D$, a ternary operation $f$ is called a majority operation if  $f(a,a,b)=f(a,b,a)=f(b,a,a)=a$ for all $a,b\in D$. 
\begin{definition}\label{def:dual discriminator}
  The \emph{dual discriminator} on a domain $D$, denoted by $\nabla$, is a majority operation such that $\nabla(a,b,c)=a$ for pairwise distinct $a,b,c\in D$.
\end{definition}

The input for $\IMP_d(\Gamma)$ consists of any given set of polynomials that defines the combinatorial ideal $\I_\Cc$ (see \cref{def:combinatorial_ideal}) corresponding to a dual discriminator closed language: 
\begin{align}\label{eq:dual_generators}
    f_{R_1}(X_{R_1}),\ldots,f_{R_\ell}(X_{R_\ell}),f_D(x_1),\ldots,f_D(x_n).
\end{align}
We want to show that $\PC$ is capable of computing the full \GB basis (in \grlex order) in polynomial time.

We will assume that the solution set is non-empty, as the search version of $\IMP_0(\Gamma)$ can be solved by \PC\ in polynomial time using ``local-consistency" algorithms, valid for the dual-discriminator, as shown in \cite{JeffersonJGD13}.

\paragraph{\cref{th:dual_discriminator} proof structure.}\label{sect:dual_discriminator_structure}
The central idea is to adapt the algorithms presented in \cite{BharathiM21, BharathiM25} and \cite{BulatovRSTOC22} to design a $\PC$ algorithm that runs in polynomial time for any given domain~$D$.
The main arguments are as follows.
\begin{enumerate}[(i)]
    \item For any given instance of $\IMP_d(\Gamma)$, consider the corresponding $\CSP(\Gamma)$ input instance $\Cc=(X,D,C)$ (see \cref{def:IMP}). It is known that any instance $\Cc = (X, D, C)$ of $\CSP(\Gamma)$ can be reduced to an equivalent $\CSP(\Gamma)$ instance with only binary constraints (that is, constraints with at most two variables in their scope). In this transformed instance, the constraints are organized into three categories: \emph{permutation} constraints, \emph{complete} constraints, or \emph{two-fan} constraints. This restructuring aligns with the classification introduced in prior work (see \cite{Cooper1994CharacterisingTC}). We derive binary constraints according to the $\CSP$ classification. \label{i}
    \item Consider the input combinatorial ideal $\I_\Cc$ associated with the given instance of $\IMP_d(\Gamma)$ (see \cref{eq:comb_Id}). The next phase consists in the decomposition of the combinatorial ideal $\I_{\Cc}$ into a collection of simpler ideals. Each of these simpler ideals arises from the structured binary constraints considered above. The advantage here is that these individual ideals have \GB bases that can be derived efficiently through the $\PC$ algorithm.
    \item Finally, we combine the \GB bases corresponding to the simpler ideals into a single \GB basis for the entire combinatorial ideal $\I_{\Cc}$. This approach allows us to efficiently compute a solution to the original problem in polynomial time.
\end{enumerate}

{Schematically, \cref{th:dual_discriminator} is proven by the following arguments:}
\begin{enumerate}
    \item In \cref{sect:intro_dual_discriminator}, by using the known result for $\CSP$s mentioned in \ref{i}, $\IMP_d(\Gamma)$ can be shown to be equivalent to $\IMP_{d}(\Pi)$, where $\Pi$ is a binary constraint language. To achieve this, we start from the given input polynomials \eqref{eq:dual_generators} and derive bivariate polynomials describing the mentioned binary constraints. The derivation can be done in polynomial time and entirely within the framework of $\PC$. 
    \item In \cref{sect:permutation_constraints}, it is shown that a \GB basis for the combinatorial ideal generated by the \textit{permutation} constraints $\I_{perm}$ can be calculated in polynomial time by $\PC$. In particular, we define new constraints $CPC_i$ that arise from ``chaining'' together permutation constraints, with the property that, if $X_i$ and $X_j$ are the variables in $CPC_i$ and $CPC_j$ respectively, then $X_i \cap X_j = \emptyset$. It follows that $\I_{perm} = \sum_i \I_{CPC_i}$, and a set of generators for each $\I_{CPC_i}$ is found.
    \item In \cref{sect:complete_two-fan_constraints}, similar to the permutation constraints case, a set of generators for the combinatorial ideal $\I_{CF}$ generated by the \textit{complete} and \textit{two-fan} constraints is found. In particular, we find a \GB basis for $\I_{CF}$.
    \item In \cref{sect:combin_gen}, we construct generators for simpler ideals by combining those of $\I_{CPC_p}$ and $\I_{CF}$. This combination preserve the structure that $\I_{\Cc} = \sum_{p \in J} CPC_p + \I_{CF}$. We will show that a \GB basis for $\I_{Cc}$ can be computed with bounded degree in polynomial time.
\end{enumerate}

We will show how to convert the ad-hoc algorithm in \cite{BharathiM21, BharathiM25} into a standard $\PC$ algorithm. Moreover, techniques from \cite{BulatovRSTOC22} are implemented for the case of the complete and two-fan constraints. This algorithm can be used to solve $\IMP_d(\Gamma)$ in polynomial time and leads to \cref{th:dual_discriminator}.

We define the sets of constraints
\begin{align*}
    &C_{P} = \{ C_{ij} \in C \, | \, C_{ij} \text{ is a \textit{permutation} constraint} \} \\
    &C_{CF} = \{ C_{ij} \in C \, | \, C_{ij} \text{ is a \textit{complete} or a \textit{two-fan} constraint} \}.
\end{align*}
Note that that $\Cc = C_{P} \cup C_{CF}$. Therefore,
\begin{equation}\label{eqn:dual_discr_ideal_decomposition}
    \I_{\Cc} = \I_{C_P} + \I_{C_{CF}}.
\end{equation}
The idea is to find a set of generators for each addenda in the sum on the RHS and the to combine these polynomials together in a single \GB basis for $\I_{\Cc}$. We recall that for having the identity \cref{eqn:dual_discr_ideal_decomposition}, by radicality, it is sufficient to have that
\begin{equation*}
    \Variety{I_{\Cc}} = \Variety{I_{C_P}} \cap \Variety{I_{C_{CF}}}.
\end{equation*}

\subsection{Binary constraints}\label{sect:intro_dual_discriminator}


Let $\Gamma$ be a language over a finite domain $D$ closed under the dual-discriminator polymorphism, i.e. $\nabla \in Pol(\Gamma)$. Let $\Cc = (X, D, C)$ be an instance of $\CSP(\Gamma)$. In general, if a language $\Gamma$ is closed under a majority polymorphism $\mu$, any instance of $CSP(\Gamma)$ is equivalent to an instance that has only binary constraints. 

Consider a relation $R$ with arity $m$ and let $J \subseteq [m]$ be a set of indices. We denote $X[J] = (x_j)_{j \in J}$ the subset of variables with indices in $J$, and similarly we denote $pr_J(R)$ the projection of $R$ to the components with indices in $J$, i.e. the tuples $(a_j)_{j \in J}$ such that there exists a $n$-tuple $(b_1, \ldots, b_n) \in R$ with $a_j = b_j$ for all $j \in J$.

\begin{proposition}[\cite{Jeavons:1997:CPC}]\label{prop:majority_to_binary_majority}
    Let $R$ be a relation of arity $m$ that is closed under a majority operation, and let $C$ be any constraint $(X,R)$ constraining the variables in $X$ with relation $R$.
    For any problem $\mathcal{P}$ containing the constraint $C$, the problem $\mathcal{P}'$ obtained by replacing $C$ with the set of binary constraints
    \begin{equation*}
        \{((X[i],X[j]), pr_{i,j}(R)) \, | \, 1 \leq i \leq j \leq m \}
    \end{equation*}
    has exactly the same solutions as $\mathcal{P}$.
\end{proposition}

Moreover, if the language $\Gamma$ is closed under the dual-discriminator polymorphism, i.e. $\nabla \in Pol(\Gamma)$, the binary constraints $C_{ij}$ are well-structured into three types.

\begin{proposition}\cite{Cooper1994CharacterisingTC}
    Suppose $\nabla \in Pol(\Gamma)$. Then each constraints $C_{ij} = \langle (x_i,x_j),R_{ij}) \rangle$ is one of the following three types.
    \begin{enumerate}
        \item Permutation constraint: $R_{ij} = \{(a, \pi(a)) \, | \, a \in D_i \}$ for some $D_i \subseteq D$ and some bijection $\pi:D_i \rightarrow D_j$, where $D_j \subseteq D$.
        \item Complete constraint: $R_{ij} = D_i \times D_j$ for some $D_i, D_j \subseteq D$.
        \item Two-fan constraint: $R_{ij} = \{(\{a\} \times D_j) \cup (D_i \times \{ b \})\}$ for some $D_i, D_j \subseteq D$ and $a \in D_i, b \in D_j$.
    \end{enumerate}
\end{proposition}

\begin{remark} \label{rmrk:binary_constraints_bounded_derivations} 
    We emphasize here that given an instance of a CSP $\Cc = (X,D,C)$ whose language $\Gamma$ is dual-discriminator closed, we can derive bivariate polynomials describing the binary constraints $C_{ij}$ in polynomial time entirely within the framework of \PC. 
    
    Indeed, first we note that $\Gamma$ is a \emph{finite} constraint language. Let $arity(R)$ denote the arity of $R$. Then $M := \max_{R \in \Gamma} arity(R) = O(1)$, i.e. the maximum arity of a relation in $\Gamma$ is constant. 
    
    Second, for any constraint we can easily find a set of generators for its combinatorial ideal. Let $T = R^{T}(x_{i_1}, \ldots, x_{i_m})$ be a $m$-ary constraint from $C$. Let $\mathcal{P}^{T}$ be a set of polynomials such that $Sol(T) = \Variety{\mathcal{P}^{T}}$ and such that the domain polynomials are in $\mathcal{P}^{T}$ for each variable appearing in any of the polynomials. Then the combinatorial ideal of $T$ is equal to the ideal generated by $\mathcal{P}^{T}$, i.e. $I_T = \langle \mathcal{P}^{T} \rangle$. 
    
    Third, since $arity(R^{T}) \leq M$ is bounded by a constant, it follows that the reduced \GB basis of $\langle \mathcal{P}^{T} \rangle$ can be calculated in constant time with respect to the number $n$ of variables in $X$. Indeed, finding the reduced \GB basis is in general an EXPSPACE-complete problem (see \cite{MAYR1982305, Mayr1989}) but only with respect to the number of variables in $\mathcal{P}^{T}$, which however is bounded by $M$ and so independent from $n$.

    Lastly, we observe that any set of polynomials describing a binary constraint can be derived from the generators of the initial (non-binary) constraint. Indeed, by \cref{prop:majority_to_binary_majority} we can describe the solution set of $T$ by using binary constraints $T_{ij}$. Let $\mathcal{P}^{T} \subseteq \mathbb{R}[x_1, \dots, x_n]$ be a set of polynomial generators such that $Sol(T) = \Variety{\mathcal{P}^{T}} \subseteq D^m$ and similarly let $\mathcal{P}^{T_{ij}} \subseteq \mathbb{R}[x_i,x_j]$ such that $Sol(T_{ij}) = \Variety{\mathcal{P}^{T_{ij}}} \subseteq D^2$. Note that the polynomial rings over which $\mathcal{P}^{T}$ and $\mathcal{P}^{T_{ij}}$ differ in the variables. Moreover, if $q \in \langle \mathcal{P}^{T_{ij}} \rangle$, then $q = 0$ over $\Variety{\mathcal{P}^{T_{ij}}}$, but if we interpret $q \in \mathbb{R}[x_1, \dots, x_n]$, then also $q = 0$ over $\Variety{\mathcal{P}^{T}}$ and therefore $q \in \langle \mathcal{P}^{T} \rangle$. Thus, $q$ can be derived by $\PC$ with bounded degree and bounded coefficients from $\mathcal{P}^{T}$.

    Note that if there are two constraints $T^1$ and $T^2$ that contain variables $x_i$ and $x_j$ in their scope, then by \cref{prop:majority_to_binary_majority} the initial $\CSP$ can be equivalently formulated with some binary constraint $T_{ij}$. By the same reasoning as in the previous case, a set of generators for $\mathcal{P}^{T_{ij}}$ can be derived by combining together polynomials in $\mathcal{P}^{T_1}_{ij}$ and $\mathcal{P}^{T_2}_{ij}$, the restrictions to variables $x_i$ and $x_j$ of $\mathcal{P}^{T_1}$ and $\mathcal{P}^{T_2}$ respectively.
\end{remark}

In light of the above results and remarks, we can assume without loss of generality that all the constraints in the CSP instance $\Cc$ are binary, and that the generators for the combinatorial ideal $I_{\Cc}$ are sets of polynomials $\mathcal{P}_{ij}$ with the property $Sol(C_{ij}) = \Variety{\mathcal{P}_{ij}}$. Furthermore, the points of any bivariate variety $\Variety{\mathcal{P}_{ij}}$ arise from either a permutation, a complete or a two-fan constraint.

\subsection{Generating sets}

In this section, we walk through the proof sketched at the beginning of \cref{sect:dual_discriminator_structure}. We start by presenting some derivations that can be efficiently made by $\PC$. We will refer these derivations in the subsequent sections. We then proceed to find generating sets for ideals arising from permutation and from complete and two-fan constraints. Finally, we will combine these generators together and find a \GB basis of $\I_{\Cc}$.

\subsubsection{Derivation schemes}

We present and prove five derivation schemes that can be performed by Polynomial Calculus in polynomial time. This subsection serves as a reference for later discussions and can be skipped at a first read.

Throughout this section $x$ will denote a variable and $D_f, D_g, D_h \subseteq D$.

\begin{lemma}[Derivation Scheme 1]\label{th:derivation_scheme_1}
    Let $h = \Pi_{a \in D_h}(x-a)$ and consider polynomials $f = h(x-\alpha)$ and $g = h(x-\beta)$ with $\alpha \neq \beta$. Then $h$ can be $\PC$-derived from $f$ and $g$ in polynomial time.
\end{lemma}

\begin{proof}\textcolor{red}{TOPROVE 26}\end{proof}

\begin{lemma}[Derivation Scheme 2]\label{th:derivation_scheme_2}
    Let $f = \Pi_{a \in D_f} (x-a)$ and $g = \Pi_{b \in D_g}(x-b)$ with $D_f \cap D_g \neq \emptyset$. Then $h = \Pi_{c \in D_f \cap D_g}(x-c)$ can be $\PC$-derived from $f$ and $g$ in polynomial time.
\end{lemma}

\begin{proof}\textcolor{red}{TOPROVE 27}\end{proof}

\begin{lemma}[Derivation Scheme 3]
    Let $f = \Pi_{a \in D_f} (x-a)$ and $g = \Pi_{b \in D_g}(x-b)(x^2 + \alpha)$ with $D_f, D_g \subseteq D$, $D_f \cap D_g \neq \emptyset$ and $\alpha \in \mathbb{R}$. Then $h = \Pi_{c \in D_f \cap D_g}(x-c)$ can be $\PC$-derived from $f$ and $g$ in polynomial time.
\end{lemma}

\begin{proof}\textcolor{red}{TOPROVE 28}\end{proof}

\begin{corollary}[Derivation Scheme 4]
    Let $f = \Pi_{a \in D_f} (x-a)$ and $g = \Pi_{b \in D_g}(x-b)\Pi_{d \in F_g}(x^2 + \beta_d)$ with $D_f, D_g \subseteq D$ and some set of indices $F_g$, $D_f \cap D_g \neq \emptyset$ and $\beta_d \in \mathbb{R}$. Then $h = \Pi_{c \in D_f \cap D_g}(x-c)$ can be $\PC$-derived from $f$ and $g$ in polynomial time.
\end{corollary}

\begin{lemma}[Derivation Scheme 5]
    Let $\sigma_{ij}:D_i \rightarrow D_j$ be a bijection with $D_i, D_j \subseteq D$. Let $f$ be the Lagrange interpolating polynomial that simulates $\sigma_{ji} = \sigma_{ij}^{-1}$ over $D_j$. Consider polynomials $p_1 := x_i - f(x_j)$, $p_2 := x_i - a$ and $p_3 = \Pi_{b \in D_j}(x_j - b)$ for some $a \in D_i$. Then $h = x_j - \sigma_{ij}(a)$ can be $\PC$-derived from $p_1$ and $p_2$ in polynomial time.
\end{lemma}

\begin{proof}\textcolor{red}{TOPROVE 29}\end{proof}

\subsubsection{Permutation constraints}\label{sect:permutation_constraints}

Let $C_{ij} = R_{ij}(x_i,x_j) \in C_P$ be a permutation constraint where $R_{ij} = \{(a, \pi_{ij}(a) \, | \, a \in D_i \}$ for some $D_i,D_j \subseteq D$ and a bijection $\pi_{ij}:D_i \rightarrow D_j$. To the constraint $C_{ij}$ it corresponds the set of polynomials $\{ x_j - f(x_i), x_i - g(x_j), \Pi_{a \in D_i} (x_i - a), \Pi_{b \in D_j}(x_j - b)\}$, where $f$ and $g$ are the (Lagrange) polynomials interpolating the points $\{(a,\pi_{ij}(a))\}_{a \in D_i}$ and $\{(\pi_{ij}^{-1}(b),b)\}_{b \in D_j}$ respectively. Recall \cref{rmrk:binary_constraints_bounded_derivations}, thus all these polynomials can be derived by $\PC$ in polynomial time.

Next we use a construction similar to the one in \cite{BharathiM21, BharathiM25} to define larger constraints called \emph{chain permutation constraints} (CPCs) that combine multiple permutation constraints together. We maintain the notation. More precisely, it is possible to define constraints
\begin{equation*}
    CPC_p := R_p(X_p = \{ x_{p_1}, \ldots, x_{p_r} \})
\end{equation*}
such that the solutions to the constraints $C_{P}$ are also the solutions to the constraints $CPC := \{CPC_p \, | \, p \in J\}$ for some $J \subseteq [n]$. Moreover, the following property holds.

\begin{lemma}[\cite{BharathiM21, BharathiM25}]
    Let $CPC_p = R_p(X_p)$ and $CPC_q = R_q(X_q)$ with $p,q \in J$ be two CPCs. If $p \neq q$, then $X_p \cap X_q = \emptyset$.
\end{lemma}

However, we do not really need to calculate any CPC: it suffices for us to derive a set of polynomials $\mathcal{P}^{CPC_p}$ such that $\Variety{\mathcal{P}^{CPC_p}} = Sol(CPC_p)$ for any $p \in J$. In order to do so, we define

\begin{equation*}
    \mathcal{P}^{CPC_p} := \bigcup_{i,j \in J_p} \mathcal{P}_{ij}
\end{equation*}

where $J_p \subseteq [n]$ is a set of indices such that for any pair of indices there exists a chain of pairs of indices "connecting" them. More precisely, let $i,j \in J_p$, then there exist pairs $$\{ l_1^1, l_2^1 \}, \{ l_1^2, l_2^2 \}, \{l_1^3, l_2^3\}, \ldots, \{l_1^k, l_2^k\} \subseteq J_p$$ for some $k \in [n]$ such that $i \in \{ l_1^1, l_2^1 \}, j \in \{l_1^k, l_2^k\}$ and $|\{l_1^w, l_2^w\} \cap \{l_1^{w+1}, l_2^{w+1}\}| = 1$ for any $w = 1, \ldots, k-1$.

Let $\I_{CPC_p}$ be the combinatorial ideal associated with $CPC_p = R_p(X_p = \{x_{p_1}, \ldots, x_{p_r} \})$. Let $S_i = pr_i(R_p) \subseteq D$ be the $i$-th projection of relation $R_p$, i.e. the set of values $x_i$ can assume for each valid solution in $R_p$. As a result of the construction of the CPCs, there exist bijections between any pair of variables in $X_p$. We denote $\sigma_{ij}: S_i \rightarrow S_j$ any such bijection between two variables $x_i, x_j \in X_p$.

\begin{lemma}
    Let $\mathcal{P}^{CPC_p}$ be a generating set of $\I_{CPC_p}$ for some $p \in J$. If $i,j \in J_p$, then there exist interpolating polynomials $f$ and $g$ simulating the bijections $\sigma_{ij}$ and $\sigma_{ji}$ respectively, i.e. $f(a) = \sigma_{ij}(a)$ for all $a \in D_i$ and similarly for $g$. It follows that $x_j - f(x_i), x_i - g(x_j) \in \langle \mathcal{P}^{CPC_p} \rangle$. Furthermore, $\deg(f), \deg(g) \leq |D| - 1$ and polynomials $x_j - f(x_i)$ and $ x_i - g(x_j)$ can be derived by $\PC$ in polynomial time.
\end{lemma}

\begin{proof}\textcolor{red}{TOPROVE 30}\end{proof}


\begin{remark}
    There are at most $|D|!$ different bijections between variables in $X_p$, implying that many variables are actually related by linear polynomials of the type $x_j - x_k$ for some $x_j, x_k \in X_p$. Indeed, consider variable $x_i \in X_p$ and consider all the bijections $\sigma_{il}$ such that $x_l \in X_p$. Suppose there exist two variables $x_j, x_k \in X_p$ such that $\sigma_{ij} = \sigma_{ik}$. Then $x_j = x_k$ for all values in $S_j = S_k$. It follows that $\sigma_{jk} = \sigma_{kj} = id$. Thus the Lagrange interpolating polynomials $f$ and $g$ are $x_j - x_k$ and $x_k - x_j$ respectively.
\end{remark}

From the above remark it follows that the number of variables which are \textit{not} linearly related is at most $|D|! = O(1)$, while for the remaining variables linear polynomials can be derived from $\mathcal{P}^{CPC_p}$. Finding a \GB basis for $\I_{CPC_p}$ thus reduces to finding the \GB basis of an ideal with at most $|D|!$ variables. Indeed, consider the set
\begin{equation}\label{eqn:CPC_linear_polynomials}
    \{ x_i - x_j \, | \, x_i > x_j \text{ and } \sigma_{ij} \text{ is the identity function } \forall x_i, x_j \in X_p \}.
\end{equation}

Let $\mathcal{S}_p$ be the reduced \GB basis of \cref{eqn:CPC_linear_polynomials}. Note that it can be derived by $\PC$ with bounded degree and bounded coefficients. Now define

\begin{equation*}
    M_p := \{LM(s) \, | \, s \in \mathcal{S}_p\}.
\end{equation*}

Therefore, by radicality it follows

\begin{equation}\label{eqn:dual_discriminator_CPC_decomposition}
    \I_{CPC_p} = \langle \mathcal{T}_p \rangle + \langle \mathcal{D}_p \rangle + \langle \mathcal{S}_p \rangle.
\end{equation}

where $\mathcal{T}_p$ is the set of interpolating polynomials for the bijections different from the identity $\sigma_{ij} \neq id$, and $\mathcal{D}_p = \{ \Pi_{a \in S_i}(x_i - a) \, | \, x_i \in X_p \setminus M_p\}$ is the set of domain polynomials.

At this stage, finding a \GB basis for $\I_{CPC_p}$ would not be difficult, but we choose to defer this step to \cref{sect:combin_gen}. As we will see, we will update the sets $\mathcal{D}_p$ so that it is easy to find a \GB basis for $\mathcal{T}_p \cup \mathcal{D}_p \cup \mathcal{S}_p \cup G$, where $G$ is a set of generators arising from the complete and two-fan constraints.

\subsubsection{Complete and two-fan constraints}\label{sect:complete_two-fan_constraints}

We consider the set of constraints $C_{CF}$ comprising of the complete and two-fan constraints. Let $G = \emptyset$. We will add polynomials to $G$ until it represents the constraints in $C_{CF}$.

A constraint $C_{ij} = R(x_i, x_j)$ is \textit{complete} whenever $R = D_i \times D_j$ with $D_i, D_j \subseteq D$. It is described by a pair of \emph{partial domain polynomials} defined as 
\begin{equation*}
    \Pi_{a \in D_i} (x_i - a), \qquad \Pi_{a \in D_j} (x_j - a).
\end{equation*}
For every complete constraint, we can derive such polynomial as seen in \cref{rmrk:binary_constraints_bounded_derivations} and add them to $G$.

A constraint $C_{ij} = R(x_i, x_j)$ is \textit{two-fan} if $R = \{(\{a\} \times D_j) \cup (D_i \times \{b\})\}$ with $D_i, D_j \subseteq D$, $a \in D_i$ and $b \in D_j$. A two-fan constraint is described by polynomials
\begin{equation*}
    (x_i - a)(x_j - b), \quad \Pi_{c \in D_i} (x_i - c), \quad \Pi_{d \in D_j} (x_j - d).
\end{equation*}
We also add those to $G$. 

It might happen that there exists a variable $x_i$ for which two partial domain polynomials have been added, say $\Pi_{c \in D_{i_1}} (x_i - c)$ and $\Pi_{d \in D_{i_2}} (x_i - d)$. In this case, we derive by Derivation Scheme 2. the polynomial $\Pi_{c \in D_i} (x_i - c)$ where $D_i = D_{i_1} \cap D_{i_2}$ and replace the two initial partial domain polynomials in $G$ with this new one. If for some variable $x_i$ no partial domain polynomial has been added to $G$, we add to $G$ the full domain polynomial $\Pi_{a \in D} (x_i - a)$.

Lastly, we observe that we can consider the equivalent $(2,3)$-consistent version $\Cc' = (X, D, C')$ of the initial $\CSP$ $\Cc = (X, D, C)$. We follow along the algorithm presented in \cite{BulatovRSTOC22}. However, we expand on that result by presenting a $\PC$ simulation of the algorithm.
\begin{itemize}
    \item Repeat until possible: consider three variables $x_i, x_j, x_k \in X$ and consider the set
    \begin{align*}
        T_{ij,k} = \{(a,b) \in R_{ij} \ | \ \nexists c \in D \text{ s.t } (a,c) \in R_{ik} \wedge (c,b) \in R_{kj} \} 
    \end{align*}
    If $T_{ij,k} \neq \emptyset$ do the following. Let $f$ and $g$ be interpolating polynomials vanishing at $R_{ik}$ and $R_{kj}$ respectively, i.e. $f(\alpha, \beta) = 0$ if and only if $(\alpha, \beta) \in R_{ik}$, and similarly we define $g$. Note that $\deg(f), \deg(g) = O(|D|^2)$. Define $h(x_i, x_j, x_k) := f(x_i, x_k)g(x_k, x_j)$. Then, by definition, $h(a,b,c) \neq 0$ if $(\alpha,\beta) \in T_{ij,k}$ and for all $c \in D$. It follows that, as done in \cref{rmrk:binary_constraints_bounded_derivations}, we can derive a bivariate polynomial $\tilde{h}(x_i,x_j)$ such that $\tilde{h}(a,b) = 0$ if and only if $(a,b) \in R_{ij} \setminus T_{ij,k}$. Add $\tilde{h}$ to $G$.
\end{itemize}
When the algorithm stops, we consider the $\CSP$ generated by the polynomials in $G$, i.e. for every $x_i, x_j \in X$ we consider the constraint $C' = \mathbf{V}_{ij}(x_i, x_j)$, where $\mathbf{V}_{ij}$ is the variety generated by the polynomials in $x_i$ and $x_j$. It turns out that $C'$ is the $(2,3)$-consistent version of $C$. Therefore, $C'$ and $C$ have the same solutions and $\nabla$ is a polymorphism of $C'$. Moreover, the following holds.

\begin{lemma}\cite[Lemma~4.1.5]{rafiey_constraint_2022}\label{th:complete_two-fan_grobner_basis}
    Let $G$ be defined as above. Then $G$ is a \GB basis of~$\I_{CF}.$
\end{lemma}





\subsubsection[Combining I(CPCp) and I(CF)]{Combining $\I_{CPC_p}$ and $\I_{CF}$}\label{sect:combin_gen}

Next, we want to combine the generators of $\I_{CPC_p}$ and $\I_{CF}$. For the moment we have
\begin{equation}\label{eqn:combinatorial_ideal_decomposition_1}
    \I_{\Cc} = \sum_{p \in J} \I_{CPC_p} + \I_{CF} = \sum_{p \in J} (\langle \mathcal{T}_p \rangle + \langle \mathcal{D}_p \rangle + \langle \mathcal{S}_p \rangle) + \langle G \rangle.
\end{equation}

The remainder of this section completes the proof of \cref{th:dual_discriminator}.

\begin{proof}\textcolor{red}{TOPROVE 31}\end{proof}

















\section{Conclusions and research directions}\label{sect:open problem}






In this paper it is shown that for two classes of problems that generalize \textsc{HORN-SAT} and \textsc{2-SAT} a $\PC$ proof of degree $d$ can be found in time $n^{O(d)}$, if it exists (see also \cite{BharathiM21} for related results). This is obtained by first showing that a (truncated) \GB basis for the graded lexicographic order can be computed by $\PC$ in polynomial time for any fixed $d$ (and therefore with polynomial bit complexity). By a simple polynomial division argument (see \cref{sect:PC_bit}), the latter implies that for these two classes there are no bit-complexity issues. Furthermore, both \textsc{HORN-SAT} and \text{2-SAT}, along with their generalizations to finite domains---semilattice and dual-discriminator closed languages, respectively---fit within the framework of bounded width languages \cite{JEAVONS_TRACTABLE_CONSTRAINTS}. As a step towards understanding the boundary of tractability of the $\PC$ criterion, it would be interesting to explore how $\PC$ can be applied to solve the $\IMP_d(\Gamma)$ for bounded width languages. Moreover, results regarding the tractability of the $\IMP_d$, even when using restricted form of algorithms such as those encapsulated in the Polynomial Calculus proof system, would be valuable on their own right.

Similar to SoS, it has often been stated that a $\PC$ refutation of degree $d$ can be found in time $n^{O(d)}$, if it exists. For $\PC$ over finite fields, this is already clear from the algorithm provided in \cite{CleggEI96}. However, in the case of $\PC$ over reals or rationals, the search for proofs can potentially result in bit complexity issues as recently shown by Hakoniemi in \cite{Hakoniemi21}. Indeed, in \cite{Hakoniemi21} it is shown that there is a set of polynomial constraints $Q_n$ on Boolean variables that has both $\sos$ and $\PC$ over rationals refutations of degree 2, but for which any $\sos$ or $\PC$ refutation over rationals must have exponential bit-complexity. The author remarks that the constraints in $Q_n$ do not arise from any CNF, and raise the open question to understand whether the
two measures of bit-complexity and monomial-size are polynomially equivalent for CNFs. Our $\PC$ criterion does not apply to other CNF problems like \textsc{3Lin(2)}, where $\PC$ and $\sos$ are known to be not complete for any fixed $d$. Moreover, we remark that \textsc{3Lin(2)} problems do not arise from bounded width languages \cite{BartoK14}.
As an intermediate step for the open question raised in \cite{Hakoniemi21}, it would be interesting to understand the bit complexity of problems with these CNF constraints.



In this paper, we have made partial advancements in the understanding of the bit complexity of \(\sos\), an issue that has only recently garnered attention and remains in its early stages of research. Since it was first raised 2017, progress has been relatively limited. In this section, we have offered some insights that we hope will stimulate further exploration and enhance our understanding of this fundamental problem.


{
\bibliography{references}
}

\newpage

\appendix
\section{Refutation degree for Horn clauses}\label{sect:ref_deg}
Consider the case all clauses are duals of Horn clauses (for simplicity, Horn clauses work out identically), namely at most one variable is negated per clause. 
We encode these clauses as a set of polynomial identities in a way that preserves their semantics over $\{0,1\}^n$ assignments.
Namely, let $\Cc=C_1\wedge C_2 \wedge \ldots \wedge C_m$ be a dual Horn clause formula. We encode each clause $C_i=\neg x_{i_1}\lor x_{i_2}\lor \ldots \lor x_{i_k}$ by introducing a polynomial identity $P_i:x_{i_1}(x_{i_2}-1)\cdots (x_{i_k}-1)=0$. The set of $\{0,1\}$ assignments that satisfy the newly introduced set of polynomial identities is exactly the set of satisfying assignments to $\Cc$.

The refutation by \PC\ works as follows. Take all the variables that are already known to be false, say set $F$. These variables belong to $\I_\Cc$. Consider clause $C_i$ and the corresponding polynomial identity $P_i:x_{i_1}(x_{i_2}-1)\cdots (x_{i_k}-1)=0$. If $\{x_{i_2},\ldots, x_{i_k}\}\subseteq F$ then it is easy show that $x_{i_1}\in \I_\Cc$ since by using the aforementioned polynomial identity $P_i$ we can express $x_{i_1}$ as polynomial combination of the variables in $\{x_{i_2},\ldots, x_{i_k}\}$.\footnote{For example if $P:x_{1}(x_{2}-1)(x_{3}-1)=0$ and $x_2,x_3\in\I_\Cc$ then by the polynomial identity $P$ we have that $x_1=x_{1}x_{2}(1-x_{3})+x_{1}x_{3}$, implying that $x_1\in\I_\Cc$.}
So we have added a new variable to the set $F$ of known false variables. If the set of $F$ covers an entire clause with no negated variables, then we can derive that $1\in \I_\Cc$ and we are done. If at some point, neither is true, by setting all remaining variables to 1 we satisfy all the clauses. So if the Horn clauses were unsatisfiable we find a proof whose degree is at most the degree of the polynomial identities encoding the clauses. 

\section{Complexity of Polynomial Division}\label{sect:PC_bit}
Consider the polynomial ring $\mathbb{R}[x_1, \dots, x_n]$ ordered according to the $\grlexns$ order, with $x_1 > x_2 > \dots > x_n$. We will study the complexity of the standard division algorithm for multivariate polynomials (see \cite[Section 2]{Cox}). In particular, we observe next that it is a polynomial time algorithm.

\begin{lemma}\label{th:complexity_polynomial_division}
    Let $\mathcal{P} = \{p_1, \dots, p_m\}$ be a set of polynomials in $\mathbb{R}[x_1, \dots, x_n]$ and consider a polynomial $f \in \mathbb{R}[x_1, \dots, x_n]$. Assume that $f, p_1, \dots, p_m$ have degree at most $d$ and bit complexity polynomial in $n$. Then $f$ can be written as
    \begin{equation*}
        f = h_1 p_1 + \dots h_m p_m + r,
    \end{equation*}
    with $r, h_1, \dots, h_m$ having bit complexity polynomial in $n$.
\end{lemma}

\begin{proof}\textcolor{red}{TOPROVE 32}\end{proof}

From this lemma it follows immediately that the existence of a "small" \GB basis implies that the \IMP\ can be solved efficiently.

\begin{corollary}
    Let $\mathcal{G}_{2d} = \{g_1, \dots, g_s\}$ be a $2d$-truncated \GB basis of the polynomial ideal $\I \subseteq \mathbb{R}[x_1, \dots, x_n]$. Consider a polynomial $r$ of degree at most $2d$. If the polynomials $r,g_1, \dots, g_s$ have bit complexity polynomial in $n$, then the (search version) of the $\IMP_{2d}$ for $r$ can be solved in time polynomial in $n$.
\end{corollary}

\begin{proof}\textcolor{red}{TOPROVE 33}\end{proof}

\end{document}