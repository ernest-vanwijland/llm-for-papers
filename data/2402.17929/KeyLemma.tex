%!TEX root = mainEV.tex


\subsection{Proof of the Key Lemma~\ref{lem:BoundW}: Few Executions of Line~\ref{algline:PM}}

\label{sec:proof key}

In this section, we prove Lemma~\ref{lem:BoundW} assuming the Progress Lemma~\ref{lem:EigenspaceChange}. 
%
Let us first recall the precise definition of $\AA$ and $\AAtil$. Suppose we execute Line~\ref{algline:PM} at update $t_{0}$. Now consider a sequence of updates, $\vv_{t_{0}+1},\cdots,\vv_{t_{0}+k}$, and let $\AA_{t_{0}+k}=\AA_{t_{0}}-\sum_{i=1}^{k}\vv_{t+i}\vv_{t+i}^{\top}.$ Suppose the next execution of Line~\ref{algline:PM} happens at $t_{0}+k$. For this to happen we must have that $\ww_{t_{0}}^{\top}\AA_{t_{0}+k}\ww_{t_{0}}<1-40\epsilon$ for all $\ww_{t_{0}}\in\WW_{t_{0}}$. We let $\AA=\AA_{t_{0}}$ and $\AAtil=\AA_{t_{0}+k}$. 

Next, recall Definition~\ref{def:SpaceA} and define $T_{\leq i}=\sum_{\nu=0}^{i}T_{\nu}$, $\tilde{T}_{\leq i}=\sum_{\nu=0}^{i}\tilde{T}_{\nu}$. The following observation will motivate our potential function analysis.
\begin{lemma}
	\label{lem:Monotone} For all $i\leq15\log\frac{n}{\epsilon}$, 
	\[
	\dim{T_{\le i}}\ge\dim{\Ttil_{\le i}}.
	\]
	Let $\nu_{0}$ be such that $\dim{T_{\nu_{0}}-\tilde{T}}>0$. For any $i\ge\nu_{0}$, we have
	\[
	\dim{T_{\le i}}\geq\dim{\Ttil_{\le i}}+\dim{T_{\nu_{0}}-\Ttil}.
	\]
	
\end{lemma}

\begin{proof}
	We claim that $\tilde{T}_{\leq i}\subseteq T_{\leq i}$, which implies the first claim. This is because the updates are decreasing. So, if $\vv^{\top}\AAtil\vv\geq1-\frac{(i+1)\epsilon}{5\log\frac{n}{\epsilon}}$ then $\vv^{\top}\AA\vv\geq1-\frac{(i+1)\epsilon}{5\log\frac{n}{\epsilon}}$. That is, if $\vv\in\Ttil_{\le i}$, then $\vv\in T_{\leq i}$. For the second part, we have $T_{\leq i}=T_{\leq i}\cap\tilde{T}_{\leq i}+(T_{\leq i}-\tilde{T}_{\leq i})\supseteq\tilde{T}_{\leq i}+(T_{\nu_{0}}-\tilde{T})$ because $T_{\nu_{0}}\subseteq T_{\le i}$ and $\Ttil_{\le i}\subseteq\Ttil$. Since $\tilde{T}_{\leq i}\cap(T_{\nu_{0}}-\tilde{T})=\emptyset$, we can conclude the second part.
\end{proof}

\paragraph{The Potentials.}
The above lemma and \Cref{lem:EigenspaceChange} motivate the following potentials.
For every $j\le15\log\frac{n}{\epsilon}$, we define the potentials $\Phi_{j}=\dim{T_{\le j}}$ and $\tilde{\Phi}_{j}=\dim{\Ttil_{\le j}}$. For all $j$, the potential may only decrease, i.e., $\Phitil_{j}\le\Phi_{j}$ by \Cref{lem:Monotone}. Also, clearly, $\Phi_{j}\le n$. 

We will show that for each execution of Line~\ref{algline:PM}, $\Phitil_{j}$ decreases from $\Phi_j$ by a significant factor with high probability for some $j$. This will bound the number of executions.

Consider any important level $\nu_{0} \in \cal{I}$. We have two observations:
\begin{enumerate}
	\item \label{enu:phi 1} $\Phitil_{\nu_{0}}\leq\Phi_{\nu_{0}}-\dim{T_{\nu_{0}}-\tilde{T}}$, and 
	\item \label{enu:phi 2} $d_{\nu_{0}}\geq\Omega(1)\frac{\epsilon}{\log^{3}\frac{n}{\epsilon}}\Phi_{v_{0}}$. 
\end{enumerate}
The first point follows directly from the second part of Lemma~\ref{lem:Monotone}. Moreover, since $\nu_{0}\in\mathcal{I}$ is important, we have $d_{\nu_{0}}\geq\frac{\epsilon}{600\log^{3}\frac{n}{\epsilon}}\sum_{\nu'<\nu}d_{\nu'}.$ Therefore, 
\[
\Phi_{\nu_{0}}=\sum_{\nu=1}^{\nu_{0}}d_{\nu}=\sum_{\nu'<\nu_{0}}d_{\nu'}+d_{\nu_{0}}\leq\left(\frac{600\log^{3}\frac{n}{\epsilon}}{\epsilon}+1\right)d_{\nu_{0}},
\]
implying the second point. 
%
Combining these observations with the Progress \Cref{lem:EigenspaceChange}, we have:
\begin{lemma}
	\label{claim:potential decrease}Suppose that $\lambda_{\max}(\AA)\ge1-\epsilon$ and $\ww^{\top}\AAtil\ww<1-40\epsilon$ for all $\ww\in\WW$. With probability at least $1-50\log\frac{n}{\epsilon}/n^{2}$, there is a level $\nu_{0}$ such that either 
	\begin{itemize}
		\item $\Phitil_{\nu_{0}}\le\left(1-\frac{\Omega(\epsilon^{2})}{\log^{4}\frac{n}{\epsilon}}\right)\Phi_{\nu_{0}}$, or 
		\item $\Phitil_{\nu_{0}}\le\Phi_{\nu_{0}}-1$ and $\Phi_{\nu_{0}}\leq O(1)\frac{\log^{4}\frac{n}{\epsilon}\log n}{\epsilon^{2}}.$
	\end{itemize}
\end{lemma}

\begin{proof}
	Given the assumption, it follows from \Cref{lem:EigenspaceChange} that with probability at least $1-50\log\frac{n}{\epsilon}/n^{2}$, there is an important level $\nu_{0}\in\mathcal{I}$ be such that either $d_{\nu_{0}}\geq\frac{3000\log n\log\frac{n}{\epsilon}}{\epsilon}$ and $\dimm(T_{\nu_{0}}-\tilde{T})\geq\frac{\epsilon}{300\log\frac{n}{\epsilon}}d_{\nu_{0}}$ or $d_{\nu_{0}}<\frac{3000\log n\log\frac{n}{\epsilon}}{\epsilon}$ and $\dimm(T_{\nu_{0}}-\tilde{T})\geq1$. So, by calculation, we have the following.
	\begin{itemize}
		\item If $d_{\nu_{0}}\geq\frac{3000\log n\log\frac{n}{\epsilon}}{\epsilon}$, we have $\Phitil_{\nu_{0}}\leq\Phi_{\nu_{0}}-\frac{\epsilon}{300\log\frac{n}{\epsilon}}d_{\nu_{0}}\le\Phi_{\nu_{0}}(1-\frac{\Omega(\epsilon^{2})}{\log^{4}\frac{n}{\epsilon}})$ where the first inequality is by (\ref{enu:phi 1}) and \Cref{lem:EigenspaceChange}. The second is by (\ref{enu:phi 2}). 
		\item If $d_{\nu_{0}}<\frac{3000\log n\log\frac{n}{\epsilon}}{\epsilon}$, we have $\Phitil_{\nu_{0}}\le\Phi_{\nu_{0}}-1$ by (\ref{enu:phi 1}) and \Cref{lem:EigenspaceChange}. In this case, we also have $\Phi_{\nu_{0}}\leq O(1)\frac{\log^{4}\frac{n}{\epsilon}\log n}{\epsilon^{2}}$ by (\ref{enu:phi 2}). 
	\end{itemize}
\end{proof}
We are now ready to prove Lemma~\ref{lem:BoundW}. 

\subsubsection*{Proof of Lemma~\ref{lem:BoundW}.}

First, observe that whenever $\lambda_{\max}(\AA)<1-\epsilon$, by Line~\ref{line: if all w 1-eps} of \Cref{alg:PowerMethod}, we will always return $\textsc{False}$ at the next execution of Line \ref{algline:PM} of \Cref{alg:DynamicMaxPM}.

Therefore, it suffices to bound the number of executions while $\lambda_{\max}(\AA)\ge1-\epsilon$. We execute Line~\ref{algline:PM} only if $\ww^{\top}\AAtil\ww<1-40\epsilon$ for all $\ww\in\WW$. When this happens, there exists a level $j$ where the potential $\Phi_{j}$ significantly decreases according to \Cref{claim:potential decrease} with probability at least $1-50\log\frac{n}{\epsilon}/n^{2}$. For each level $j$, this can happen at most $L=O(\frac{\log n\log^{4}\frac{n}{\epsilon}}{\epsilon^{2}})$ times because for every $j$, $\Phi_{j}$ is an integer that may only decrease and is bounded by $n$. Suppose for contradiction that there are more than $L\times15\log\frac{n}{\epsilon}$ executions of Line~\ref{algline:PM}. So, with probability at least $1-L\cdot50\log\frac{n}{\epsilon}/n^{2}\ge1/n$, there exists a level $j$ where $\Phi_{j}$ decreases according to \Cref{claim:potential decrease} strictly more than $L$ times. This is a contradiction. 











\subsection{Proof of the Progress Lemma~\ref{lem:EigenspaceChange}}\label{sec:progress}
It remains to prove the Progress Lemma. We first restate the lemma here.

\progress*
Recall the definitions of subspaces $T,T_\nu,\Ttil$ and $\overline{T}$ in \Cref{def:SpaceA}.
We will first state the following claim and show that this is sufficient to prove \Cref{lem:EigenspaceChange}. After concluding the proof of \Cref{lem:EigenspaceChange}, we would prove the claim.

\begin{claim}\label{cl:progress} Suppose that $\lambda_{\max}(\AA) \geq 1-\epsilon$. If for every $\nu \in \mathcal{I}$, 
\begin{itemize}
\item $\dim{T_{\nu} -\tilde{T}} < \frac{\epsilon}{300\log\frac{n}{\epsilon}} d_{\nu}$ if $d_{\nu} \geq \frac{3000\log n\log\frac{n}{\epsilon}}{\epsilon}$, and 
\item $\dim{T_{\nu} -\tilde{T}} < 1$ if $d_{\nu} < \frac{3000\log n\log\frac{n}{\epsilon}}{\epsilon}$.
\end{itemize}
Then, with probability at least $1-\frac{40\log\frac{n}{\epsilon}}{n^2}$, $\ww^{\top}\VV\ww\leq 35 \epsilon$ for all $\ww\in \WW$.
\end{claim}
\subsubsection*{Proof of \Cref{lem:EigenspaceChange} using \Cref{cl:progress}}
Suppose for contradiction that \Cref{lem:EigenspaceChange} does not hold, i.e., the conditions on $\dim{T_\nu-\Ttil}$ of \Cref{cl:progress} hold for all $\nu \in \cal{I}$.
 On one hand, since $\lambda_{\max}(\AA)\geq 1-\epsilon$, \Cref{cl:progress} says that $\ww^{\top}\VV\ww\leq 35 \epsilon$ for all $\ww \in \WW$ with probability at least $1-\frac{40\log\frac{n}{\epsilon}}{n^2}$.
 From the assumption of \Cref{lem:EigenspaceChange}, we have $\ww^{\top}\AAtil\ww < 1- 40\epsilon$ for all $\ww\in \WW$ as well, this implies that, for all $\ww \in \WW$,
\[
\ww^{\top}\AA\ww < \ww^{\top}\AAtil\ww +\ww^{\top}\VV\ww < 1-5\epsilon.
\]
On the other hand, since $\lambda_{\max}(\AA)\geq 1- \epsilon$, we must have  $\ww^{\top}\AA\ww \geq 1-5\epsilon$ for some $\ww\in \WW$ with probability at least $1-1/n^2$ by  \Cref{thm:StaticPower}.
This gives a contradiction. 

Therefore, we conclude that, with probability at least $1-\frac{40\log\frac{n}{\epsilon}+1}{n^2}$, the conditions of \Cref{cl:progress} must be false for some $\nu \in \mathcal{I}$. That is, we have
\begin{itemize}
\item $\dim{T_{\nu} -\tilde{T}} \geq \frac{\epsilon}{300\log\frac{n}{\epsilon}} d_{\nu}$ if $d_{\nu} \geq \frac{3000\log n\log\frac{n}{\epsilon}}{\epsilon}$, and 
\item $\dim{T_{\nu} -\tilde{T}} \geq 1$ if $d_{\nu} < \frac{3000\log n\log\frac{n}{\epsilon}}{\epsilon}$.
\end{itemize}
This concludes the proof of \Cref{lem:EigenspaceChange}.


\subsubsection*{Setting Up for the Proof of \Cref{cl:progress}}

Recall the definitions of subspaces $T,T_\nu,\Ttil$ and $\overline{T}$ in \Cref{def:SpaceA}.

\begin{proposition}\label{prop:decomp space}
We can cover the entire space with the following subspaces
\begin{equation}\label{eq:SplitSpace}
 \mathbb{R}^n = T + \overline{T} = \tilde{T} + \sum_{\nu = 0}^{15\log \frac{n}{\epsilon}-1}(T_{\nu} -\tilde{T}) + \overline{T}
\end{equation}
where all subspaces in the sum are mutually orthogonal.
\end{proposition}
\begin{proof}
    It suffices to show that $T = \tilde{T} + \sum_{\nu = 0}^{15\log \frac{n}{\epsilon}-1}(T_{\nu} -\tilde{T})$.
    To see this, note that $\tilde{T}\subseteq T$. Therefore, we have $T = (T-\tilde{T}) + T\cap \tilde{T} = (T - \tilde{T}) + \tilde{T}$. We also know that $ T = \sum_{\nu=0}^{15\log \frac{n}{\epsilon}-1}T_{\nu}$ and this gives
$T - \tilde{T} = \sum_{\nu=0}^{15\log \frac{n}{\epsilon}-1} (T_{\nu}-\tilde{T})$, which concludes the proof.
\end{proof}


\paragraph{Notation.}The goal of \Cref{cl:progress} is to bound $\ww^{\top}\VV\ww\leq 35 \epsilon$ for all $\ww\in \WW$. We will use the following notations.
\begin{itemize}
    \item Let $\Pi_{\tilde{T}},\Pi_{\nu},\Pi_{\overline{T}}$ denote projection matrices to the subspaces $\tilde{T}$, $T_{\nu}-\tilde{T}$, and $\overline{T}$ respectively.
    \item  Define $\VV_{\tilde{T}} = \Pi_{\tilde{T}}\VV\Pi_{\tilde{T}}$, $\VV_{T_{\nu}-\tilde{T}} = \Pi_{\nu}\VV\Pi_{\nu}$, and $\VV_{\overline{T}} = \Pi_{\overline{T}}\VV\Pi_{\overline{T}}$.
\end{itemize}
By \Cref{prop:decomp space}, for any $\ww\in \WW$, we can decompose $\ww^{\top}\VV\ww$  as 
\[
\ww^{\top}\VV\ww = \ww^{\top}\VV_{\tilde{T}}\ww+\sum_{\nu = 0}^{15\log\frac{n}{\epsilon}-1}\ww^{\top}\VV_{T_{\nu} -\tilde{T}}\ww+ \ww^{\top}\VV_{\overline{T}}\ww.
\]
Our strategy is to upper bound each term one by one. Bounding $\ww^{\top}\VV_{\tilde{T}}\ww$ is straightforward, but bounding other terms requires technical helper lemmas.
\Cref{lem:boundLowEV} is needed for bounding $\ww^{\top}\VV_{\overline{T}}\ww$.
\Cref{lem:GaussianProjD,lem:NotImp} are helpful for bounding $\ww^{\top}\VV_{T_{\nu} -\tilde{T}}\ww$ when $\nu \in \cal{I}$ and when $\nu \notin \cal{I}$, respectively.


\subsubsection*{Helper Lemmas for \Cref{cl:progress}}
In all the statements of the helper lemmas below. Let $\WW$ be as defined in Line~\ref{line:before case} in the execution of \textsc{PowerMethod}($\epsilon,\AA$). Consider any fixed $\ww\in\WW$. Observe that we can write 
\begin{equation}\label{eq:rewrite w}  
\ww=\sum_{i=1}^{n}\frac{\lambda_{i}^{K}\alpha_{i}\uu_{i}}{\sqrt{\sum_{j}\lambda_{j}^{2K}\alpha_{j}^{2}}}
\end{equation}
where $K=\frac{4\log\frac{n}{\epsilon}}{\epsilon}$, $\alpha_{i}\sim N(0,1)$ are gaussian random variables, and $\lambda_i$ and $\uu_{i}$ are the $i$-th eigenvalue and eigenvector of $\AA$, respectively.

The following lemma shows that the projection of $\ww$ on $\overline{T}$ is always small. At a high level, 
since $\overline{T}$ is spanned by the eigenvectors with the small eigenvalues, the power method guarantees with high probability that the direction of $\ww$ along these eigenvectors will be exponentially small in the number of iterations $K$.
Recall that $\Pi_{\overline{T}}$ is the projection matrix to the space $\overline{T}$.
\begin{lemma}\label{lem:boundLowEV}
If $\lambda_{\max}(\AA)\geq 1-\epsilon$, then
\[
\Pr\left[\|\Pi_{\overline{T}}\ww\|^2 \leq \frac{\epsilon^2}{4}\right]\geq 1 - \frac{3}{n^2}.
\]
\end{lemma}
\begin{proof}
From the definition of $\overline{T}$ and $d$ defined in \Cref{def:SpaceA}, we have $\Pi_{\overline{T}}\ww = \frac{\sum_{i>d} \lambda_i^{K}\alpha_i\uu_i}{\sqrt{\sum_{j=1}^n \lambda_j^{2K}\alpha_i^2}}$ by \Cref{eq:rewrite w}. Hence,  
\[
\|\Pi_{\overline{T}}\ww\|^2 = \frac{\sum_{i>d}\lambda_i^{2K}\alpha_i^2}{\sum_{i=1}^n\lambda_i^{2K}\alpha_i^2}.
\]
First, we give a crude lower bound for the denominator. We have $$\sum_{i=1}^n\lambda_i^{2K}\alpha_i^2 \geq \frac{\lambda_1^{2K}}{n^4}$$ with probability at least $1-1/n^{2}$. This is because $\sum_{i=1}^n\lambda_i^{2K}\alpha_i^2 \geq \lambda_1^{2K}\alpha_1^2$ and,  since $\alpha_1^2 \sim \chi^2_1$,  we have $\alpha_1^2 \geq 1/n^4$ with probability at least $1-1/n^{2}$ by \Cref{lem:chi}.

Next, we upper bound the numerator as 
\[
\sum_{i>d}\lambda_i^{2K}\alpha_i^2 \leq \lambda_{d+1}^{2K}\sum_{i=1}^n\alpha_i^2.
\]
From \Cref{lem:NormG}, $\sum_{i=1}^n\alpha_i^2 \leq 2 n$ with probability at least $1-1/n^2$. Also note that, since $\lambda_{\max}(\AA)\geq 1-\epsilon \geq \lambda_0 (1-2\epsilon)$. We now have with probability $1-3/n^2$,
\[
\|\Pi\ww\|^2 \leq \left(\frac{\lambda_{d+1}}{\lambda_1}\right)^{2K}\cdot 2n^5 \leq  2n^5\left(\frac{\lambda_{d+1}}{\lambda_0 (1-2\epsilon)}\right)^{2K} \leq 2 n^5 \left(\frac{1-3\epsilon}{1-2\epsilon}\right)^{2K} \leq 2 n^5 \frac{\epsilon^6}{n^6}\leq \frac{\epsilon^2}{4}.\qedhere
\]
\end{proof}


The next two helper lemmas are to show that the projection of $\ww$ to $T_{\nu}- \tilde{T}$ is small. To do this, we introduce some more notations and one proposition. 
For any level $\nu$, we will use $q_{\nu}$ to denote,
\begin{equation}
    q_{\nu} \defeq \dim{T_{\nu}-\tilde{T}}.
\end{equation}
Let 
\begin{equation}\label{def:z}
\zz=\sum_{i}z_{i}\uu_{i}\text{ where }z_{i}=\lambda_{i}^{K}\alpha_{i}.
\end{equation} 
Therefore, $\ww=\zz/\|\zz\|$.

We now bound the norm of the projection of $\zz$ to $T_\nu - \Ttil$. The proof is based on the fact that $\zz$ is a {\it scaled} gaussian random vector, and the projection of a gaussian on a $q_{\nu}$-dimensional subspace should have norm proportional to $q_{\nu}$. 
\begin{proposition}\label{lem:projZ}
For $\zz$ as defined in~\eqref{def:z}, we have
\[
\|\Pi_{\nu}\zz\|^2 \leq \lambda_{a_{\nu}}^{2K} \cdot \sum_{j=a_{\nu}}^{b_{\nu}}\alpha_j^2.
\] 
Furthermore, if $q_{\nu}\geq 10 \log n$, then with probability at least $1-1/n^2$,
\[
\|\Pi_{\nu}\zz\|^2 \leq 2q_{\nu}\cdot \lambda_{a_{\nu}}^{2K}.
\]
\end{proposition}
\begin{proof}
Let $\Pi_{\nu}^{\text{full}}$ be a projection matrix to the subspace $T_{\nu}$. Recall from \Cref{def:Basis} that $\uu_{a_{\nu}},\dots,\uu_{b_{\nu}}$ form an orthonormal basis of $T_\nu$ and so we have $\Pi_{\nu}^{\text{full}}=\sum_{j=a_{\nu}}^{b_{\nu}}\uu_{j}\uu_{j}^{\top}$ and so $$\Pi_{\nu}^{\text{full}}\zz=\sum_{j=a_{\nu}}^{b_{\nu}}(\lambda_{j}^{K}\alpha_{j})\uu_{i}.$$ Since $T_{\nu}-\Ttil\subseteq T_{\nu}$, we have 
\[
\|\Pi_{\nu}\zz\|^{2}\le\|\Pi_{\nu}^{\text{full}}\zz\|^{2} = \lambda_{a_{\nu}}^{2K}\sum_{j=a_{\nu}}^{b_{\nu}}\alpha_{j}^{2},
\]
which proves the first part of the lemma. 

Before proving the second part, we consider the vector $\yy=\sum_{i}\alpha_{i}\uu_{i}$. Since $\alpha_{i}\sim N(0,1)$ for all $i$, we also have $\Pi_{\nu}\yy\sim N(0,1)$ is a gaussian in a $q_{\nu}$-dimensional space. So by \Cref{lem:NormG}, we have
\[
\|\Pi_{\nu}\yy\|^{2}\le2q_{\nu}
\]
with probability at least $1-e^{-q_{\nu}/4}\ge1-e^{-2\log n}=1-1/n^{2}$. 

To prove the second part, observe that $(\lambda_{a_{\nu}}^{K}\cdot\yy)$ ``dominates'' $\Pi_{\nu}^{\text{full}}\zz$ in every coordinate, i.e,. the coefficient of each $\uu_{i}$ in $(\lambda_{a_{\nu}}^{K}\cdot\yy)$ is at least that of $\Pi_{\nu}^{\text{full}}\zz$ for every $i$. Therefore, $\|\PP(\Pi_{\nu}^{\text{full}}\zz)\|\le\|\PP(\lambda_{a_{\nu}}^{K}\cdot\yy)\|$ for any projection matrix $\PP$. Since $T_{\nu}-\Ttil\subseteq T_{\nu}$, we have $\Pi_{\nu}\zz=\Pi_{\nu}\Pi_{\nu}^{\text{full}}\zz$. Therefore, we can conclude that 
\[
\|\Pi_{\nu}\zz\|^{2}=\|\Pi_{\nu}\Pi_{\nu}^{\text{full}}\zz\|^{2}\le\|\Pi_{\nu}(\lambda_{a_{\nu}}^{K}\cdot\yy)\|^{2}
\]
which is at most $\lambda_{a_{\nu}}^{2K}\cdot2q_{\nu}$ with probability at least $1-1/n^{2}$. \qedhere
\end{proof}
The following lemma shows that the projection of $\ww$ on $T_{\nu}-\Ttil$ is small when $\dim{T_\nu - \Ttil}:= q_\nu$ is roughly at most an $\epsilon$-factor of $\dim{T_\nu}:= d_\nu$, and $q_\nu$ is still at least logarithmic.
We will use this lemma to characterize the projection of $\ww$ on $T_{\nu}$ for $\nu \in \mathcal{I}$. 
Recall that $\Pi_\nu$ is a projection matrix that projects any vector to the space $T_{\nu}-\Ttil$.
\begin{lemma}\label{lem:GaussianProjD}

If $ 10 \log n \leq q_{\nu} \leq \frac{\epsilon}{300\log\frac{n}{\epsilon}}d_{\nu}$, then
\[
\Pr\left[\norm{\Pi_{\nu}\ww}^2 \leq \frac{\epsilon}{\log\frac{n}{\epsilon}} \right] \geq 1-\frac{2}{n^{2}}.
\]
\end{lemma}
\begin{proof}
Since $\ww=\zz/\|\zz\|$, it is equivalent to show that, with probability $1-\frac{2}{n^{2}}$, $$\|\Pi_{\nu}\zz\|^{2}\leq\frac{\epsilon}{\log\frac{n}{\epsilon}}\|\zz\|^{2}.$$ 

We first bound $\|\Pi_\nu \zz\|$ in terms of $d_\nu$. As $q_{\nu} \ge 10\log n$, by \Cref{lem:projZ}, we have with probability at least $1-1/n^{2}$, 
\[
\|\Pi_{\nu}\zz\|^{2}\leq\lambda_{a_{\nu}}^{2K}\cdot2q_{\nu}\le\lambda_{a_{\nu}}^{2K}\cdot\frac{\epsilon}{150\log\frac{n}{\epsilon}}d_{\nu}.
\]
where the second inequality follows from the assumption $q_{\nu}\leq\frac{\epsilon}{300\log\frac{n}{\epsilon}}d_{\nu}$. 

Next, we bound $d_{\nu}$ in terms of $\|z\|$. Consider the $d_{\nu}$-dimensional gaussian vector with coordinate $\alpha_{i}$ for $i=a_{\nu},\dots,b_{\nu}$. Applying \Cref{lem:NormG} to this vector with $\delta=1/10$, we have $\Pr[\sum_{i=a_{\nu}}^{b_{\nu}}\alpha_{i}^{2}\geq (1-\frac{1}{2})d_{\nu}]\geq1-e^{-d_{\nu}/100}\geq1-\frac{1}{n^{2}}$ where the last inequality used that $d_{\nu}\ge 3000\log n$. With probability $1-1/n^{2}$, we now have
\[
d_{\nu}\le2\sum_{i=a_{\nu}}^{b_{\nu}}\alpha_{i}^{2}=2\sum_{i=a_{\nu}}^{b_{\nu}}\frac{z_{i}}{\lambda_{i}^{2K}}\le\frac{2}{\lambda_{b_{\nu}}^{2K}}\|\zz\|^{2}
\]
Combining the two inequalities, we can conclude that, with probability at least $1-2/n^{2}$, 
\[
\|\Pi_{\nu}\zz\|^{2}\le\left(\frac{\lambda_{a_{\nu}}}{\lambda_{b_{\nu}}}\right)^{2K}\frac{\epsilon}{75\log\frac{n}{\epsilon}}\|\zz\|^{2}\le\frac{\epsilon}{\log\frac{n}{\epsilon}}\|\zz\|^{2}
\]
as desired. To see the last inequality, recall from \Cref{def:Basis} that $\lambda_{a_{\nu}}\leq\left(1-\frac{\nu\epsilon}{5\log\frac{n}{\epsilon}}\right)\lambda_{0}$ and $\lambda_{b_{\nu}}\geq\left(1-\frac{(\nu+1)\epsilon}{5\log\frac{n}{\epsilon}}\right)\lambda_{0}$. So $\frac{\lambda_{a_{\nu}}}{\lambda_{b_{\nu}}}\le1+\frac{\epsilon}{2\log\frac{n}{\epsilon}}$ and, hence, 
\[
\left(\frac{\lambda_{a_{\nu}}}{\lambda_{b_{\nu}}}\right)^{2K}\leq\left(1+\frac{\epsilon}{2\log\frac{n}{\epsilon}}\right)^{2K}\le e^{4}\approx54.6. \qedhere
\]
\end{proof}

We next prove that for all $\nu\notin \mathcal{I}$, arbitrary projections of $\ww$ on $T_{\nu}-\Ttil$ are always small. This proof uses a similar idea as that of the previous lemma and the main difference is that we can use the fact that $d_{\nu}$ is small for $\nu\notin \mathcal{I}$ to additionally show that the projection of $\ww$ is small even for small dimensional arbitrary subspaces of $T_{\nu}$. Recall that $\Pi_\nu$ is a projection matrix to the space $T_{\nu}-\Ttil$.
%
\begin{restatable}{lemma}{NotImp}\label{lem:NotImp}
For any non-important level, $\nu \notin \cal{I}$,
\[
\Pr\left[\norm{\Pi_{\nu}\ww}^2 \leq \frac{\epsilon}{\log\frac{n}{\epsilon}} \right] \geq 1-\frac{1}{n^{2}}.
\]
\end{restatable}

\begin{proof}
Again, it is sufficient to prove for $\zz$ as defined in \Cref{def:z},
\[
\Pr\left[\norm{\Pi_{\nu}\zz}^2 \leq \frac{\epsilon}{\log\frac{n}{\epsilon}}\|\zz\|^2 \right] \geq 1-\frac{1}{n^{2}}.
\]
In this proof, we consider the case of $q_{\nu}\geq 20\log n$ and $q_{\nu}<20\log n$ separately. Let us first look at $q_{\nu}\geq 20\log n$.
\paragraph{Case $q_{\nu}\geq 20\log n$:}
Our strategy will be to first bound $\|\Pi_{\nu}\zz\|^2$ by $d_{\nu}$, which can be further bounded by $\sum_{\nu'<\nu}d_{\nu'}$.
From \Cref{lem:projZ}, with probability at least $1-1/n^2$,
\[
\|\Pi_{\nu}\zz\|^2 \leq 2q_{\nu}\lambda_{a_{\nu}}^{2K}.
\]
Since $T_{\nu}-\tilde{T}\subseteq T_{\nu}$, $q_{\nu}\leq d_{\nu}$. Furthermore, since $\nu \notin \mathcal{I}$, $d_{\nu}\leq \frac{\epsilon}{600\log^3 \frac{n}{\epsilon}}\sum_{\nu'<\nu}d_{\nu'}$. Using these bounds, we then have with probability $1-1/n^2$,  
\[
\|\Pi_{\nu}\zz\|^2 \leq \frac{\epsilon}{300\log^3 \frac{n}{\epsilon}}\lambda_{a_{\nu}}^{2K}\sum_{\nu'<\nu}d_{\nu'}.
\]
We next bound $\sum_{\nu'<\nu}d_{\nu'}$ in terms of $\|\zz\|$. Consider the $\sum_{\nu'<\nu}d_{\nu'}$ dimensional gaussian vector with coordinates $\alpha_i$, for $i = 1, \cdots, b_{\nu-1}$. Applying \Cref{lem:NormG} to this vector with $\delta=1/3$ gives,
\[
\Pr\left[\sum_{i=1}^{b_{\nu-1}} \alpha_i^2 \geq \left(1-\frac{8}{9}\right)\sum_{\nu'<\nu}d_{\nu'}\right] \geq 1- e^{-\frac{\sum_{\nu'<\nu}d_{\nu'}}{9}} \geq 1-\frac{1}{n^2}.
\]
In the last inequality we used that $\sum_{\nu'<\nu}d_{\nu'}\geq d_{\nu}$ and $d_{\nu}\geq q_{\nu}\geq 20\log n$. We now know that with probability at least $1-1/n^2$,
\[
\sum_{\nu'<\nu}d_{\nu'} \leq 9\sum_{i=1}^{b_{\nu-1}}\alpha_i^2 = 9\sum_{i=1}^{b_{\nu-1}}\frac{\zz_i^2}{\lambda_i^{2K} }\leq 9\frac{\|\zz\|^2}{\lambda_{b_{\nu-1}}^{2K}}.
\]
Therefore, with a probability of at least $1-2/n^2$,
\[
\|\Pi_{\nu}\zz\|^2 \leq \frac{\epsilon}{15\log^3 \frac{n}{\epsilon}}\left(\frac{\lambda_{a_{\nu}}}{\lambda_{b_{\nu-1}}}\right)^{2K}\|\zz\|^2 \leq  \frac{\epsilon}{15\log^3 \frac{n}{\epsilon}}\|\zz\|^2.
\]
The last inequality follows from the fact $\lambda_{a_{\nu}} \leq \lambda_{b_{\nu-1}}$.
\paragraph{Case $q_{\nu} <20 \log n$:} In this case, since $q_{\nu}<20\log n$, we apply the first part of \Cref{lem:projZ} to get
\[
\|\Pi_{\nu}\zz\|^2\leq  \lambda_{a_{\nu}}^{2K} \sum_{j=a_{\nu}}^{b_{\nu}}\alpha_j^2.
\]
Observe that in this case $d_{\nu}$ can be less than $20\log n$. We also know that since $\nu \notin \mathcal{I}$, we can bound $d_{\nu}$ by $\sum_{\nu'<\nu}d_{\nu'}$. In our analysis, we consider the value of $\sum_{\nu'<\nu}d_{\nu}$ and further split it into two parts based on whether $\sum_{\nu'<\nu}d_{\nu}$ is large or small.
\begin{itemize}
    \item $\sum_{\nu'<\nu} d_{\nu'} \geq 20 \log n$: Our strategy would be to first bound $\|\Pi_{\nu}\zz\|^2$ by $\sum_{\nu'<\nu}d_{\nu}$, and then bound $\sum_{\nu'<\nu}d_{\nu}$ by $\|\zz\|^2$. Note that since $\alpha_i$'s are gaussian random variables, $\sum_{j=a_{\nu}}^{b_{\nu}}\alpha_j^2$ follows a $\chi^2_k$ distribution with $k = d_{\nu}$. Therefore, $\sum_{j=a_{\nu}}^{b_{\nu}}\alpha_j^2 \leq d_{\nu} \log n$ with probability at least $1-1/n^2$. Further since $d_{\nu}\leq \frac{\epsilon}{600 \log^3 \frac{n}{\epsilon}}\sum_{\nu'<\nu} d_{\nu'}$, we get with probability at least $1-2/n^2$,
    \[
    \|\Pi_{\nu}\zz\|^2\leq  \lambda_{a_{\nu}}^{2K} \cdot \log n\cdot d_{\nu} \leq \lambda_{a_{\nu}}^{2K}\frac{\epsilon}{600\log \frac{n}{\epsilon}}\sum_{\nu'<\nu} d_{\nu'}.
    \]
    Now, since $\sum_{\nu'<\nu} d_{\nu'} \geq 20 \log n$ we use Lemma~\ref{lem:NormG} again with $\delta = 1/3$, on a vector with coordinates $\alpha_i$'s for $i = 1,\cdots,b_{\nu-1}$ to get with probability at least $1-1/n^2$, 
    \[
    \sum_{\nu'<\nu} d_{\nu'} \leq 9\sum_{i=1}^{b_{\nu-1}}\alpha_i^2=9\sum_{i=1}^{b_{\nu-1}}\frac{z_i^2}{\lambda_i^{2K}} \leq 9\frac{\|\zz\|^2}{\lambda_{b_{\nu-1}}^{2K}}.
    \]
    Plugging this back, we get with probability at least $1-3/n^2$,
    \[
    \|\Pi_{\nu}\zz\|^2\leq \frac{\epsilon}{60\log \frac{n}{\epsilon}} \left(\frac{\lambda_{a_{\nu}}}{\lambda_{b_{\nu-1}}}\right)^{2K}\|\zz\|^2 \leq\frac{\epsilon}{60\log \frac{n}{\epsilon}}\|\zz\|^2.
\]
Last inequality follows from $\lambda_{a_{\nu}} \leq \lambda_{b_{\nu-1}}$.
\item $\sum_{\nu'<\nu} d_{\nu'} < 20 \log n$: Since $\nu\notin \mathcal{I}$, we know that 
\[
d_{\nu}\leq \frac{\epsilon}{600 \log^3\frac{n}{\epsilon}}\sum_{\nu'<\nu}d_{\nu'}.
\]
Since $\sum_{\nu'<\nu} d_{\nu'} < 20 \log n$, we must then have that,
\[
d_{\nu}\leq \frac{\epsilon}{30 \log^2\frac{n}{\epsilon}} <1.
\]
Since the dimension $d_{\nu}$ must be an integer, it must be the case that $d_{\nu} = 0$, and therefore, $\|\Pi_{\nu}\zz\| = 0.$
\end{itemize}
\end{proof}


%
\paragraph{Proof of \Cref{cl:progress}.}
 We are now ready to finally prove \Cref{cl:progress}.

\begin{proof}

We want to show that if $\lambda_{\max}(\AA)\geq 1- \epsilon$ and $\dim{T_{\nu}-\tilde{T}}$ is small for all $\nu\in \mathcal{I}$ as stated in \Cref{cl:progress}, then $\ww^{\top}\VV\ww\leq 35 \epsilon$ for all $\ww\in \WW$ with high probability. Recall that
\[
\ww^{\top}\VV\ww = \ww^{\top}\VV_{\tilde{T}}\ww+\sum_{\nu = 0}^{15\log\frac{n}{\epsilon}-1}\ww^{\top}\VV_{T_{\nu} -\tilde{T}}\ww+ \ww^{\top}\VV_{\overline{T}}\ww.
\]
Let us upper bound each term in the sum below.
\begin{enumerate}
    
    \item \textbf{$\ww^\top\VV_{\tilde{T}}\ww$:} 
    We have 
    \[
        \ww^\top \VV_{\Ttil} \ww = (\Pi_{\tilde{T}}\ww)^{\top}\VV\Pi_{\tilde{T}}\ww =
        (\Pi_{\tilde{T}}\ww)^{\top}\AA\Pi_{\tilde{T}}\ww - (\Pi_{\tilde{T}}\ww)^{\top}\AAtil\Pi_{\tilde{T}}\ww. 
    \]
    From the definition of $\tilde{T}$ (see \Cref{def:SpaceA}), we know that $(\Pi_{\tilde{T}}\ww)^{\top}\AAtil\Pi_{\tilde{T}}\ww \geq \left(1-10\epsilon\right)\lambda_0\|\Pi_{\tilde{T}}\ww\|^2 $ because $\Pi_{\tilde{T}}\ww \in \Ttil = \Span(3\eps,\AAtil).$
    We also know that $(\Pi_{\tilde{T}}\ww)^{\top}\AA\Pi_{\tilde{T}}\ww \leq \lambda_0 \|\Pi_{\tilde{T}}\ww\|^2$. So 
    \begin{equation}\label{eq:V2}
    \ww^{\top}\VV_{\tilde{T}}\ww \leq 10\epsilon\lambda_0 \|\Pi_{\tilde{T}}\ww\|^2\leq 10\epsilon(1+\epsilon)\|\ww\|^2 =10\epsilon (1+\epsilon).
  \end{equation}
\item \textbf{$\ww^\top\VV_{\overline{T}}\ww$:} Since $\ww\in \WW$, from Lemma~\ref{lem:boundLowEV}, with probability at least $1-\frac{3}{n^2}$, $\|\Pi_{\overline{T}}\ww\|\leq \epsilon/2$. Now, 
    \begin{equation}\label{eq:V1}
        \ww^{\top}\VV_{\overline{T}}\ww = (\Pi_{\overline{T}}\ww)^{\top}\VV(\Pi_{\overline{T}}\ww)\leq \|\Pi_{\overline{T}}\ww\|^2\|\VV\| \leq \frac{\epsilon^2}{4}\lambda_0 \leq \frac{\epsilon^2}{2},
    \end{equation}
    where we used that $\|\VV\|\leq \lambda_0$ since $\AAtil = \AA-\VV \succeq 0$ and $\lambda_0\leq 1+\epsilon/\log n$.
    %
    \item \textbf{$\ww^\top\VV_{T_{\nu} -\tilde{T}}\ww$ when $\nu \in \mathcal{I}$:} Note that the dimension of the space $T_{\nu} -\tilde{T}$ is small. We now have,
    \[
    \ww^{\top}\VV_{T_{\nu} -\tilde{T}}\ww = \ww^{\top}\Pi_{\nu}\VV\Pi_{\nu}\ww.
    \]
    We will now consider the large $d_{\nu}$ and small $d_{\nu}$ cases separately.
    \paragraph{Large dimension: $d_{\nu}\geq \frac{3000\log n\log\frac{n}{\epsilon}}{\epsilon}$.}
    In this case, $\dim{T_{\nu} -\tilde{T}} \leq \frac{\epsilon}{300\log\frac{n}{\epsilon}} d_{\nu}$. We can now apply Lemma~\ref{lem:GaussianProjD}, which gives with probability at least $1-\frac{2}{n^2}$,
    \[
\|\Pi_{\nu}\ww\|^2 \leq \frac{\epsilon}{\log\frac{n}{\epsilon}}.
    \]

    Now, using this value,
    \begin{equation}\label{eq:V3}
    \ww^{\top}\VV_{T_{\nu} -\tilde{T}}\ww \leq \|\Pi_{\nu}\ww\|^2 \|\VV\| \leq \frac{\epsilon}{\log\frac{n}{\epsilon}} \|\VV\|\leq  \frac{\epsilon}{\log\frac{n}{\epsilon}} \lambda_0 \leq  \frac{\epsilon(1+\epsilon)}{\log\frac{n}{\epsilon}}.
    \end{equation}
    As in case 2, we again used the fact that $\|\VV\| \le \lambda_0 \le (1+\eps)$.
    \paragraph{Small dimension: $d_{\nu}<\frac{3000\log n\log\frac{n}{\epsilon}}{\epsilon}$.}
    In this case, $\dim{T_{\nu} -\tilde{T}}<1.$ Therefore, the space $T_{\nu} -\tilde{T}$ is empty and as a result, 
    \begin{equation}\label{eq:V4}
    \ww^{\top}\VV_{T_{\nu} -\tilde{T}}\ww  = 0.
    \end{equation}
\item \textbf{$\ww^\top\VV_{T_{\nu} -\tilde{T}}\ww$ when $\nu \notin \mathcal{I}$:}
From Lemma~\ref{lem:NotImp}, $\|\Pi_{\nu}\ww\|^2 \leq \frac{\epsilon}{\log\frac{n}{\epsilon}}$ with probability at least $1-1/n^2$. Since $\|\VV\|\leq \lambda_0\leq 1+\epsilon$, we get,
\begin{equation}\label{eq:V5}
\ww^{\top}\VV_{T_{\nu} -\tilde{T}}\ww \leq \|\Pi_{\nu}\ww\|^2 \|\VV\| \le \frac{\epsilon(1+\epsilon)}{\log\frac{n}{\epsilon}}.
\end{equation}
\end{enumerate}
We now combine all the cases. We have for both large and small $d_{\nu}$ from Equations~\eqref{eq:V2},\eqref{eq:V1},\eqref{eq:V3},\eqref{eq:V4} and \eqref{eq:V5}, with probability at least $1-\frac{40\log\frac{n}{\epsilon}}{n^2}$ for any $\ww\in \WW$,
\[
\ww^{\top}\VV\ww \leq \ww^{\top}\VV_{\overline{T}}\ww + \ww^{\top}\VV_{\tilde{T}}\ww + \sum_{\nu = 0}^{15\log\frac{n}{\epsilon}-1}\ww^{\top}\VV_{T_{\nu} -\tilde{T}}\ww \leq \frac{\epsilon^2}{2} + 10\epsilon(1+\epsilon) + 10\epsilon(1+\epsilon) \leq 35\epsilon.
\]

\end{proof}

